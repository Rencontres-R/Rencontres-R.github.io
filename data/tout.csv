url,titre,auteurrices,langue,resume,thematique,type,mots_cles,conference
https://r2015-grenoble.sciencesconf.org/65868.html,Graphiques interactifs en analyse de données avec Factoshiny,"François Husson, Pauline Vaissié, Astrid Monge",Visualisation,Factoshiny est un package qui permet d'utiliser le package FactoMineR pour d'une part paramétrer les méthodes d'analyse de données et d'autre part pour construire des graphiques interactifs. ,NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66722.html,visNetwork : création et visualisation intéractives de réseaux,Benoit Thieurmel,Visualisation,"Nous proposons de présenter un nouveau package R : visNetwork. Ce package est basé sur la librairie vis.js. Il permet une création et une visualisation intéractives de réseaux, avec notamment les fonctionnalités suivantes : - Réseaux orientés, réseaux hierarchiques - Customisation simple des noeuds et des arêtes (groupe, forme, couleur, taille, image, ...) - Module de clustering des noeuds - Module de création dynamique du réseau - Module de contrôle de la 'physique' - Contrôle de l'intéractivité du graphique (noeuds mouvants ou figés, tooltip, ...)",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66005.html,Classification et visualisation de graphes avec SOMbrero,"Madalina Olteanu, Nathalie Villa-Vialaneix",Visualisation,"Récemment, les données structurées et notamment les graphes ont connu un intérêt croissant. Celles-ci ont en effet de multiples applications en sciences humaines et sociales, en biologie ou en informatique. Pour comprendre les structures complexes modélisées par les graphes, une approche courante consiste à combiner classification des sommets du graphe avec visualisation. Les cartes auto-organisées (SOM) sont une classe d'algorithmes de classification non-supervisée dont le principe est de projeter de manière non linéaire les données sur une carte de dimension faible (généralement une grille rectangulaire à deux dimensions) tout en préservant la structure topologique des données. Dans cette proposition de communication, nous proposons de présenter le package R SOMbrero. Celui-ci contient une version stochastique de l'algorithme SOM adaptée à des données décrites par des matrices de dissimilarités, appelée SOM relationnel. En particulier, le package permet l'utilisation de l'algorithme pour des graphes à partir de (dis)similarités calculées entre sommets.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66101.html,Un package R pour modéliser la survie en tenant compte des effets centres et des risques compétitifs,Marie De Antonio,Application,"Dans la majorité des études cliniques, les patients sont souvent exposés simultanément à plusieurs évènements exclusifs (rechutes, décès...), appelés risques compétitifs. En présence d'évènements multiples, l'effet des covariables doit être estimé en prenant en compte les risques en compétition. En effet, différents événements d'intérêt peuvent être considérés. Plusieurs méthodes statistiques ont été mise en place pour prendre en compte les risques compétitifs. Fine & Gray a proposé “the subdistribution model”. Par exemple, dans le cas d'une leucémie aiguë ; les patients peuvent (1) rechuter directement, (2) rechuter après la survenue de la maladie du greffon contre l'hôte (GvHD) ou (3) décéder sans rechute et sans survenue de la GvHD.  Les modèles à fragilité permettent de modéliser une hétérogénéité entre des groupes de patients issus des différents centres. Par exemple, la prise en charge dans les hôpitaux peut-être différente. Par conséquent, ce paramètre est donc important, d'autant plus si les pratiques sont hétérogènes. Ces individus issus d'un même groupe sont considérés dépendants entre eux. Cette dépendance est contenue dans les termes de fragilité qui permettent d'estimer l'effet centre. L'étude des effets centres permet d'expliquer la variabilité du risque inter-centre et d'avoir des coefficients non biaisés. Pour estimer ces paramètres, la vraisemblance partielle pénalisée est utilisée. Cette approche consiste à exprimer la vraisemblance en deux parties : (1) la vraisemblance partielle conditionnelle en tenant compte des termes de fragilité et (2) la distribution des effets aléatoires.  La distribution des effets aléatoires peut être supposée par une distribution gaussienne ou gamma, selon l'hypothèse de distribution la formule est adaptée. Dans la fonction de l'algorithme il y a deux boucles qui permettent de maximiser la vraisemblance, la boucle interne qui vise à estimer les coefficients pour une distribution donnée des effets aléatoires et la boucle externe qui consiste à estimer la variance des termes de fragilités en utilisant la dernière estimation des coefficients.  Les modèles à risques compétitifs ont ensuite été étendus aux modèles de fragilité qui permettent de prendre en compte l'effet cluster en présence de risques concurrents. Ces deux spécificités (risques compétitifs et effets centres) sont bien connues dans les analyses de survies et doivent être prises en compte afin que le modèle soit performant. Katsahian & Boudreau ont intégré un terme de fragilité pour prendre compte l'effet centre dans le modèle de Fine & Gray qui tient compte des risques compétitifs.  A l'aide de l'étude de simulation, si en réalité il n'y a pas d'effet centre nous pouvons voir que les estimations sont non biaisées. En revanche, l'utilisation d'un modèle classique dans le cadre d'effets centres donne des estimateurs biaisées. Un modèle de fragilité est quant à lui robuste. Quel que soit l'hypothèse de la distribution des effets aléatoires (gamma ou gaussienne), les estimations des coefficients sont très proches, nous observons la même variance de ces estimateurs.  L'exemple illustratif de ce travail concerne l'allogreffe de cellules souches hématopoïétiques (moelle ou sang de cordon ombilical) comme traitement de la leucémie aiguë de l'enfant. Les données proviennent du registre Eurocord de greffes de moelle et concernent 442 enfants atteints de leucémie aiguë et allogreffés soit après soit sans T-déplétion du greffon entre le 1er janvier 1994 et le 31 mai 1998. A la date de point du 1er janvier 1999, le suivi médian est de 30,3 mois; 182 enfants ont eu une GvHD aiguë, 141 ont rechuté et 237 sont décédés.  Comme nous avons observé dans l'exemple, ces méthodes sont importantes à prendre en compte dans les études cliniques. Les méthodes ont été programmées sous R et implémentées dans un package. Les calculs sont basés à partir des fonctions usuelles telles que coxph et it coxme. Ce nouveau package permets donc directement, de modéliser la survie en présence d'effets centres et de risques compétitifs. Dans un tel cadre, le modèle de survie est fortement biaisé si on ne prend pas en compte ces spécificités.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66026.html,Une étude de cas en biomécanique avec la fonction lme de R pour modéliser des structures complexes d'effets aléatoires et de matrice de variance-covariance des erreurs,"Frédérique Letué, Caroline Bazzoli, Marie-José Martinez",Application,"Nous présentons ici une étude de cas sur la modélisation de l'intensité des forces de doigts en biomécanique. L'expérience dont sont issues les données a été décrite dans [1]. Dans cette étude, on a demandé à 15 sujets de presser des capteurs avec les 4 doigts simultanément dans trois conditions expérimentales différentes. Trois mesures ont été réalisées par sujet et par condition expérimentale. Un des buts de l'étude est de comparer les intensités de force de chaque doigt entre les différentes conditions expérimentales et pour chaque condition expérimentale, de comparer les intensités de forces de doigts entre elles. Les données ont d'abord été analysées dans [1] par une simple ANOVA à deux facteurs. Ceci revient à supposer que les mesures entre les 4 doigts sont indépendantes et qu'elles ont été faites sur 45 individus différents. Dans cette présentation, nous proposons une nouvelle modélisation permettant de prendre en compte la répétition des mesures sur les 15 sujets et la dépendance entre les doigts, puisque les mesures sont simultanées. Pour cela, nous utilisons les modèles linéaires mixtes en introduisant des effets aléatoires pour modéliser la variabilité intra-sujet et des structures complexes de variance-covariance des erreurs pour modéliser la dépendance entre les 4 doigts d'une même mesure. Les données sont traitées à l'aide de la fonction lme du package nlme de R [2]. Nous expliquerons pourquoi nous avons choisi lme plutôt que la fonction lmer du package lme4, pourtant développée plus récemment. Nous montrerons les étapes de la modélisation grâce aux options de lme pour aboutir à des structures complexes d'effets aléatoires et de matrices de variance-covariance des erreurs. Enfin, nous présenterons les problèmes que nous avons rencontrés, notamment pour modéliser des corrélations résiduelles complexes à l'aide de lme. Les résultats complets sont disponibles dans [3].   Références [1] Quaine, F., Paclet, F., Letué, F. , Moutet, F. (2012) Force sharing and neutral line during finger extension tasks. Human Movement Science, 31 (4), 749-757. [2] Pinheiro, J., Bates, D., DebRoy, S., Sarkar, D., and R Core Team (2014) nlme: Linear and Nonlinear Mixed Effects Models. R package version 3.1-117. [3] Bazzoli, C., Letué, F., Martinez, M.-J. (2014) Modelling finger force produced from different tasks using linear mixed models with lme R function. En révision pour CSBIGS",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/61214.html,A General Method to map Single-cell Probabilistic Trait Loci of the Genome,"Florent Chuffart, Helene Duplus-Bottin, Daniel Jost, Gaël Yvert",Application,"In living organisms, cell-to-cell variability can have dramatic consequences. For example, in some individuals, the occurrence of rare cellular events is responsible for disease. This single-cell variability can be quantified. It can also be described statistically by considering quantitative traits as random variables that follow probability density functions, each single-cell having a probability to express a given value of a trait. It is now known that genotypes can shape the statistical properties of single-cell phenotypic traits. Finding genetic loci involved in the control of single-cell quantitative trait density functions is therefore a promising challenge. However, methods to map such loci have not yet been developed beyond the approaches based on QTL (Quantitative Trait Loci) mapping, which are focused on the main moments (mean and variance) of the distribution. We propose here a novel method that allows us : i) to discriminate individuals by comparing the distribution of their phenotype and ii) to map the genetic loci responsible for specific distributions. This method is based on a metric that compares individuals on the basis of their single-cell trait distributions. Individuals are then projected into a space vector, and multivariate analysis searches for discrimination based on the genotype. Our method was validated on a simulated dataset of an auto-regulated gene model and on a published yeast morphological traits dataset. We have observed that our method is of particular interest do detect loci that have a small effect on the shape of single-cell trait density function. This project is funded by European Research Council (SiGHT project, ERC-StG2011-281359). [1] Yvert G. 'Particle genetics': treating every cell as unique. Trends in Genetics. 2014 30(2):49-56. [2] Nogami S, Ohya Y and Yvert G. Genetic Complexity and Quantitative Trait Loci Mapping of Yeast Morphological Traits. PLoS Genetics, 2007, 3(2):e31.  ",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66081.html,An extension to generalized pairwise comparisons for prioritized outcomes with censoring,Julien Péron,Modélisation,"Generalized pairwise comparisons have been proposed to permit a comprehensive assessment of several prioritized outcomes between two groups of observations [1]. We propose an extension of generalized pairwise comparisons for time-to-event outcomes that takes into account the time to censored observations. We show how pairwise scores can be calculated from the Kaplan-Meier estimates of the survival function in the presence of right-censored data. These scores are used to estimate the chance of a better outcome with treatment than with control, which is defined as where the outcome is captured by the variable in the treatment group and by the variable in the control group. A randomization test can be used to test the null hypothesis , and to calculate a confidence interval for . The extended procedure for generalized pairwise comparisons is more efficient than the standard procedure. When several outcomes are prioritized in a single assessment of the overall treatment effect (i.e. benefit-risk assessment), the estimation of the chance of a better outcome varies only slightly with the censoring pattern. Since the way the censoring occurs is independent of the parameters of interest (benefits and risks of an investigational treatment), the censoring rate on the survival outcome should not have a large impact on the estimation of the chance of a better outcome. To facilitate the use of generalized pairwise comparisons we have developed an R package BuyseTest, which we will present. The package includes the standard procedure of generalized pairwise comparisons, and two extensions for time-to-event outcome analyses. The standard procedure of pairwise scoring for time-to-event variable is to classify as ‘uninformative' all the pairs not known to be favorable or unfavorable because of censoring. When only one time-to-event outcome is considered, this approach is equivalent to Gehan's extension of the Wilcoxon test for censored data [2]. The first extension estimates using the Kaplan-Meier estimate of the survival function based on all observations, following Latta's modification of Efron's test and Peto and Peto's test [3]. The second extension estimates using the Kaplan and Meier estimates of the survival function of the two groups of patients, following the Efron's generalization of the Wilcoxon test [4]. The R package BuyseTest also includes a function to compute sample size while designing randomized trials.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66216.html,abc : un paquetage R pour le calcul bayésien approché,Michael Gb Blum,Modélisation,"Le calcul bayésien approché (« Approximate Bayesian Computation » en anglais) est une technique de statistique bayésienne qui permet de faire de l'inférence statistique dans des modèles où le calcul de la vraisemblance est trop couteux d'un point de vue numérique. Cette technique a fait ses preuves en génétique des populations dans le cadre des modèles de coalescence [1]. Dans ces modèles, les paramètres à estimer sont en général de l'ordre de la dizaine tandis que le nombre de variable latentes est beaucoup plus grand ce qui rend difficile voire impossible le calcul de la vraisemblance et l'application des méthodes de Monte-Carlo par chaînes de Markov. Dans le calcul bayésien approché, l'inférence statistique repose sur des simulations numériques du modèle et un algorithme de rejet éventuellement suivi de méthodes dites d'ajustement [2,3]. Dans cet exposé, je présenterai comment effectuer les différentes étapes de l'analyse statistique avec le calcul bayésien approché : inférence des paramètres, comparaison de modèles et évaluation de l'adéquation du modèle aux données. Après une présentation des concepts statistiques, je montrerai comment effectuer ces opérations avec le paquetage R abc [4]. J'illustrerai les différentes étapes du calcul bayésien approché avec un exemple issu de la génétique des populations où l'objectif est d'inférer la démographie passée de populations humaines à partir d'indicateurs statistiques de la variabilité génétique.   Références [1] Beaumont, M. A., Zhang, W., & Balding, D. J. (2002). Approximate Bayesian computation in population genetics. Genetics, 162(4), 2025-2035. [2] Blum, M. G. B., & François, O. (2010). Non-linear regression models for Approximate Bayesian Computation. Statistics and Computing, 20(1), 63-73. [3] Blum, M. G. B. (2010). Approximate Bayesian computation: a nonparametric perspective. Journal of the American Statistical Association, 105(491), 1178-1187. [4] Csilléry, K., François, O., & Blum, M. G. B. (2012). abc: an R package for approximate Bayesian computation (ABC). Methods in ecology and evolution, 3(3), 475-479.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/68590.html,ibr: un paquet R pour la réduction itérative de biais,"Eric Matzner-Lober, Pierre-André Cornillon",Modélisation,"   Si nous souhaitons expliquer une variable Y par un ensemble de d variables explicatives X1, · · · , Xd, la régression constitue un outil classique de la statistique. Cette famille de modélisation com- prend la régression paramétrique linéaire ou non-linéaire, la régression non-paramétrique util- isant des lisseurs construits à partir d'ondelettes, de noyaux, de splines.  Dès que le nombre d'observations est modéré (de l'ordre de plusieurs centaines) et que le nombre de variables d est plus grand que 3 ou 4, les approches non-paramétriques classiques rencontrent le problème dit du fléau de la dimension. Dans ce cas, un modèle structurel est souvent utilisé: par exemple un modèle additif, des directions révélatrices ou MARS.  Le boosting est aussi une réponse possible au problème de régression et cette méthode possède maintenant de nombreux développements comme adaboost, logitboost pour la dis- crimination ou le L2 boosting pour la régression. Cette dernière peut être utilisée avec de nombreux lisseurs et donne lieu à une modélisation additive par composante.  A contrario, la réduction itérative de biais permet d'estimer une fonction de régression multi- variée directement via un lisseur multivarié sans hypothèse paramétrique ou sans contraintes structurelles.    ",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66887.html,Compétitions d'apprentissage automatique avec le package rchallenge,"Robin Genuer, Adrien Todeschini",Lightning talk,"En apprentissage automatique, les performances empiriques obtenues sur données réelles sont déterminantes dans le succès d'une méthode. Ces dernières années ont vu l'apparition d'un grand nombre de compétitions d'apprentissage automatique. Ces challenges sont motivés par des applications industrielles (prix Netflix) ou académiques (challenge HiggsML) et mettent en compétition chercheurs et data scientists pour obtenir les meilleures performances. Nous avons souhaité confronter les étudiants à cette réalité en leur soumettant un challenge dans le cadre du cours d'apprentissage automatique. Leur classement est affiché sur une page web mise à jour automatiquement permettant une émulation parmi les étudiants. L'historique des résultats leur permet également de visualiser leur progression au fil des soumissions. De plus, le challenge peut se poursuivre en dehors des sessions encadrées favorisant l'autonomie et l'exploration de nouvelles techniques d'apprentissage et outils informatiques. Le système que nous avons mis en oeuvre est disponible sous forme de package R afin d'être réutilisé par d'autres enseignants. S'appuyant sur les outils R Markdown et Dropbox, il ne nécessite aucune configuration réseau et peut être déployé très facilement sur un ordinateur personnel.",NA,lightning talk,,rr2015
https://r2015-grenoble.sciencesconf.org/65999.html,"Datacamp : Apprendre R, en faisant du R, dans R...et en français.",Vincent Guyader,Lightning talk,"Les outils permettant d'apprendre R en français sont relativement rares. Beaucoup ont commencé leur apprentissage grâce au cours PDF d'Emmanuel Paradis ""R pour les débutants"" [1] complété par le PDF ""R pour les statophobes"" de Denis Poinsot [2] et ces supports ont maintenant plus de 10 ans. Il existe aussi quelques livres plus récents tels que ""Statistique avec R"" [3] et ""Comprendre et réaliser les tests statistiques à l'aide de R : Manuel de biostatistique"" [4]. Cela dit les ressources en ligne sont plutôt pauvres : la blogosphère et les sites spécialisés francophones sont peu développés. Tous ces supports (livres, tutoriels online, vidéos...) supposent des aller-retour entre les instructions dispensées par le contenu et la console R.   Lors du processus d'apprentissage, il est essentiel que la langue ne soit pas une barrière. Ainsi pouvoir se focaliser pleinement sur ce que l'on doit apprendre sans devoir se concentrer pour déchiffrer une langue qui parfois ne nous est pas familière est un atout indéniable. Dès lors, il était important de proposer aux francophones un outil dans l'air du temps permettant d'apprendre efficacement à maitriser R et ses subtilités.   Datacamp (www.datacamp.com) est une plateforme interactive qui propose des cours R de tous niveaux, aussi bien pour les grands débutants que pour les experts qui veulent approfondir telles ou telles fonctionnalités. Concrètement l'utilisateur est face à une version web de R, avec un éditeur et une console.L'interface interagit avec l'utilisateur et lui propose de suivre un cours sur un sujet qui l'intéresse (exemple : ""introduction à R"", "" R pour les utilisateurs de SAS"", ...). L'apprenant s'approprie alors R, en faisant du R, dans R. L'interface est prévue de telle sorte qu'elle est capable de comprendre les instructions tapées par l'utilisateur : elle peut le corriger, lui donner des astuces et le conseiller au fur et à mesure de sa progression. Pour l'utilisateur tout se passe comme si un formateur R se penchait sur son épaule pour le conseiller. Nul besoin de se référer à un tutoriel sur une autre application ou dans un livre : l'interface se charge de tout.   Lancée en 2014 par une équipe Belge de 3 passionnés [5] la version anglophone de la plateforme connaît déjà un grand succès. Des dizaines de milliers d'utilisateurs de tous niveaux utilisent quotidiennement la plateforme, confirmant ainsi l'intérêt du projet. La version française de l'outil initiée par ThinkR [6] vient enrichir l'offre. L'outil est gratuit pour les cours de bases et en intégralité pour les universités, le coût est de l'ordre de 9$ par mois pour les étudiants et 25$ par mois pour les autres.   Nous avons hâte de vous présenter en juin la prochaine version de cet outil qui utilise cette fois la version web de Rstudio et qui permet de proposer une expérience utilisateur encore plus immersive.",NA,lightning talk,,rr2015
https://r2015-grenoble.sciencesconf.org/66085.html,FreeSortR : un package pour l'analyse de données de tri libre.,Philippe Courcoux,Lightning talk,"FreeSortR : un package pour l'analyse de données de tri libre.   Ph. Courcoux   Unité de Sensométrie et Chimiométrie Oniris Rue de la Géraudière 44322 Nantes, France. philippe.courcoux@oniris-nantes.fr     Mots clefs : Tri libre, Partitions, Multidimensional Scaling.     L'épreuve de tri libre est une tâche mise en œuvre pour mettre en évidence les catégories d'objets ou de stimuli que les sujets construisent ainsi que les dimensions qui structurent leurs perceptions. Couramment utilisée en psychologie, cette technique est de plus en plus adoptée dans le cadre de l'analyse sensorielle pour décrire un ensemble de produits [2]. Lors d'une épreuve de tri libre, le sujet est invité à partitionner les produits en autant de classes qu'il/elle juge nécessaire avec la consigne que les produits d'une même classe sont ceux qu'il/elle perçoit comme étant proches. Ainsi les données collectées se présentent sous forme de partitions d'un même ensemble de produits, chaque partition étant produite par un sujet. Très souvent, à l'issue du partitionnement des produits, les sujets sont invités à décrire les groupes constitués à l'aide de mots ou expressions qui leur semblent pertinents. Généralement, cette description verbale (ou « verbatims ») est utilisée comme élément d'interprétation des résultats.   Le package FreeSortR est destiné à fournir des outils de traitement et d'interprétation de données issues d'une épreuve de tri libre. Les principales fonctionnalités sont : - Des fonctions permettant de générer facilement des structures de données adaptées à l'exploitation de données de tri libre, - Une fonction réalisant une analyse multidimensionnelle de l'ensemble des partitions générées. Basée sur du MDS (Multidimensional Scaling) de type Smacof, cette fonction admet du bootstrap sur les sujets, permettant de construire des régions de confiance dans la configuration des stimuli, - Une fonction permettant de générer la partition consensus de l'ensemble des sujets [1]. Cette partition est celle qui maximise la similarité (au sens du critère du Rand ajusté) avec les partitions originales, - Des outils pour représenter les verbatims utilisés par les sujets et interpréter la configuration issue du MDS.   La présentation illustrera les différentes fonctionnalités du package en s'appuyant sur une expérimentation sur la perception d'arômes par des sujets.     Références [1] P.Courcoux, P.Faye, E.M.Qannari (2013) Determination of the consensus partition and cluster analysis of subjects in a free sorting task experiment. Food Quality and Preference 32:107–112.  [2] P.Faye, P.Courcoux, E.M.Qannari (2011) Méthodes de traitement statistique des données issues d'une épreuve de tri libre. Revue Modulad, 43:1-24.  ",NA,lightning talk,,rr2015
https://r2015-grenoble.sciencesconf.org/66116.html,L'histoire en miettes : analyse de graphes avec R pour l'étude de la fragmentation des objets archéologiques,Sébastien Plutniak,Lightning talk,"En archéologie, l'analyse des relations entre fragments provenant d'un même objet a suscité un renouveau d'intérêt ces dernières décennies [3, 4]. Ces relations peuvent être utiles à plusieurs titres: permettre la reconstruction des objets originaux, identifier les séquences de leur confection ou enfin critiquer les divisions stratigraphiques en considérant les déplacements des fragments entre les couches. C'est ce dernier aspect qui retient ici notre attention. De nombreuses propositions ont été faites, certaines très raffinées, concernant la définition et le décompte des relations entre fragments et des ensembles qu'elles constituent [3, 4]. Toutefois, ces méthodes reposent en grande majorité sur un décompte des relations sans que la manière dont elles sont organisées soient prise en compte.  En représentant ces relations sous la forme de graphes, nous proposons donc de préciser leur description en tenant compte leur structure et en l'évaluant. Si une approche similaire a pu être proposée à des fins de reconnaissance de forme afin d'automatiser la reconstruction des objets archéologiques [5], aucune tentative n'a été faite [1] pour établir une mesure structurale de l'intégrité d'une séquence stratigraphique à partir de l'analyse des relations entre fragments situés au sein ou entre les strates. Nous illustrerons donc les résultats d'une telle analyse à partir de l'exemple des restes céramiques trouvés lors des fouilles de l'abri sous roche de Liang Abu, à Kalimantan est, Indonésie [6]. La formalisation de ces relations en termes de graphe pousse à l'explicitation d'intéressantes caractéristiques permettant de préciser les spécificités des objets archéologiques. L'analyse de ces graphes est ensuite menée à l'aide de la librairie \emph{igraph} [2]. Nous proposerons enfin l'état des lieux d'un projet de librairie R dédiée à l'analyse de la fragmentation des objets archéologiques.   [1] Brughmans T., (2012). Thinking through networks: a review of formal network methods in archaeology. Journal of Archaeological Method and Theory, 1-40.  [2] Csardi G, Nepusz T., (2006). The igraph software package for complex network research. InterJournal Complex Systems, 1695.  [3] Cziesla E., Eickoff S., Arts N., Winter D. (eds), (1990). The Big Puzzle: International Symposium on Refitting Stone Artifacts. Studies in Modern Archaeology, 1. Bonn: Holos Verlag.  [4] Hofman J.L., Enloe J.G. (eds), (1992). Piecing together the past: applications of refitting studies in archaeology, 578, Tempus Reparatum.  [5] Maiza C., Gaildrat V. (2005). Automatic classification of archaeological potsherds. In Pléménos D., (ed.) The Eight International Conference on Computer Graphics and Artificial Intelligence, 3IA 2005, MSI Laboratory, Faculté des sciences, Limoges, France, May 11-12 2005.  [6] Plutniak, S., Oktaviana, A. A., Sugiyanto, B., Chazine,J.-M., Ricaut, F.-X. (2014). New Ceramic Data from East Kalimantan: cord-marked and red-slipped sherds of Liang Abu's layer 2 and Kalimantan's pottery chronology. Journal of Pacific Archaeology}, 5 (1), 90-99.",NA,lightning talk,,rr2015
https://r2015-grenoble.sciencesconf.org/65112.html,Modèles de mutations : étude probabiliste et estimation paramétrique,"Adrien Mazoyer, Stéphane Despreaux, Bernard Ycart",Lightning talk,"(Voir fichier fourni pour le résumé complet, avec références et description plus détaillée du package) L'estimation des probabilités de mutation est d'une importance cruciale dans plusieurs domaines de la médecine et de biologie: cancer, tuberculose, microbiologie, etc. Une construction générale des modèles de mutation se décompose en trois niveaux : l'apparition de mutations aléatoires au cours d'un processus de croissance, la durée de développement de chaque clone issu des cellules mutantes et le nombre de cellules produites par un clone durant un temps de développement donné. En pratique, les divisions cellulaires sont très nombreuses, et la probabilité de mutation est très faible, ce qui mène à une modélisation asymptotique. Le modèle classique de Luria-Delbrück repésente le nombre final de mutantes observées comme la composée poissonnienne (nombres de mutations) d'un mélange exponentiel (durée de développement des clones) de lois géométriques (taille finale du clone). Cette loi dépend alors de deux paramètres, la probabilité individuelle de mutation p, et le rapport des taux de croissance des cellules normales et mutantes r, aussi appelé fitness. Le problème statistique consiste à estimer p et r au vu d'un échantillon de décomptes finaux de cellules mutantes. Il peut être résolu par la méthode du maximum de vraisemblance, par une méthode de moment exponentiel, ou par la méthode dîte ""p0"". Cependant, les hypothèses de modélisation sous laquelle la distribution du nombre final de mutantes est explicite sont irréalistes : absence de morts cellulaires, durées de vie exponentielles, nombre final de cellules constant, etc. On obtient des estimations biaisées par rapport aux valeurs réelles. Le package flan que nous développons permet d'effectuer des simulations et des estimations dans le cas du modèle classique de Luria-Delbrück, mais également sous des hypothèses de modélisation plus générales : durées de vie non-exponentielles, morts cellulaires, variabilité du nombre final de cellules.",NA,lightning talk,,rr2015
https://r2015-grenoble.sciencesconf.org/66059.html,SARTools : un pipeline complet pour l'analyse différentielle de données RNA-Seq,"Hugo Varet, Jean-Yves Coppée, Marie-Agnès Dillies",Lightning talk,"SARTools est un package R dédié à l'analyse différentielle de données RNA-Seq dans le cadre de plans d'expériences simples, i.e. de plans d'expériences comparant deux ou plusieurs conditions biologiques d'un même facteur. SARTools fournit des outils pour importer les données de RNA-Seq, pour générer des graphiques descriptifs et de diagnostic, pour réaliser l'analyse différentielle avec DESeq2 [1] ou edgeR [2] et pour exporter les listes de gènes différentiels dans des fichiers textes tabulés compatibles avec tout tableur. En s'appuyant sur le package knitr [3], SARTools génère également un rapport final au format HTML qui reprend toutes les figures produites, explique les méthodes statistiques et donne les résultats de l'analyse différentielle. Dans un souci de recherche reproductible, le rapport affiche également les paramètres choisis pour l'analyse ainsi que les versions des packages utilisés. SARTools ne remplace pas DESeq2 ou edgeR mais fournit un environnement complet pour les mettre en oeuvre. De plus, la vignette du package fournit une aide à l'utilisation du workflow et donne des conseils pour détecter divers problèmes telles que la présence d'effets batch dans les données, ou une inversion d'échantillons.SARTools est disponible sur GitHub et est distribué avec deux scripts R génériques : un pour DESeq2 et un pour edgeR. Une fois le package et ses dépendances installés, il suffit de définir les paramètres de l'analyse dans le préambule d'un des scripts et de l'exécuter entièrement pour générer tous les fichiers de résultats décrits ci-dessus.",NA,lightning talk,,rr2015
https://r2015-grenoble.sciencesconf.org/66796.html,Validation de données en phénotypage végétal,"Antoine Schorgen, Nadine Hilgert",Lightning talk,"Lors d'expériences menées dans des plateformes de phénotypage à haut débit, une grande quantité d'information est récoltée: mesures physiologiques, mesures environnementales, photographies des plantes au cours du temps... Cette masse de données empêchant une vérification manuelle des résultats, il devient nécessaire de mettre au point des routines de visualisation et validation des données. En utilisant les photographies des plantes, nous vous présenterons la méthodogie, basée sur des packages R et des régressions, qui nous permet d'obtenir des mesures fiables de biomasse et surface foliaire notamment.",NA,lightning talk,,rr2015
https://r2015-grenoble.sciencesconf.org/66664.html,Clustering divisif monothétique. La package divclust,"Marie Chavent, Marc Fuentes",Classification,"DIVCLUS-T est une méthode descendante de clustering hiérarchique basée sur une approche de bi-partitionnement monothétique permettant de lire le dendrogramme comme un arbre de décision. Nous présenterons cette méthode et verront comment elle peut s'appliquer à des données quantitatives, qualitatives ou mixtes. L'algorithme ainsi que le package ""divclust"" seront présentés et illustrés sur des exemples.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66090.html,Classification de variables avec possibilité de mettre à l'écart des variables atypiques ou de bruit. Implémentation dans le package ClustVarLV.,"Evelyne Vigneau, El Mostafa Qannari",Classification,"En général, les méthodes de classification ne permettent pas de tenir compte de la présence de données atypiques ou de bruit. Le processus de classification concerne tous les objets statistiques, même ceux qui n'ont pas de liens (proximités) avec aucun autre objet du jeu de données. Les méthodes de classication floue offrent la possibilité d'affecter ce type d'objets à différentes classes mais avec un degré d'appartenance faible. On adoptera des approches de classification ""nette"", mais en offrant la possibilité qu'un objet atypique ne soit affecté à aucune classe, ou, alternativement, que cet objet ne soit pas pris en compte dans la dénifition des noyaux des différentes classes. On se placera dans le cadre de la classification de variables, les objets statistiques considérés pouvant être des items de réponse d'un questionnaire; des caractéristiques sensorielles, biochimiques; ou encore des variables spectométriques ou chromatographiques quantiées par des approches holistiques de type -omiques, etc.La méthode de classification de variables autour de variables latentes (CLV) [1], implémentée dans le package ClustVarLV [2], a été adaptée an de pouvoir mettre à l'écart les variables assimilables à du bruit ou atypiques en regard de la structure des corrélations au sein du jeu de données. A partir d'une partition initiale des variables, l'algorithme d'optimisation alternée de CLV consiste en deux étapes : (a) une étape d'estimation de la variable latente de chaque groupe, et (b) une étape de (ré-)affectation de chacune des variables au groupe avec lequel elle présente le lien le plus fort. Dans la méthode CLV, selon l'objectif poursuivi par l'utilisateur, ce lien est mesuré soit par la covariance, soit par la covariance au carré, entre la variable considérée et la composante latente du groupe. Deux stratégies différentes de modification de l'algorithme sont proposées. ... Il est possible de mettre en oeuvre, l'une ou l'autre de ces deux stratégies en utilisant la fonction CLV_kmeans() du package ClustVarLV. Deux exemples de mise en oeuvre de cette démarche de classication de variables, avec ""nettoyage"", seront brièvement présentés. Dans le contexte de la segmentation de consommateurs en évaluation sensorielle, la possibilité de mettre de côté des consommateurs dont les préférences ne s'accordent pas avec les grandes tendances au sein du panel, permet d'exhiber une segmentation plus interprétable. Dans le domaine des techniques analytiques à haut débit, telle que la RMN, qui permettent de collecter un grand nombre de points de mesure pour chaque échantillon, la classification CLV permet d'identifier des sous-ensembles de variables fortement corrélées. Les stratégies complémentaires proposées ici permettent, également, d'écarter les variables spectrales dont la variabilité serait assimilable à du bruit. Références[1] Vigneau, E., Qannari, E. M. (2003). Clustering of variables around Latent Variables. Comm.Stat. - Simul. Comput., 32(4), 1131-1150.[2] Vigneau, E., Chen, M. (2015). ClustVarLV: Clustering of variables around Latent Variables.URL http://CRAN.R-project.org/package=ClustVarLV,R package version 1.3.2.[3] Davé, R. N. (1991). Characterization and detection of noise in clustering. Pattern Recognition Letters, 12,(11), 657-664.[4] Zou, H., Hastie, T., Tibshirani, R. (2006). Sparse principal component analysis. J. Comput. Graph. Statist., 15, 265-286.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/61963.html,Etude de la robustesse de RMixmod (package de classification par modèles de mélanges) en cas de chevauchement de classes,Florent Langrognet,Classification,"Les modèles de mélanges offrent un cadre probabiliste flexible et efficace pour traiter des problématiques de classification supervisée ou non supervisée. L'objectif du projet MIXMOD est de diffuser un ensemble logiciel de classification des données par modèles de mélanges à un large spectre d'utilisateurs via plusieurs composants logiciels. La bibliothèque de calcul mixmodLib (C++) en est la pierre angulaire, résultat d'un travail de près de 15 ans sur la robustesse et la rapidité de calcul. Le package RMixmod, ensemble de fonctions pour R, interfacé avec mixmodLib (grâce à RCPP) est devenu un outil de référence pour la classification des données.Intégrant de nombreuses fonctionnalités (algorithmes de type EM, critères de sélection, modèles parcimonieux, stratégies d'initialisation, ...), cet ensemblelogiciel permet de traiter des données quantitatives, qualitatives et mixtes, y compris dans des situation complexes.L'une des difficultés en classification des données réside dans la capacité à donner des bons résultats en cas de chevauchement entre plusieurs classes : trouver le bon nombre de classes, les bons paramètres et les bonnes affectations des individus à ces classes (labels). L'étude consiste à tester RMixmod sur des jeux de données simulées en contrôlant le degré de chevauchement entre les classes (grâce au package MixSim) sur des données quantitatives.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66855.html,"An experimental assessment of the ""Gibbs-Energy and Empirical-Variance"" estimating equations (via Kalman smoothing) for Matérn processes",Didier Girard,Poster,"   The problem of estimating (from n noisy observations of a single realization, at known sites) the parameters of a centered stationary Gaussian process whose autocorrelation function belongs to the Matérn class appears in many contexts (e.g. [1, 2, 3]). The recently proposed CGEM-EV method [4] only requires the computation of several conditional means, at the observation sites, corresponding to candidate values for the Matérn parameters. In dimension 1 and when the “Matérn differentiability” parameter is fixed to k + 1/2 with k integer (an often-used value is k = 0 or k = 1, see e.g. [3], [1], [6], [7]), each of these conditional means reduces to a Kalman smoothing.  An R implementation of CGEM-EV for this context is presented : it is built on the R-package dlm [5]. It proves to be quite fast, even for high-frequency sampling (e.g. n = 8196), and an empirical comparison with the classical maximum likelihood estimator confirms the near- efficiency results of [4].       References  [1] Rasmussen C.E., Williams C.K.I. (2006), Gaussian Processes for Machine Learning, Cam- bridge, MA: MIT Press. www.gaussianprocess.org/gpml/chapters.  [2] Zhang H. (2012). “Asymptotics and Computation for Spatial Statistics,” in Advances and Challenges in Space-time Modelling of Natural Events (Lecture Notes in Statistics, Vol. 207) (E. Porcu, J. M. Montero, and M. Schlather, eds.), New York: Springer, pp. 239−−252. doi:10.1007/978-3-642-17086-7_10.  [3] Kaufman C.G., Shaby, B.A. (2013). “The Role of the Range Parameter for Estimation and Prediction in Geostatistics,” Biometrika 100 (2), pp. 473−−484. doi:10.1093/biomet/ass079.  [4] Girard D.A. (2012). “Asymptotic Near-Efficiency of the 'Gibbs-Energy and Empirical- Variance' Estimating Functions for Fitting Matérn Models to a Dense (Noisy) Series,” 2012. arxiv.org/pdf/0909.1046v2.pdf.  [5] Petris Giovanni (2010). “An R Package for Dynamic Linear Models,” Journal of Statistical Software, 36(12), 1-16. URL: http://www.jstatsoft.org/v36/i12/  [6] Girard D.A. (2014) “Estimating a Centered Ornstein-Uhlenbeck Process under Measurement Errors,” Wolfram Demonstrations Project, Published: July 1, 2014. URL: demonstrations.wolfram.com/EstimatingACenteredOrnsteinUhlenbeckProcessUnderMeasurementE/  [7] Girard D.A. (2015) “Three Alternatives to the Likelihood Maximization for Estimating a Centered Matérn (3/2) Process, ” Wolfram Demonstrations Project, URL: demonstrations.wolfram.com/ThreeAlternativesToTheLikelihoodMaximizationForEstimatingACe/         ",NA,poster,,rr2015
https://r2015-grenoble.sciencesconf.org/65946.html,Bayesian Analysis of Connectivity in Macaque Cerebral Cortex using JAGS and Stan,"Artemis Toumazi, Kenneth Knoblauch, Henry Kennedy, Martin Privat",Poster,"There is currently great interest in understanding the network structure (or connectome) of the nonhuman primate (NHP) cortex as it will be much more informative about human cortical organization than other animal models. Our group has assembled a consistent data base of the weighted inputs to 29 areas (of the 91 in our cortical parcellation) distributed across the macaque cortex, using retrograde tract-tracing techniques [3]. In retrograde tracing, an injected marker is transported along axons from the target site of injection to the cell bodies in a source area that project to the injection site. The number of marked neurons is exhaustively counted for each cortical source area projecting to the target. We analyze a measure of strength of projection for each source called the extrinsic Fraction of Labelled Neurons (FLNe) defined as the proportion of marked neurons from a source with respect to all marked neurons in the cortex external to the target area. The data constitute a 29 × 91 weighted and directed graph, G29×91. We also study the 29×29 edge-complete subgraph of the connections only between the 29 injection sites, G29×29. Since the injection sites are distributed across the cortex, the G29×29 subgraph is expected to be representative of the full connectivity matrix of the brain, G91×91. We have characterized the variability of the data base and found a number of regularities in it that indicate fundamental principles of cortical organization. Connection strength decreases approximately exponentially with distance traversed by a projection. This Exponential Distance Rule (EDR) predicts a surprising number of features of macaque cortical organization. We are exploring the use of Bayesian models that incorporate the observed characteristics of our data base in order to construct a probabilistic map of connectivity across the cortex covering unexplored areas and to evaluate where to place new injections to minimize uncertainty about the full connectivity matrix. We are currently building models using JAGS and Stan and running these from R with interfacing packages. Because of overdispersion, the neuron counts were assumed to be distributed as a negative binomial. To model the FLNe, the log of the total counts for each injection was used as an offset. Since, Target areas vary in their number of Sources by almost a factor of 3, using the EDR to predict FLNe rather than treating each Source as an independent level of a factor, enormously reduces the number of parameters to estimate. To account for variations in the EDR across Target areas, however, the space constant was treated as exchangeable with a hyperprior distribution. The current model provides a reasonable description of the FLNe profiles for 4 Target areas in which we have data for multiple repeat injections. We are seeking to extend the model to the full set of 29 injections and to use it to estimate characteristics of the unobserved connectivity profiles of the Target areas that are as yet uninjected.",NA,poster,,rr2015
https://r2015-grenoble.sciencesconf.org/66039.html,"Computational optimisation for mixOmics, the R package dedicated to 'omics' data integration","FranÇois Bartolo, Sébastien Déjean, Benoit Gautier, Ignacio González, Florian Rohart, Kim-Anh Lê  Cao",Poster,We have recently implemented novel methodologies in mixOmics to integrate several 'omics data sets simulaneously. These novel developments require intensive computations which can be eased through efficient optimisation and memory management.,NA,poster,,rr2015
https://r2015-grenoble.sciencesconf.org/66111.html,Identifier des biomarqueurs en métagénomique quantitative : la promesse du Big Data,"Magali Berland, Emmanuelle Le Chatelier, Edi Prifti, Nicolas Pons, Anne-Sophie Alvarez, Ndeye Gaye, Jean-Michel Batto, Vincent Ducrot, Kévin Juilly, Sébastien Monot, Thierry Goubier, Nahid Emad, Dusko Ehrlich",Poster,"Par des approches de séquençage à très haut-débit, la métagénomique quantitative consiste à quantifier les gènes ou les espèces composant un écosystème complexe (par exemple la flore intestinale humaine). Cependant, l'analyse des données métagénomiques se confronte à un défi de taille : la masse de données sans précédent générée par les nouvelles technologies de séquençage nécessite des outils de traitement et d'analyse de données adaptés à plusieurs millions de variables. La suite MetaOMineR est un ensemble de packages R permettant d'explorer de nombreuses questions cruciales en métagénomique quantitative et a été largement déployé dans plusieurs projets fondateurs du domaine [1-2]. Elle a permis d'identifier des biomarqueurs prometteurs sur le plan de la santé humaine et permis des avancées significatives dans la quête de compréhension de ces écosystèmes complexes [3]. Le package central de la suite, momr, implémente une série de fonctions pour analyser des matrices de comptage des gènes présents ou absents au sein d'une cohorte d'individus en fonction d'un catalogue de gènes de référence. Des fonctions de normalisation et de sous-échantillonnage permettent de réduire la variabilité technique entre les séquençages. De plus, la réduction du nombre de dimensions est possible grâce à l'implémentation de fonctions de clustering, de projection sur les espèces métagénomiques (MGS) [4], et diverses procédures de filtrage et de mesures de qualité du signal. Enfin, un ensemble de fonctions statistiques permettent d'identifier les gènes, MGS ou fonctions associées à un phénotype ou à une donnée clinique et à visualiser les différentes relations et données. La taille des catalogues de gènes sans cesse croissante (3.3 millions en 2010, 10 millions en 2014) limite l'utilisation de ce package avec des méthodes calculatoires classiques (calcul lent, voire impossible). R n'étant pas adapté aux données Big Data, dans le cadre du projet européen MACH (Massive Calculation of Heterogeneous System) [5], il a été proposé de construire une solution permettant de rendre possibles ces analyses. Ce consortium est en train de développer un compilateur ‘R' avec un nouvel IDE associé ayant pour cible des architectures data-parallèles comme le GPU ou le Xeon PHI. En parallèle, nous avons proposé l'implémentation d'une bibliothèque (version C/Cuda) ayant pour cible des architectures de type GPU dans le but d'optimiser le package momr. Dans ce poster, nous présenterons le package ainsi que sa nouvelle implémentation accélérée pour une application sur des données réelles.",NA,poster,,rr2015
https://r2015-grenoble.sciencesconf.org/65986.html,Maximum likelihood conjoint measurement: From GLM to GAM,"Clement Abbatecola, Kenneth Knoblauch, Peggy Gerardin, Henry Kennedy",Poster,"Conjoint measurement is a psychophysical paradigm in which an observer is presented with pairs of stimuli varying independently along several dimensions and is required to order them according to one of those dimensions. Including noise in the decision model makes it possible to estimate the respective contributions of each dimension by maximum likelihood, producing Maximum Likelihood Conjoint Measurement (MLCM). Knoblauch and Maloney (2012) have also shown that this analysis can be reformulated as a special case of the Generalized Linear Model (GLM) with a Bernoulli distribution. These analyses are simplified in R using the MLCM package. In most applications, the number of levels tested along each dimension is small, and they are treated as categorical variables, which ignores the continuous nature of the physical scales and underlying psychophysical functions. If a sufficient number of levels is tested for each dimension, this issue can be addressed by reformulating the problem as a Generalized Additive Model (GAM). A GAM is a penalized GLM resulting in a smooth curve defined by a regression spline where the complexity is constrained by a criterion related to cross-validation. We demonstrate the method using data from a gender comparison task in which the voices and faces of video stimuli varied through morphing along a gender continuum over nearly 20 levels. The use of GAM models is a promising approach for characterizing and testing the contributions of different stimulus dimensions to perception.",NA,poster,,rr2015
https://r2015-grenoble.sciencesconf.org/66074.html,Packages R pour la détection d'observations atypiques multivariées.,"Aurore Archimbaud, Anne Ruiz Gazen, Klaus Nordhausen",Poster,Dans ce poster nous souhaitons présenter certaines fonctions programmées dans différents packages de R et adaptées à la détection d'observations atypiques en multivarié. Les méthodes mises en oeuvre sont des méthodes de type projections révélatrices et certaines font appel à des estimateurs de matrices de covariances robustes. Nous présenterons des exemples d'application tirés de la statistique industrielle et insisterons sur les aspects graphiques.,NA,poster,,rr2015
https://r2015-grenoble.sciencesconf.org/66852.html,BIG-SIR a Sliced Inverse Regression Approach for Massive Data,Benoit Liquet,Big data,"In a massive data setting, we focus on a semiparametric regression model involving a real dependant variable Y, a $p$-dimensional covariable $X$. This model includes a dimension reduction of X via an index $X'\beta$. The Effective Dimension Reduction (EDR) direction $\beta$ cannot be directly estimated by the Sliced Inverse Regression (SIR) method due to the large volume of the data. To deal with the main challenges of analysing massive data set which are the storage and computational efficiency, we propose a new scalable estimator of the EDR direction by following the ``divide and conquer'' strategy. The data are divided into subsets. EDR directions are estimated in each subset which is a small dataset. The recombination step is based on the optimisation of a criterion which assesses the proximity between the EDR directions of each subset. Computations are run in parallel with no communication among them. The consistency of our estimator is established and its asymptotic distribution is given. Extensions to multiple indices models, $q$-dimensional response variable and/or SIR$_{\alpha}$-based methods are also discussed. Simulation study using our \texttt{edrGraphicalTools} \R package show that our approach enables us to reduce the computation time and conquer the memory constraint problem posed by massive data sets. A combination of \texttt{foreach} and \texttt{bigmemory} \R packages are exploited to offer efficiency of execution in both speed and memory. Finally, results are visualised using bin-summarise-smooth approach through the \texttt{bigvis} \R package.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66739.html,PARConnector : sans détour du Langage R au Cloud Big Data - Application à l'analyse Metagenomique,"Iyad Alshabani, Jean-Michel Batto, Magali Berland, Denis Caromel, Ndeye Aram Gaye, Emmanuelle Le Chatelier, Laurent Pellegrino, Nicolas Pons, Edi Prifti, Fabien Viale",Big data,"L'analyse quantitative du microbiote humain a été développé conjointement par l'équipe INRA-MetaGenoPolis (www.mgps.eu) dans le cadre du projet Européen MetaHIT (www.metahit.eu) qui impliquait 13 partenaires académiques et industriels. Cette approche explore l'information génomique des bactéries vivant dans le tractus digestif de manière globale et quantifiée. L'analyse repose sur ‘R' qui présente l'avantage d'avoir une gratuité et un vaste choix en modules et traitements. Dans un environnement de traitement HPC, l'orchestration permet de présenter à l'utilisateur une puissance de traitement sans en exposer la complexité sous-jacente. Nous présentons ici notre approche et les outils utilisés pour effectuer du traitement Big Data en lien avec la metagénomique quantitative à travers l'utilisation de l'orchestrateur open source ProActive. ",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66894.html,Rtkpp: Un package pour faire l'interface entre R et la bibliothèque STK++,Serge Iovleff,Big data,"STK++ (The Statistical ToolKit, http://www.stkpp.org) est une librairie écriteen C++ qui est développ\ée de manière continue depuis dix ans. Elle a connu un essor particuliérementimportant ces trois dernières années avec sa participation à plusieurs activité de valorisation etde transfert, en particulier par la création de packages R s'appuyant sur STK++.La dernière étape significative a consisté à la mettre à disposition de la communauté Rau travers du package rtkpp que nous détaillerons dans cette présentation.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/65912.html,Reporting automatisé avec ReporteRs et rtable,David Gohel,Logiciel R,"Encore aujourd'hui le format Microsoft reste un format de document prédominant au sein des sociétés. Le formatage des résultats d'étude est quant à lui une charge de temps importante pour les statisticiens. Le package ReporteRs et son extension rtable ont pour objet de permettre l'automatisation et la reproductibilité de ces opérations chronophages et sources d'erreur.   Le package ReporteRs permet la production de documents à partir de R. Il existe depuis février 2014 et sa communauté d'utilisateurs est devenue importante ; celle ci se compose majoritairement de sociétés touchant les sciences de la vie, l'économie et aussi un ensemble de consultants R fréquemment confrontés à une demande de reporting avancé. Parmi les fonctionnalités populaires, on trouvera une API complète de gestion des exports R tabulaires, graphiques et textuels, la production de graphiques éditables au format Microsoft et la gestion de modèles de documents.   Le package rtable est focalisé sur la production d'éléments tabulaires. Il permet notamment l'utilisation des objets du package xtable (reporting de modèles statistiques), offre une fonction de pivot et permet l'intégration native des tableaux produits dans les documents knitr ou dans les applications shiny.   Nous présenterons ces deux packages et illustreront leurs principales fonctionnalités au travers d'exemples simples. ",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66016.html,The Rsocialdata.network extension: Handling and analysing egocentric network survey data in R,"Emmanuel Rousseaux, Gilbert Ritschard",Divers,"This communication introduces the R package Rsocialdata.network. This package provides specific tools for dealing with network survey data in R. The package comes as an extension to the Rsocialdata package [1] by adding two new classes respectively designed to store (1) network survey variables (for instance emotional support, financial support, or conflict between family members) and (2) covariate variables describing members cited in the networks. These covariates generally include the family tie with the respondent as well as demographic variables: for instance gender, age, marital status, or education level. The framework allows to store network survey variables in one single variable instead of separated variables usually stored in a tabular form. All Rsocialdata features for survey data management are available, for instance the distinction between valid cases and missing values, handling several different missing value types, and a variable description. Most common network measures (centrality, density, in/out-degree, etc.) can directly be computed without any additional recoding or data preparation. Furthermore, the user has the possibility to link network variables with corresponding network covariate data. Specifically, the main features of the package are the net_extract and net_query functions. The net_extract function allows to stem new networks from existing networks using information from covariate variables. For instance, the user can generate a new network variable by removing for each respondent links coming from her/his father in one single step. This is particularly useful to assess the role played by a specific actor on the structure on the network (assessed for instance by the density or the in/out-degree). The net_query function offers facilities to easily retrieve networks based on criteria from both network and covariate information. For example the user can, in one single step, select networks based on the following properties: (1) the father is cited by the respondent (2) the father has a low education, and (3) the density of the network is lower than 0.2. This is particularly useful to model a hypothesis and generate dummies to be tested in regression models. We start this communication by introducing existing packages dealing with network data in R and motivating the development of this extension. Then we introduce the design of the package before to illustrate the package with an application on family configuration of the elderly in the Canton of Geneva, Switzerland. The package is currently available from the R-Forge.   [1] Rousseaux E., Bolano D. and Ritschard G. (2013), ``The Rsocialdata package: Handling survey data in R'', In XXVII IUSSP International Population Conference, Busan, Republic of Korea, August 26th to 31th, 2013.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/61202.html,«MTK» : un package pour unifier les démarches d'exploration numérique de modèles,"Juhui Wang, Hervé Monod, Robert Faivre, Hervé Richard",Divers,"L'exploration numérique de modèles couvre un très large spectre de méthodes allant de la planification d'expérience à l'analyse de sensibilité en passant par la propagation d'incertitude, la calibration, l'optimisation, etc. Due à la complexité croissante des modèles, elle est aujourd'hui devenue un outil indispensable des modélisateurs. D'ailleurs, de nombreux packages sous R lui sont consacrés : sensitivity, diceDesign, lhs, planor, multisensi, FME, puma, etc. Cependant, face à une offre en méthodes et en logiciels de plus en plus riche et en constante évolution, il est difficile pour un non-spécialiste de s'y retrouver, même pour des méthodes relativement simples. C'est dans ce contexte que le projet « mtk » a été développé. Il a pour but de rassembler l'ensemble des méthodes d'exploration numérique de modèles (existantes et à venir) dans un environnement générique, et ce avec une démarche unifiée et une syntaxe standardisée. Il peut être soit intégré dans les plateformes de modélisation, soit utilisé directement sous R.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66023.html,ClustInvest : outils pour l'analyse et l'interprétation de classifications nonsupervisées avec variables binaires. Application à des données d'accidents de décompression,"Gérard Grégoire, Jean-Pierre Imbert",Classification,Nous proposons un package R pour l'analyse et l'interprétation de classifications sur données binaires. Le package est utilisé pour étudier un jeu de données d'accidents de plongée où les variables sont les différents symptômes que peut présenter l'individu accidenté.,NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66097.html,Paquet R pour l'estimation d'un mélange de lois de Student multivariées à échelles multiples.,"Alexis Arnaud, Florence Forbes, Benjamin Lemasson, Emmanuel Barbier",Classification,"L'utilisation d'un modèle de mélange de lois est une approche statistique classique en classification non-supervisée. Un mélange fréquemment utilisé pour sa simplicité est le mélange gaussien. Cependant, un tel modèle est sensible aux données atypiques. Pour remédier à cela, nous présentons ici le mélange de lois de Student multivariées à échelles multiples, que nous sommes en train d'incorporer au sein d'un paquet R. Une classification multivariée avec des lois de Student à échelles multiples permet de retrouver des classes alongées. En effet, ces lois peuvent gérer des queues de lourdeurs différentes selon les directions alors que les lois gaussiennes et les lois de Student multivariées standards sont contraintes à être symétriques.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66136.html,Le package ClustGeo : Classification ascendante hiérarchique avec contraintes de proximité géographique,"Amaury Labenne, Marie Chavent, Vanessa Kuentz-Simonet, Jérôme Saracco",Classification,"La Classification Ascendante Hiérarchique (CAH) est une méthode bien connue de classification d'individus décrits par différentes variables. Cette méthode vise à rassembler dans une même classe les individus qui se ressemblent du point de vue des variables. Cependant lorsque les individus dont on dispose sont des territoires géographiques, on souhaite parfois que des individus proches géographiquement se retrouvent dans la même classe sans que cela ne nuise trop à la qualité de la partition. La méthode ClustGeo que nous avons développée permet d'intégrer des contraintes de proximité géographique au sein d'une CAH, pour cela on utilise le critère d'homogénéité de Ward sur deux matrices différentes de distances.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/64276.html,funFEM: an R package for functional data clustering,"Charles Bouveyron, Julien Jacques",Classification fonctionnelle,This paper presents the funFEM package for R which implements a new clustering algorithm for times series (or more generally functional data). This algorithm is based on a functional mixture model which allows the clustering of the data in a discriminative functional subspace. Such model presents the advantage to be parsimonious and to allow the visualization of the clustered systems.,NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/64448.html,kmlShape : un algorithme de partitionnement des données longitudinales basé sur la forme des trajectoires,Christophe Genolini,Classification fonctionnelle,"Les données longitudinales sont des données dans lesquelles chaque variable est mesurée àplusieurs reprises au cours du temps. Une possibilité pour analyser ce genre de données consisteà les partitionner. La majorité des méthodes de partitionnement classent deux individusensemble si leurs trajectoires sont proches à chaque temps de mesure. Ce type de méthode prenden compte les ressemblances locales mais ne tient pas vraiment compte de la forme généraledes trajectoires. Or, dans un certain nombre de situations, l'évolution d'un phénomène peutavoir plus d'importance que son moment d'apparition. On souhaite dans ces situations pouvoirpartitionner en classant dans le même groupe des individus dont les trajectoires ont des formessimilaires, indépendamment d'un décalage dans le temps. kmlShape est un package permettant de partitionner des données longitudinales en fonction de leur forme, indépendament du moment précis de l'apparition d'un évènement.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66037.html,MRIaggr : un package pour la gestion et le traitement de données multivariées d'imagerie,Brice Ozenne,Big data,"L'imagerie médicale a connu essor considérable au cours des vingt dernières années, notamment en Imagerie par Résonance Magnétique (IRM) avec le développement d'une multitude de séquences sur lesquelles sont basés le diagnostic et l'étude de nombreuses maladies. Ces séquences donnent accès à des paramètres de contraste qui fournissent différentes caractérisations de la zone observée: présence d'une tumeur, irrigation sanguine ou activité neuronale. L'utilisation conjointe de ces informations a trouvé de nombreuses applications [1-3] mais sa mise en place est rendue difficile par le volume d'informations à gérer.  Sous R, des packages de manipulation de données d'imagerie existent mais uniquement pour des images uni-paramétriques. Or utiliser un objet par patient et par paramètre de contraste devient rapidement difficile même avec un nombre limité de patients et de paramètres. De plus, en amont de l'analyse, il est souvent nécessaire d'effectuer des traitements pour identifier les zones d'intérêt, normaliser les valeurs de paramètre ou améliorer le rapport signal sur bruit.  Le package MRIaggr (contraction de 'MRI data aggregation') introduit une nouvelle classe d'objets MRIaggr permettant d'agréger l'ensemble des données d'imagerie IRM relatif à un patient ainsi que d'éventuelles métadonnées (données cliniques, résolution spatiale, ...). La création d'un objet MRIaggr est facilitée par la fonction constMRI qui transforme une liste d'objets image (array, Nifti, Analyse ou Dicom) en un objet MRIaggr. Le package fournit plusieurs fonctions de traitement d'image classiquement implémentées dans les librairies de traitement d'images (segmentation, filtrage, reconnaissance morphologique, normalisation) dont certaines sont spécifiques à l'analyse d'images cérébrales. Ces fonctions peuvent automatiquement mettre à jour l'objet avec les résultats obtenus. Des fonctions facilitant l'accès aux données et la visualisation sont aussi disponibles, voir la figure 1 pour une vue d'ensemble des fonctionnalités du package. Le package est disponible sur le CRAN (R≥3.1.3). L'exposé consistera en une présentation de la classe MRIaggr puis de son utilisation depuis l'import des données jusqu'à la visualisation des résultats. L'illustration se fera sur des données IRM d'un patient atteint d'un Accident Vasculaire Cérébral. Ces données sont inclues dans le package.",NA,oral,,rr2015
https://r2015-grenoble.sciencesconf.org/66166.html,LEA : un package R pour la génomique des populations,Olivier Francois,Big data,Voir le fichier déposé.,NA,oral,,rr2015
https://r2018-rennes.sciencesconf.org/207527.html,Tools and methods for model-based clustering in R,Bettina Grün,Invitée,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/205405.html,Les Addins RStudio,Victor Perrier,R extensions,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/194247.html,Maîtrise Augmentée du Réseau par Intelligence Artificielle,Pierre Rebours,R extensions,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/204125.html,Construction et déploiement d'applications web basées sur R,Alassane Samba,R extensions,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/207764.html,"Conversion d'une équipe à une méthode de travail plus efficace et fiable : autour de R (RMarkdown, Git et packages)",Eric Marcon,Invitée,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/204540.html,VarSelLCM: an R/C++ package for variable selection in model-based clustering of mixed-data with missing values,"Matthieu Marbac, Mohammed Sedki",Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/208119.html,Outil d'interprétation de score,Benoit Thieurmel,Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/206667.html,"Begin'R, Un projet collaboratif pour l'enseignement de R","Robin Genuer, Perrine Soret, Marthe-Aline Jutand, Jean-Pierre Da Costa, Florent Arnal, Raphaëlle Savoire, Marie Lebreton, Cecile Dantzer, Jerome Saracco, Lionel Bombrun, Sébastien Moutault",Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/208125.html,Modélisation de taux de défaillance par composante des départs Basse Tension,"Benoît Ravel, Odilon Faivre",Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/205545.html,tripdown : un package pour créer des blogs de voyage,Cécile Sauder,Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/205510.html,ergo: interface entre R et Go,Romain Francois,Packages et interactions,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/202993.html,Notre système de revue de paquets en revue : présenter et analyser rOpenSci onboarding,Maëlle Salmon,Données et interfaces,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/205552.html,Fabriquer un package R en moins de 6 minutes,Diane Beldame,Données et interfaces,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/203758.html,ASICS: un package R pour l'identification et la quantification de métabolites dans un spectre RMN 1H,"Gaëlle Lefort, Laurence Liaubet, Cécile Canlet, Nathalie Villa-Vialaneix, Rémi Servien",Inférence et bioinfo,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/208341.html,Stochastic approximation EM for logistic regression with missing values,"Wei Jiang, Julie Josse, Marc Lavielle",Inférence et bioinfo,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/204748.html,RNAseqNet : un package pour l'inférence de réseaux à partir de données RNA-seq,"Alyssa Imbert, Nathalie Villa-Vialaneix",Inférence et bioinfo,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/204775.html,"Bibliométrie, Contrôle qualité et production d'indicateurs, automatisation sous R","Sylvain Cariou, Lise Frappier",Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/204051.html,Vous allez aimer avoir {purrr},Colin Fay,Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/205791.html,L'analyse de séquences (TraMineR) et de survie (survival) : identifier des trajectoires de vie puis en repérer les facteurs déterminants,Luc-Olivier Hervé,Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/204807.html,"Dégun sait ce qui va se passer... Allez, vaï, industrialisons R !",Félix Rougier,Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/202749.html,Clustering avec R Application sur les données des eaux embouteillées commercialisées en Algérie,Yamina Khemal-Bencheikh,Poster,NA,NA,poster,,rr2018
https://r2018-rennes.sciencesconf.org/202990.html,Capturez votre écran depuis R !,Maëlle Salmon,Poster,NA,NA,poster,,rr2018
https://r2018-rennes.sciencesconf.org/203342.html,"Introduction de nouveaux outils (learnr, bookdown, machine virtuelle, Github Classroom, . . . ) dans un cours de Science des Données Biologiques","Guyliann Engels, Philippe Grosjean",Poster,NA,NA,poster,,rr2018
https://r2018-rennes.sciencesconf.org/203471.html,FOREST OF PERFECT TREES,"Jean-Michel Nguyen, Aurelie Gaultier, Daniel Antonioli",Poster,NA,NA,poster,,rr2018
https://r2018-rennes.sciencesconf.org/204168.html,5 packages inutiles donc indispensables,Vincent Guyader,Poster,NA,NA,poster,,rr2018
https://r2018-rennes.sciencesconf.org/204214.html,Analyse Factorielle des Correspondances sur données liées à l'évaluation des étudiants à l'université,Smail Gueddou,Poster,NA,NA,poster,,rr2018
https://r2018-rennes.sciencesconf.org/204725.html,dad : package pour l'analyse de données multi-groupes via les densités de probabilité associées,"Rachid Boumaza, Pierre Santagostini, Smail Yousfi, Sabine Demotes-Mainard",Poster,NA,NA,poster,,rr2018
https://r2018-rennes.sciencesconf.org/204780.html,Un outil pour l'importation dans R de données d'architecture de plantes,"Pierre Santagostini, Rachid Boumaza, Smail Yousfi, Sabine Demotes-Mainard",Poster,NA,NA,poster,,rr2018
https://r2018-rennes.sciencesconf.org/204888.html,Modélisation de la propagation de l'infection sur une feuille de chou à partir d'images de fluorescence de chlorophylle,"Pierre Santagostini, Besnik Pumo, Etienne Belin, Tristan Boureau, Claire Campion, Céline Rousseau",Poster,NA,NA,poster,,rr2018
https://r2018-rennes.sciencesconf.org/208060.html,Comparaison de méthodes d'analyses multivariées pour la description de données de germination de semences,"Ophélie Thierry, Rachid Boumaza, Julia Buitink, Claudine Landes, Olivier Leprince, Pierre Santagostini, Julie Bourbeillon",Poster,NA,NA,poster,,rr2018
https://r2018-rennes.sciencesconf.org/208083.html,Introduction to the MultiVarSel package,Marie Perrot-Dockès,Poster,NA,NA,poster,,rr2018
https://r2018-rennes.sciencesconf.org/208354.html,AriCode un package R pour calculer efficacement l'ARI et d'autres mesures pour comparer des classifications.,"Guillem Rigaill, Julien Chiquet, Valentin Dervieux",Poster,NA,NA,poster,,rr2018
https://r2018-rennes.sciencesconf.org/207525.html,Une introduction au deep learning,Romain Tavenard,Invitée,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/205163.html,Système de recommandation interactif pour l'analyse de données médicales,"Joris Falip, Frédéric Blanchard",Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/204838.html,R via SAS : Tirer profit de R au sein d'une chaîne de traitement SAS,Louis Pecourt,Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/204440.html,"R++, the Next Step : une nouvelle interface graphique pour R",Christophe Genolini,Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/203468.html,Package ROP: Arbres à noeuds multivariés,"Jean-Michel Nguyen, Aurelie Gaultier, Daniel Antonioli",Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/206588.html,XLSTAT-R – Création de connecteurs entre R et XLSTAT pour une interface conviviale et aisément modifiable,Thierry Fahmy,Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/204368.html,Incorporating bad outputs in non-parametric frontier models,"K Hervé Dakpo, Yann Desjeux, Laure Latruffe",Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/207528.html,Clustering des noeuds d'un réseau dans le cadre des Stochastic et Latent Blockmodels,Jean-Benoist Léger,Invitée,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/204009.html,Les SIG et la cartographie avec {sf} & Co.,Sébastien Rochette,Données et interfaces,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/201976.html,Manipulation de données communales en historique avec le package COGugaison,Kim Antunez,Données et interfaces,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/204778.html,queryMed : enrichissement des données de recherche en pharmaco-épidémiologie,"Yann Rivault, Olivier Dameron, Nolwenn Le Meur",Données et interfaces,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/208340.html,Inférence de modèle à blocs stochastiques en présence de données manquantes,"Timothée Tabouy, Pierre Barbillon, Julien Chiquet",Distributions et simulations,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/202273.html,funHDDC : extension du package R pour le clustering de courbes fonctionnelles multivariées,"Amandine Schmutz, Julien Jacques, Charles Bouveyron, Laurence Chèze, Pauline Martin",Distributions et simulations,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/204261.html,Nouveaux graphes d'ajustement pour les données censurées dans le package fitdistrplus,"Marie Laure Delignette-Muller, Christophe Dutang, Aurélie Siberchicot",Distributions et simulations,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/205308.html,Génération de documents Microsoft Office avec le package officer,David Gohel,R workflow,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/204167.html,"""Introduction au 'tidyeval' (ou comment programmer dans le {tidyverse})",Vincent Guyader,R workflow,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/203305.html,Est-il possible d'améliorer encore la courbe d'apprentissage de R au delà de tidyverse? Les packages flow et chart.,"Philippe Grosjean, Guyliann Engels",R workflow,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/199664.html,Une application Shiny pour prédire dynamiquement la survie patient-greffon d'un patient transplanté rénal : vers une décision médicale plus partagée,"Marie-Cécile Fournier, Florent Le Borgne, Yohann Foucher, Magali Giral, Etienne Dantan",Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/208248.html,Un Utilitaire SHINY pour la Modélisation et l'Analyse Statistique de Données de Défaillance de Cause Commune en Fiabilité,"Yacouba Kone, Pima Bazié, Augustin Zoungrana",Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/202411.html,Etude de la démographie française du XIXe siècle à partir de données collaboratives de généalogie,"Ewen Gallic, Arthur Charpentier",Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/208088.html,La Fragilité en EHPAD. Construction et Evaluation d'un Syndrome.,Tiba Delespierre,Lightning,NA,NA,lightning talk,,rr2018
https://r2018-rennes.sciencesconf.org/208042.html,From the knapsack problem to drawing metro maps - mixed integer linear programming in R,Dirk Schumacher,Invitée,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/203798.html,Depth and depth-based classification with R package ddalpha,"Oleksii Pokotylo, Pavlo Mozharovskyi, Rainer Dyckerhoff, Stanislav Nagy",Statistique et analyse de données,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/207963.html,Analysis of Variance for functional data using the R package ERP,David Causeur,Statistique et analyse de données,NA,NA,oral,,rr2018
https://r2018-rennes.sciencesconf.org/204185.html,The R package bigstatsr: Memory- and Computation-Efficient Statistical Tools for Big Matrices,Florian Privé,Statistique et analyse de données,NA,NA,oral,,rr2018
https://rr2023.sciencesconf.org/468075,De R Markdown à Quarto sans effort pour aller plus loin avec ses publications.,Christophe Dervieux,français,"Ce tutoriel propose de découvrir comment Quarto reprend et repense les fonctionnalités de l'écosystème R Markdown, en passant de plusieurs packages R à un seul et unique outil. Quarto propose les fonctionnalités de R Markdown remaniées (cross references, article layout, gestion des figures, ...) ainsi que de multiple formats (document HTML & PDF, site web, présentation HTML, ... ). Tout en ajoutant des nouvelles fonctionnalités pour une meilleure flexibilité et collaboration (modification facile d'un thème HTML, mécanisme d'extensions, projet collaboratif facilité, ...) Dans quel cas et pourquoi passer de R Markdown à Quarto ? Comment faire la transition sur des projets existants ?Comment démarrer un nouveau projet avec Quarto ? C'est ce que nous allons aborder dans ce tutoriel de 2h.",Tutoriel Quarto,Tutoriel,"quarto, rmarkdown, publication, reproductibilité",rr2023
https://rr2023.sciencesconf.org/464104,Créer un pipeline de machine learning complet avec {tidymodels},"Antoine Bichat, Julie Aubert",français,"Tidymodels regroupe un ensemble de packages facilitant l'utilisation de méthodes d'apprentissage statistique (telles que les forêts aléatoires, modèles linéaires bayésien ou non...) dans un cadre unifié et ""tidy"".Ce tutoriel vous montrera comment utiliser ces packages pour prétraiter les données, construire, entraîner et évaluer un modèle, optimiser des hyperparamètres et tout ce que vous devez savoir pour mener de bout en bout un projet d'apprentissage statistique supervisé.   Tidymodels gathers a set of packages facilitating the use of statistical learning methods (such as random forests, Bayesian or non-Bayesian linear models...) in a unified and ""tidy"" framework.This tutorial will show you how to use these packages to preprocess data, build, train and evaluate a model, tune hyperparameters and everything you need to know to run a complete supervised machine learning pipeline.",Tutoriel ML,Tutoriel,"machine learning, statistiques, tidymodels",rr2023
https://rr2023.sciencesconf.org/462116,Statspatial : Analyse spatiale et cartographie avec R,"Kim Antunez, Etienne Côme",français,"Ce tutoriel propose une introduction aux principaux packages et outils disponibles dans l'éco-système R pour manipuler des données spatiales et réaliser des cartes thématiques, avec un focus sur les données vectorielles.  Une large place sera consacrée à la prise en main du package sf et à la réalisation de géotraitements simples. Nous aborderons également la réalisation de cartes thématiques statiques avec ggplot2 et mapsf ainsi que l'utilisation de mapview pour réaliser facilement des cartes interactives d'exploration de données. Enfin, une courte ouverture vers des outils et questions plus spécifiques complètera cette introduction : données rasters, lissage spatial, géocodage, données Open Street Maps, réseaux géographiques, ...   La majorité de l'atelier sera consacrée à une mise en application des différents concepts et outils sur la base de données annuelle des accidents corporels de la circulation routière.  ",Tutoriel StatSpatial,Tutoriel,"Statistique spatiale, Cartographie",rr2023
https://rr2023.sciencesconf.org/465770,Tips pour combattre le syndrome de l'imposteur,Aurélie Vache,français," Qui n'a pas un jour prononcé la phrase : J'ai l'impression d'être un imposteur ? Je ne me sens pas légitime de faire ceci ou de faire cela ? Certaines personnes sont persuadées qu'elles ne méritent pas leur succès, malgré les efforts qu'elles fournissent pour réussir. Elles s'auto-persuadent souvent que leur réussite n'est pas liée à leur travail, leur accomplissement personnel, mais tout bonnement à la chance ou bien au travail des autres. De fait, elles vivent en permanence avec un sentiment de duperie et craignent sans cesse que quelqu'un ne les démasque d'un jour à un autre. Dans ce talk nous ferons un retour sur ce qu'est le syndrome de l'imposteur, comment il se reflète au quotidien et nous verrons que ce n'est pas une fatalité, au contraire, qu'il existe des tips et astuces pour le combattre, se dépasser et s'améliorer. ",Keynote I,Keynote,developpement personnel,rr2023
https://rr2023.sciencesconf.org/468014,"DeCovarT, a R package for a robust deconvolution of cell mixture in transcriptomic samples using a multivariate Gaussian generative framework","Bastien Chassagnol, Etienne Becht, Gregory Nuel, Yufei Luo",anglais,"Transcriptomic analyses have contributed greatly to a better understanding of the biologicalprocesses involved in the evolution of complex and versatile diseases. However, bulktranscriptomic analyses ignore the heterogenous contribution of diverse cell populations tosamples heterogeneity. Thus, computational deconvolution methods have been developed toanalyse the cellular composition of tissues. However, the performance of these algorithms islimited in distinguishing between cell populations with very similar expression profiles, and wehypothesised that integrating the covariance between genes could enhance the performance ofdeconvolution algorithms for closely related cell populations. We therefore developed a newdeconvolution algorithm, DeCovarT, which takes into account the transcriptomic networkstructure of each cell population. To do so, we represented the set of transcriptomicinteractions as a multivariate Gaussian distribution, assuming a sparse network structurededuced from the precision matrix returned by the gLasso algorithm. Next, we reconstructthe overall mixing profile by a generative model, in which we show, under reasonableassumptions, that the law describing the overall expression profile conditional on the cell ratiosand purified expression profiles also follows a multivariate Gaussian distribution. Themaximum likelihood estimate (MLE) of the associated function, i.e. the cell ratios optimisingthe probability of observing the observed transcriptomic distribution, is estimated in ourpaper by first reparametrising the log-likelihood function into an unconstrained version andthen optimising it by consecutive iterations of the Levenberg-Marquardt algorithm. Thisallows us to obtain an estimator that respects the simplex constraint and to derive thecorresponding asymptotic confidence bands. In addition to the introduction of a newstatistical modelling paradigm, we plan in our presentation to briefly review the standardoptimisation methods implemented in R with their specific features and main restrictions.Notably, we benchmarked them on a toy example that highlights strong behaviouraldifferences in the context of constrained optimisation.",Lightning I,Présentation courte,"cellular deconvolution, gLasso, generative model, bulk RNA Sequencing, Levenberg, Marquard, constrained optimisation",rr2023
https://rr2023.sciencesconf.org/469986,CGI – Permettre à de nouveaux utilisateurs de R de créer des graphiques respectant les contraintes de son institut,Jean Dupin,français,"Dans le cadre du renouvellement de la charte graphique de l'Insee en 2021 et de l'abandon progressif de SAS depuis 2022, l'initiative a été prise de proposer un package R répondant à 2 problématiques :  1) Permettre de produire des figures respectant les contraintes graphiques de l'Insee.  2) Être facilement utilisable et mobilisable pour des agents n'ayant pas (ou peu) de connaissances avec l'outil R, lesquels privilégient aujourd'hui Calc. C'est dans ce cadre que le package CGI (pour Charte Graphique de l'Insee) a été développé, avec comme ambition de proposer une syntaxe plus claire pour des utilisateurs qui ne sont pas habitués à la grammaire de ggplot2.",Lightning I,Présentation courte,"Package, Design, Visualisation",rr2023
https://rr2023.sciencesconf.org/470111,Applications Shiny pour le suivi de systèmes agricoles et environementaux.,"Thierry Faure, Loris Croce, Gil De Sousa",français,"Le développement d'applications Shiny pour le suivi des activités agricoles ou la surveillance del'environnement est un domaine en pleine expansion. Couplé à un système d'acquisition basé sur des objetsconnectés déployés dans le cadre de l'Internet des Objets (IdO), ces applications permettent d'intégrer desdonnées agricoles et environnementales en temps réel, de les prétraiter, de les visualiser et de les d'effectuer desanalyses statistiques avec R. Nous illustrons cela par différents cas d'usage que l'on pourrait classer en deuxcatégories (Elijah et al. 2018). La première catégorie concerne des applications à base de données multimédia.La seconde catégorie concerne l'intégration et l'analyse de données “scalaires”, comme des températures,collectées par des objets connectées. L'intégration dans une application Shiny permets à la fois de col-lecter, visualiser et de traiter les données. Ces traitements peuvent être réalisés en mode offline ou en temps réel.",Lightning I,Présentation courte,"application Shiny, IoT, traitement, visualisation et analyse de données",rr2023
https://rr2023.sciencesconf.org/468083,"Camtrapviz, une interface Shiny pour visualiser les données de pièges photographiques","Lisa Nicvert, Hervé Fritz, Stéphane Dray",français,"Les pièges photographiques sont des appareils photos à déclenchement automatique généralement installés en milieu naturel pour étudier la distribution des espèces animales. Leur fonctionnement automatisé permet de surveiller la biodiversité sauvage en minimisant le dérangement causé. Pour cette raison, les pièges photographiques sont de plus en plus utilisés en écologie. Les données de présence des espèces animales ainsi récoltées présentent un intérêt pour les chercheurs et chercheuses en écologie, mais aussi les gestionnaires ou les associations. Or, parmi ces publics, certaines personnes ne sont pas formées à l'analyse de données ou à la programmation. Par ailleurs, même pour celles et ceux qui le sont, écrire un script pour visualiser les données peut s'avérer coûteux en temps et en énergie. Pour faciliter la visualisation des données de pièges photos, nous développons le package R camtrapviz. Le code de ce package (en développement) est disponible à l'adresse suivante : https://github.com/LisaNicvert/camtrapviz. Ce package permet d'importer des données d'occurrence récoltées à partir de pièges photos (au format de tableaux) et de les visualiser de façon interactive grâce à une application Shiny. L'interface permet de visualiser quelques indicateurs sur ces données (comme les différentes espèces capturées ou la durée d'activité des pièges photos), et d'effectuer des analyses préliminaires courantes (comme obtenir la fréquence à laquelle les espèces ont été vues pour chaque piège). Ce package a deux objectifs. Tout d'abord, il permet de visualiser simplement les données avec l'interface Shiny sans nécessiter de compétences particulières en programmation R. Pour que l'analyse faite dans l'interface Shiny soit reproductible, il est également possible d'exporter le code R permettant de reproduire les analyses. Par ailleurs, pour les utilisateurs et utilisatrices de R, ce package fournit également des fonctions permettant de pré-traiter et de visualiser les données de pièges photos.",Lightning I,Présentation courte,"visualisation de données, Shiny, package R, écologie, pièges photographiques",rr2023
https://rr2023.sciencesconf.org/465497,{crosstable} : décrivez vos datasets en quelques lignes,Dan Chaltiel,français,"C'est le quotidien de presque tous les statisticiens et de beaucoup de data-scientists, il faut toujours et encore décrire ses données. Avec {crosstable}, il est possible de décrire complètement un dataset entier en quelques lignes de code seulement. Mieux, il existe une myriade d'options pour que le résultat soit le plus personnalisé possible. Le résultat est une dataframe classique, mais tout est pensé pour facilement la transformer en table exportable (flextable, gt, Excel, Word...). Il est possible de pivoter et de transposer les crosstables, ce qui facilite grandement la description de certaines bases. {crosstable} intègre également plusieurs helpers pour utiliser les options, gérer les labels de colonnes, et s'interfacer avec le package {officer}. La documentation est très détaillée et disponible sur GitHub. S'il existe déjà plusieurs packages pour l'analyse descriptive, notamment {gtsummary} et {table1}, {crosstable} se pose dans la complémentarité en termes d'interface (mais aussi parfois de performances). Testez-les tous et choisissez votre préféré !",Lightning I,Présentation courte,Package – Statistique – épidémiologie – Biostatistique – Description – Data – Dataset,rr2023
https://rr2023.sciencesconf.org/469024,Comment bien rater votre forge logicielle R ?,Vincent Guyader,français,"Installer, configurer et maintenir une infrastructure R est un défi en soi. Les équipes IT ont du mal à comprendre les besoins des utilisateurs, les utilisateurs ne savent pas toujours ce qui est bon pour eux, et R a des spécificités qui font que cela ne se passe presque jamais bien du premier coup.Cette présentation contient tout ce que vous devez savoir pour mal configurer votre forge logicielle R. Autrement dit, on présentera les erreurs classiques rencontrées lors de la mise en place de serveurs de développement R.Vous apprendrez tout ce qu'il faut faire pour vous assurer de rester bloqué sur une version obsolète de R pendant des années. Nous parlerons de l'indispensable package métier dont on n'a plus les sources et qui ne peut être installé que sur un Windows 32 bits.Bien entendu, nous verrons aussi les fausses bonnes idées qui, ""pour des raisons de sécurité"", aboutissent à imposer aux utilisateurs de faire des copier-coller de RStudio vers Putty. Sans oublier ce package que personne ne doit mettre à jour au risque de ""tout casser en prod"".Un regard bienveillant sur les problèmes réels rencontrés ces dernières années quand il s'agit de rendre R disponible à ses utilisateurs, quelle que soit la taille des structures.",Infra I,Présentation longue,"Infrastructure, Workbench",rr2023
https://rr2023.sciencesconf.org/468181,RKeOps v2: Kernel operations with Symbolic Tensors on the GPU in R,"Amélie Vernay, Benjamin Charlier, Ghislain Durif, Chloé Serre-Combe",anglais,"We present RKeOps version 2, a binder in R for the KeOps library which implements ""kernel operations on the GPU, with autodiff, without memory overflows"". The RKeOps package allows the user to seamlessly perform fast and memory-efficient kernel computations, based on symbolic matrix operations, such as kernel matrix reductions, convolutions or nearest neighbor search, involving large datasets (up to 1E7 points), on CPU or GPU without any additional development cost. The main contribution of this work is to provide the LazyTensor abstraction directly in R, allowing to write tensor operations similarly to R native syntax for vector and matrix operations, greatly simplifying the user experience.",Infra I,Présentation longue,"Kernel operations, Matrix reduction, GPU, Symbolic matrix operations, Computational statistics",rr2023
https://rr2023.sciencesconf.org/465431,"MongoDB - J'suis pas venu ici pour souffrir, ok ?",Colin Fay,français,"La grande force de MongoDB, c'est sa flexibilité extrême. La grande faiblesse de MongoDB, c'est sa flexibilité extrême. De prime abord, quand on travaille avec R, on opte pour les bases de données tabulaires, celles que l'on classe dans la grande famille du SQL. Pour une raison inconnue, Colin a au contraire été souvent confronté à des projets de production où la base de données disponible était en NoSQL — notamment en MongoDB. Le résultat ? Un syndrome post traumatique lié à une bataille sans relâche contre des données non structurées, avec pour seule arme un langage qui n'est pas équipé pour maitriser efficacement le chaos du NoSQL. Alors, que faire ? Renoncer ? Se résigner ? Continuer à monter au front ? Embrasser l'adversité et faire de cette flexibilité un atout ? Dans ce talk, Colin viendra raconter l'histoire de sa bataille avec MongoDB depuis R, un parcours semé d'embuches et de listes de listes, un chemin de croix fait de hauts, de bas, mais aussi et surtout de découvertes sur le potentiel inexploité de MongoDB quand on fait du R.",Infra I,Présentation longue,"Package, Base de données, production, krav maga",rr2023
https://rr2023.sciencesconf.org/468051,Comment Shiny aide Enedis à contribuer à la transition énergétique pour les collectivités territoriales,Gabrielle Devaux,français,"Sujet : De l'expérimentation à l'industrialisation, Enedis utilise Shiny dans la création de prototypes d'applications aidant à la transition énergétique. L'application CAP'TEN (CAP sur la Transition ENergétique) est une cartographie des capacités d'accueil du réseau électrique ENEDIS, permettant la simulation d'installation de projets de panneaux solaires, éoliennes, et bornes de recharges pour véhicules électriques.   Initialement une petite étude R pour calculer des bilans électriques, CAP'TEN est aujourd'hui une application industrialisée (back-end SCALA, front-end Angular), accessible depuis le portail Enedis Collectivités et Entreprises depuis 2022.   La version expérimentale a été réalisée en R et R Shiny entre 2019 et 2021. Ces trois années de développement ont permis de produire et optimiser un prototype répondant aux besoins suivants :  Scénariser les trajectoires possibles de transition écologique d'un territoire   Détecter les opportunités de raccordement (consommation et production) au réseau, et anticiper les contraintes de capacité du réseau.   Collecter des retours utilisateurs pour créer un prototype final avant industrialisation du projet      Contributeurs du projet :  Gabrielle Devaux, développement Shiny   Abalrhaman Shlash, développement Shiny   Florian Henot, modèle statistique   Emmanuelle Vanet, modèle statistique   Pierre Achaichia, chargé de projet   Mohamed Rhaima, analyste fonctionnel et maquettes  ",Shiny/plumber I,Présentation courte,"Statistique spatiale, Visualisation, Cartographie",rr2023
https://rr2023.sciencesconf.org/460150,"glitter makes SPARQL: glitter, un package R pour explorer et collecter des données du web sémantique","Lise Vaudor, Maëlle Salmon",français,"Les données du web sémantique sont formalisées selon un modèle en graphe de triplets RDF. Elles nécessitent, pour être collectées depuis les endpoints dédiés (e.g. Wikidata, dbpedia, HAL, etc.) l'élaboration de requêtes dans un langage dédié: SPARQL. Ce langage, qui est aux données du web sémantique ce que SQL est aux bases de données relationnelles, a ainsi un objectif très spécifique et demeure assez méconnu des utilisateur·rice·s de données. Au contraire, R est un langage de programmation assez généraliste puisqu'il permet de gérer de nombreux aspects de la chaîne de traitements de données, depuis leur recueil jusqu'à leur valorisation (par des modèles, graphiques, cartes, rapports, applications, etc.).Le package glitter permet aux utilisateur·rice·s de R sans connaissance préalable de SPARQL d'explorer et collecter les données du web sémantique. Par des commandes R inspirées du tidyverse et ainsi selon un langage spécifiques à un domaine (DSL), l'utilisateur peut générer des requêtes SPARQL, les envoyer aux points d'accès de son choix, et recueillir les données tabulaires correspondantes. Ces étapes sont ainsi intégrées à l'environnement R dans lequel l'utilisateur·rice peut également réaliser les étapes d'analyse et de valorisation des données, dans une chaîne de traitement reproductible.Lors de cette présentation, nous montrerons les principales fonctionnalités du package glitter* à partir d'exemples. Le package est toujours en développement mais il est fonctionnel, documenté et peut être installé par les participant·e·s qui souhaitent le tester en suivant les instructions décrites sur [cette page](https://lvaudor.github.io/glitter/).",Shiny/plumber I,Présentation longue,"Web sémantique, Linked Open Data, RDF, SPARQL, Wikidata, tidyverse, Package",rr2023
https://rr2023.sciencesconf.org/468295,"Vigie-Analyse, des applications shiny pour les scol'R",Simon Benateau,français,"Vigie-Nature École est un programme de sciences participatives. Nous proposons à des élèves (de la maternelle au lycée) de suivre des groupes d'espèces afin de travailler autrement les questions d'écologie et de récolter des données pour la recherche.Ce programme est aussi une formidable opportunité de faire travailler les élèves non seulement sur les données qu'ils ont eux-mêmes produites mais aussi sur l'ensemble des données collectées par les établissements participants. Nous proposions des données tabulées directement téléchargeables sur notre site web mais face aux difficultés de manipulation des logiciels classiques et à la quantité de données présente dans nos bases, deux applications shiny ont été développées. L'une permet de répondre à des questions scientifiques de manière guidée et présente un workflow d'analyse le plus simplifié possible. Elle est disponible en suivant ce lien : https://www.vigienature-ecole.fr/papers. L'autre permet d'être plus libre dans l'analyse pour traiter des questions plus ouvertes et propose donc des outils plus génériques.Elle sera mise à disposition des élèves et enseignants prochainement. Lien vers le Github Vigie-Analyse : https://github.com/Vigie-Nature/vigie-analyse.Ces applications sont accompagnées de document pour appuyer les enseignants qui sont souvent peu formés à la question de l'analyse de données.",Shiny/plumber I,Présentation longue,"Statistique, Ecologie, Application shiny, data, Enseignement",rr2023
https://rr2023.sciencesconf.org/468896,{VMR} to manage Virtual Machines for/with R,Jean-François Rey,anglais,"A R package to manage Virtual Machines using Vagrant tool.{vmr} allows users to manage, provision and use a virtual machine preconfigured for R. It alllows to develops, makes tests and builds a package in a clean environment. It offers different OS providers choices to improve the quality, the productivity, the reproductibility and the sharing of R productions. Here we present a pipeline over GitLab CI/CD to create VMs, a Vagrant cloud repository and how {vrm} uses Vagrant, and the posibilities offered by the {vmr} package to manipulate a VM using R code.It allows to manage, provision and use Virtual Machines preconfigured for R.",Pause Poster,Poster,"vagrant, virtual machines, gitlab",rr2023
https://rr2023.sciencesconf.org/465678,"Packages mggd et mcauchyd – Distribution gaussienne généralisée multivariée, distribution de Cauchy multivariée","Pierre Santagostini, Nizar Bouhlel",français,"Nous présentons deux packages qui fournissent des outils pour des lois de probabilité multivariées :• mggd : distributions gaussiennes généralisées multivariées• mcauchyd : distributions de Cauchy multivariées Ces deux packages permettent le calcul de la divergence de Kullback-Leibler entre deux densités de probabilité multivariées, en fonction de leurs paramètres. Pour cela, on utilise une expression analytique des divergences, grâce à des calculs publiés par Bouhlel et Dziri (2019) et Bouhlel et Rousseau (2022). En outre, ces packages fournissent des outils pour ces distributions de probabilité multivariées : valeur de la densité de probabilité, estimation des paramètres, simulation d'échantillons, graphiques.",Pause Poster,Poster,"Package, Loi gaussienne généralisée multivariée, Loi de Cauchy multivariée, Divergence de Kullback, Leibler",rr2023
https://rr2023.sciencesconf.org/455019,Modelling plant resistance deployment: the R package {landsepi},"Loup Rimbaud, Julien Papaïx, Jean-François Rey, Marta Zafarroni, Marta Zafarroni",anglais,"The R package {landsepi} provides a general modelling framework to help compare plant resistancedeployment strategies and understand the impact of epidemiological, evolutionary and genetic factors for awide range of pathosystems. The model is based on stochastic geometry for describing the landscape and theresistant hosts, a dispersal kernel for the dissemination of the pathogen, and a SEIR (Susceptible-Exposed-Infectious-Removed) architecture to simulate plant response to disease. The package includes a web interface,coded in R-Shiny, for pedagogical purposes.",Poster,Poster,Modélisation – Pathologie Végétale– Package,rr2023
https://rr2023.sciencesconf.org/467131,Welcome to the golemverse,Colin Fay,français,"Construire une application qui part en production, ce n'est pas une mince affaire. Esquisser des plans d'interface utilisateur, réfléchir à l'interaction es différentes pièces du grand puzzle de la production (application web, base de données, plateforme de déploiement, services tiers...), prototyper l'organisation visuelle et les widgets, brancher les fils en s'assurant que rien ne casse en chemin, documenter, tester, structurer..., et enfin envoyer en production.  Dans ce marathon, vous n'êtes pas seul.e : le golemverse est à vos côtés. En proposant des packages construits autour d'une philosophie commune, cet univers offre tous les outils indispensables pour envoyer une application {shiny} en production l'esprit serein. Et ça, à chaque étape du projet : pendant le design, le prototypage, la construction, la solidification, et le déploiement.   Ce poster sera l'occasion de découvrir les packages du golemverse : {golem}, {shinipsum}, {gargoyle}, {dockerfiler}, et les autres !",Poster,Poster,"Package, shiny, production, golem",rr2023
https://rr2023.sciencesconf.org/464908,Une application R Shiny pour la simulation du bilan hydrique des sols viticoles (modèle WaLIS),Xavier Delpuech,français,"Le changement climatique en cours se traduit par des épisodes de chaleur et de sécheresse plus fréquents et plus intenses. Ces épisodes se traduisent par des contraintes hydriques sur la vigne. Ces contraintes, si elles deviennent excessives, peuvent être préjudiciables au rendement et à la qualité des raisins. L'enjeu est de pouvoir piloter les pratiques culturales afin d'économiser une ressource en eau de plus en plus rare tout en conservant un potentiel de production économiquement viable. L'IFV et INRAE ont codéveloppé le modèle WaLIS, qui permet de simuler le bilan hydrique du sol à partir des données météorologiques, et ainsi de caractériser la contrainte hydrique potentielle pour la vigne. Ce modèle est codé sous R, et une application Shiny a été développée pour permettre un accès libre au modèle.",Pause Poster,Poster,"vigne, modélisation, contrainte hydrique, R, shiny",rr2023
https://rr2023.sciencesconf.org/468951,Enseigner les statistiques avec YouTube et la pop culture,Nancy Rebout,français,"En doctorat, tous les ans, j'entendais les mêmes plaintes « non, mais tu sais, ça ne sert à rien de m'expliquer tout ça, j'ai jamais rien compris en stats ». Ces plaintes ? Des étudiants en biologie quelque peu réfractaire à l'idée des statistiques et de faire du codage sur R. Tous les ans, je me donnais comme défi de leur prouver le contraire : oui, les statistiques c'est simple et ça même être fun. Oui, vous avez bien entendu. C'est ainsi qu'est né Stat'Apprendra, « la chaîne qui te permet de ne plus avoir peur des statistiques et qui va peut-être même, te donner une folle envie, d'analyser des données » avec cette ambition, celle de dédramatiser l'apprentissage des statistiques et de la programmation sur R. Sur Stat'Apprendra, je présente les méthodes statistiques et la programmation sur R en utilisant des exemples tirés de films, de séries, de jeux vidéo ou de bandes dessinées. Cette approche ludique permet de rendre les statistiques plus accessibles, plus concrètes et plus attrayantes pour les étudiants. Dans cette communication, je décrirai le contenu et le fonctionnement de ma chaîne YouTube, ainsi que la façon dont je l'intègre dans mes cours de statistiques dans une école d'ingénieur en agronomie. Je discuterai enfin des retours et des évaluations que j'ai reçus de la part des étudiants, ainsi que des perspectives d'amélioration et de diffusion de ce projet.",Poster,Poster,Programmation – statistiques – pédagogie – ludique,rr2023
https://rr2023.sciencesconf.org/468077,R package for analyzing adverse drug reactions in FDA database: Evaluation of ALS patients adverse drug reactions,Luis Garcez,anglais,"The package faersexplorer for R programming language provides easy access and analysis to FDA Adverse Event Report System (FAERS) database. This database contains information on the reported Adverse Drug Events (ADRs) in the United States since 2012. The available data format in FDA website is in XML or ASCII format, and therefore, the users need to be familiar with creation of relational databases. This package allows the reading of these files and transform them into tabular format, in order to be analyzed by statistical software like R. To explain this R package potential, a step-by-step analysis of reported ADRs from ALS patients is presented. Analysis by sex, age, year of report and reporter (consumer vs healthcare workers) was conducted. This analysis provides information to better manage drug safety concerns of ALS patients. This paper describes the faersexplorer package practical use.",Poster,Poster,"Statistics, Pharmacology, Adverse Drug Reactions, Package, ALS",rr2023
https://rr2023.sciencesconf.org/469304,{qdd} : un package R de nettoyage et de qualité des données pour les Plateformes d'Epidémiosurveillances,"Marine Marjou, Marie Grosdidier, Charlotte Rüger, Pauline Bres",français,"Les trois Plateformes d'Epidemiosurveillance françaises : en santé animale (ESA), en santé végétale (ESV) et sécurité de la chaîne alimentaire (SCA) centralisent et travaillent sur des données issues de divers plans de surveillance nationaux. Ces données sont multiples et variées et un travail de nettoyage en amont est nécessaire afin de pouvoir les analyser et les exploiter. Le package {qdd} peut s'utiliser selon deux angles différents mais complémentaires. Il permet notamment de décrire d'un point de vue quantitatif la qualité d'un jeu de données en générant automatiquement un rapport (par exemple le pourcentage de données manquantes, de coordonnées géographiques en dehors du périmètre d'étude, etc.). Ce rapport permet de mieux connaître les données et de faire un retour aux fournisseurs de données dans le but d'améliorer le recueil des données des plans de surveillance. Dans un deuxième temps, le package propose également des fonctions qui permettent de nettoyer facilement et rapidement les données de types calendaire, caractères ou des coordonnées géographiques. Les trois grands principes qui servent de base au développement du package sont la complétude, le format et la cohérence des données. Le package est en cours de conception.",Pause Poster,Poster,"data, package, qualité des données, nettoyage, épidémiologie, épidémiosurveillance",rr2023
https://rr2023.sciencesconf.org/467335,airGRgalaxy : des outils hydrologiques autour des modèles GR,"Olivier Delaigue, Guillaume Thirel, David Dorchies, Pierre Brigode",français,"En raison de leur utilité et de leur commodité, les modèles pluie-débit sont largement utilisés dans la recherche et l'ingénierie. Les applications de ces modèles vont de l'estimation des risques d'inondation à la gestion des ressources en eau et des sécheresses. L'INRAE a développé une famille de modèles hydrologiques conceptuels au cours des 30 dernières années, avec pour objectif principal de concevoir des modèles aussi efficaces que possible en termes de simulation du débit, en s'assurant qu'ils sont applicables à une large diversité de bassins versants, tout en restant parcimonieux en termes de données d'entrée. Afin de rendre disponibles ces modèles hydrologiques, un package nommé airGR a été développé il y a 10 ans. Il propose également des outils complémentaires (module d'accumulation et de fonte de la neige, algorithme de calage, calcul de critères de performance, etc.). Ces dernières années, un ensemble de packages s'est développé autour d'airGR. Le package airGRteaching a ainsi été conçu pour des applications simples et nécessite des connaissances limitées en programmation, et il offre une interface graphique particulièrement utile à des fins éducatives. La package airGRdatasets fournit des jeux de données permettant notamment de réaliser des exercices proposés avec le package airGRteaching sur 19 bassins versants. Le package airGRiwrm permet l'intégration des influences anthropiques dans un modèle hydrologique semi-distribué spatialement (barrages, prélèvements pour l'agriculture, etc.) et les règles de gestion associées. Enfin, le package airGRdatassim permet d'assimiler des données d'observation pour contraindre les modèles GR, notamment pour améliorer les prévisions des crues. En plus de ces packages, la airGRgalaxy comprend deux applications web disponibles sur sunshine.inrae.fr : airGRmaps qui fournit des paramètres régionalisés en France pour les modèles journalier GR à partir de coordonnées géographiques, et une démo de l'interface d'airGRteaching. Cette communication vise à présenter l'ensemble de ces outils.",Pause Poster,Poster,"Package, Hydrologie, Modélisation, Assimilation de données, Influences anthropiques, Enseignement",rr2023
https://rr2023.sciencesconf.org/456044,SK8 : Un service institutionnel de gestion et d'hébergement d'applications Shiny,"Elise Maigné, Isabelle Sanchez, David Carayon, Joseph Tran, Jean-François Rey",français,"Le projet SK8 (Shiny Kubernetes Service) est un projet qui regroupe une quinzaine d'ingénieur·es de l'institut INRAE et vise à proposer une solution de gestion et d'hébergement d'applications Shiny. Shiny a été largement adopté dans notre institut pour partager, valoriser et démocratiser les travaux scientifiques, or se pose systématiquement la question de l'hébergement de ces applications  Partant du constat que différentes solutions isolées ont été mises en place pour répondre aux besoins des laboratoires de recherche, nous avons décidé de proposer une solution institutionnelle open-source afin de décloisonner les pratiques et fédérer la communauté R INRAE. Le projet SK8 offre la possibilité d'héberger le code des applications Shiny sur une instance GitLab accessible à tous les agents INRAE. Des templates (Gitlab CI/CD) permettent de gérer la stabilité des applications (utilisation de{renv}), leur containérisation (Docker) et leur déploiement dans un cluster Kubernetes, le tout géré, développé et maintenu par l'équipe SK8. En terme d'utilisation, la démarche est simple puisqu'il suffit de déposer le code d'une application dans un projet Gitlab dédié. De plus l'utilisateur·rice du service reste propriétaire de son code. La version Bêta de SK8 est accessible et utilisée depuis avril 2022. Plus d'information sur le site web https://sk8.inrae.fr. Dans ce poster nous présenterons le projet, le public visé et les cas d'usages, le workflow d'industrialisation d'hébergement, ainsi que l'écosystème sous-jacent. Poster : https://hal.inrae.fr/hal-04141247",Pause Poster,Poster,"R, Shiny, Web, Application, Devops, INRAE, Kubernetes, Docker, renv, CI/CD, Gitlab, service",rr2023
https://rr2023.sciencesconf.org/466458,Développement d'une base de données hydro-climatiques nationale à l'aide de R,"Guilherme Mendoza Guimarães, Olivier Delaigue",français,"Les hydrologues cherchent à comprendre le fonctionnement hydrologique des bassins versants, notamment afin de quantifier la disponibilité de la ressource en eau, ou d'estimer les risques liés aux inondations. Ceci est fondamental pour la planification de cette ressource et la prévention des risques dans les conditions climatiques actuelles et futures. Pour ce faire, il est essentiel de comprendre comment le comportement du bassin versant est contrôlé par le climat, les influences anthropiques, ou ses attributs physiographiques (topographie, géologie, hydrogéologie). Ceci requiert la combinaison de différentes bases nécessitant le prétraitement d'une quantité importante de données. Afin de construire une base de données à l'échelle nationale, l'INRAE a mis en place un workflow basé sur le langage R, qui comporte quatre étapes principales. La 1re étape consiste en le calcul des limites des bassins versants à partir d'un modèle numérique de terrain. Ceci nécessite l'utilisation du couplage entre R et Fortran pour le calcul d'un réseau hydrographique théorique, ainsi que l'utilisation d'une interface shiny permettant de vérifier le positionnement de stations de mesure sur ce réseau. La 2e étape consiste en l'extraction des données hydrologiques et climatiques. Cette étape a nécessité le développement d'un package spécifique, hydroportail (reposant sur les packages httr, jsonlite, rvest), permettant de faciliter la récupération les données de la base hydrométrique nationale. La 3e étape consiste en l'agrégation des entrées hydro-climatiques et physiographiques à l'échelle du bassin versant en croisant les limites de ces derniers avec les rasters climatiques et physiographiques à l'aide des packages sf et terra. La 4e étape consiste en la création de produits graphiques : séries temporelles hydro-climatiques avec les packages dygraphs et rmarkdown, et fiches de synthèse (disponibles sur webGR.fr) représentant différents attributs du bassin (signatures hydro-climatiques, topographie, occupation du sol). ",Pause Poster,Poster,"Bassin versant, Hydrologie, Climatologie, Physiographie, Base de données",rr2023
https://rr2023.sciencesconf.org/455788,IDEATools : Un package R pour évaluer la durabilité des exploitations agricoles avec la méthode IDEA4,"David Carayon, Sydney Girard, Frédéric Zahm",français," Ce poster présente le package R {IDEATools}, un outil associé à la méthode IDEA4 développée en grande partie au sein d'INRAE. La méthode IDEA4 est une méthode d'évaluation de la durabilité d'une exploitation agricole selon les 3 dimensions du développement durable et les 5 propriétés des systèmes agricoles durable. Elle permet le calcul de 53 indicateurs qui sont ensuite agrégés selon différentes techniques pour rendre compte de la durabilité d'une exploitation agricole de manière synthétique, permettant au final d'identifier ses principaux leviers d'amélioration.  Figurant parmi les outils permettant la mise en oeuvre de la méthode, le package R {IDEATools} est le seul ayant permis la réalisation de certaines agrégations (qualitatives hiérarchiques) et propose les visualisations graphiques les plus complexes. IDEATools (et l'environnement R en général) a également permis de fournir aux utilisateurs des solutions de reporting automatiques, élégantes et synthétiques, couplées à des possibilités de traiter simultanément plusieurs exploitations agricoles et de les comparer entre elles (analyses de groupe). Une interface graphique minimale est également intégrée au package pour une utilisation plus aisée pour les néophytes.  Le package est en accès libre sur github et sera soumis au CRAN prochainement. ",Pause Poster,Poster,"R, Package, Dataviz, Reporting, INRAE, IDEA4, Agriculture, Durabilité",rr2023
https://rr2023.sciencesconf.org/468000,RFLOMICS: Interactive web application for multi-omics data analysis,"Nadia Bessoltane, Audrey Hulot, Gwendal Cueff, Christine Paysant - Le Roux, Delphine Charif",français,"Afin de mieux comprendre les processus biologiques complexes, des données moléculaires à différentes échelles de la cellule, appelées « données multi-omiques », sont produites en masse. Ces données omiques décrivent par exemple l'expression des gènes (données transcriptomique), l'abondance des protéines (données protéomique) ou l'abondance des métabolites (données métabolomique). Ces données sont hétérogènes, de grande dimension et souvent bruitées. Elles sont acquises selon un plan d'expérience commun construit autour de l'étude d'un ou plusieurs processus biologiques. On distingue les analyses single-omics (une table) des analyses multi-omics (plusieurs tables). L'étude de chaque couche omique constitue une première étape intéressante pour explorer et extraire la variabilité biologique pertinente au regard du processus étudié et réduire la dimension des tables. Une fois cette étape effectuée, l'analyse conjointe des tables est envisageable, pour lier entre elles les différentes couches d'omiques. L'analyse multi-omics constitue un domaine de recherche actif, les caractéristiques de ces données demandant des traitements particuliers. Une telle analyse de données multi-tableaux hétérogènes, reste un défi technique qui nécessite des méthodes pertinentes et des paramètres adaptés aux données, ainsi que des méthodes de visualisations adéquates et une gestion rigoureuse de l'environnement d'analyse. C'est dans ce contexte que RFLOMICS a été développé : pour permettre d'harmoniser les pratiques, de gagner du temps sur le code et de garantir la reproductibilité des analyses en s'appuyant sur un pipeline utilisant des méthodes et des paramètres expertisés. RFLOMICS est un package R avec une interface shiny, qui permet d'analyser de manière guidée trois types d'omiques (transcriptomique, protéomique et metabolomique), acceptant plusieurs tables par type d'omique. Il permet de prendre en compte jusqu'à trois facteurs biologiques et deux facteurs techniques. L'interface guide l'utilisateur dans toutes les étapes de l'analyse, de la création de son modèle jusqu'à la génération d'un rapport html contenant toutes les étapes qu'il aura effectuées.",Poster,Poster,"Biostatistiques, omiques, Rshiny, Reproductibilité, package",rr2023
https://rr2023.sciencesconf.org/469513,Russ a 10 ans ...,"Pascal Cristofoli, Bénédicte Garnier, Timothée Giraud, Elisabeth Morand",français,"Le séminaire R à l'Usage des Sciences Sociales (RUSS) (https://russ.site.ined.fr/) a été crée en 2013 pour offrir une plateforme d'information à destination prioritairement de chercheur.e.s et de doctorant.e.s en sciences humaines et sociales. Le format de chaque séance, calibré autour d'une thématique, le plus souvent méthodologique, permet de juxtaposer une introduction par un.e praticien.ne rompu.e à l'outil, et des mises en œuvres métiers, permettant d'apprécier l'opportunité de son utilisation.  Après avoir décrit les modalités et objectifs du séminaire, nous tirerons un bilan de 10 années de fonctionnement, à la fois en termes de champs applicatifs couverts et de publics fidélisés.",Pause Poster,Poster,"Sciences sociales, Ingenieure, Résilient, Histoire",rr2023
https://rr2023.sciencesconf.org/468037,Analyse de réseaux trophiques : comparaison d'algorithmes pour l'échantillonage uniforme de polytope,"Théo Grente, Valérie Girardin, Phillipe Regnault, Matthieu Dien",français,"Utilisés notamment en écologie marine, les réseaux trophiques sont une représentation sous forme de graphes pondérés des interactions proies/prédateurs d'un écosystème. Les nœuds du graphe représentent alors les espèces et les arêtes leurs interactions sous forme d'échanges de matière organique appelés flux. Dans le but d'estimer la valeur de ces flux, une classe de méthode appelée Modélisation Linéaire Inverse (LIM) a été développée. Cette méthode consiste à établir un système de contraintes sur ces flux à partir de mesures réalisées sur le terrain, d'expériences en laboratoire et de connaissances issues de la bibliographie. Les équations et les inéquations de ce système de contraintes définissent un polytope (généralisation à toutes dimension de la notion de polygone en deux dimensions) à l'intérieur duquel se trouvent l'ensemble des solutions du système de contraintes. Afin de mieux comprendre le réseau trophique, les écologues souhaitent obtenir un échantillon représentatif de l'ensemble des scénarios possibles, ce qui revient à échantillonner de manière uniforme le polytope de solutions. À l'heure actuelle, les écologues utilisent majoritairement le package limsolve de R pour obtenir ces échantillons. Malheureusement, la fonction xsample (la fonction d'échantillonage implémentée par [den Meersche et al., 2009]) du package limsolve est très lente etlimite les écologues travaillant sur le LIM dans leur analyse de réseaux trophiques. C'est avec cette problématique en tête que nous avons développé un package R appelé SampleLIM dont la fonction d'échantillonage est beaucoup plus performante que xsample, tout en reposant sur le même algorithme. Les performances de cette nouvelle fonction sont comparées à d'autres fonctions d'échantillonage existantes, autant du point de vue du temps de calcul que de la qualité des échantillons obtenus.",Poster,Poster,"Package, Biologie, Réseaux trophiques, Échantillonage uniforme, Méthodes MCMC, Modélisation Linéaire Inverse",rr2023
https://rr2023.sciencesconf.org/470365,"L'analyse de survie, une « nouvelle » méthode pour modéliser les dynamiques temporelles du dépérissement de la vigne",Inchboard Lauren,français,"L'Esca et l'eutypiose, maladies du bois de la vigne, constituent une préoccupation majeure pour les viticulteurs car elles remettent en cause la pérennité du vignoble par le biais 1) d'une baisse de productivité individuelle et 2) d'une mortalité des ceps de vigne dès un jeune âge. Les délais de première expression de symptômes foliaires, la fréquence des périodes symptomatiques et asymptomatiques après une première expression et les délais de mortalité sont mal quantifiés. Cela complique l'établissement de stratégies de lutte prophylactique simples et applicables par les vignerons. Afin d'élucider les dynamiques des maladies du bois sur le cépage Ugni blanc, des notations visuelles de symptômes foliaires d'Esca et d'eutypiose ont débuté en 2003 sur un réseau qui comporte aujourd'hui 41 parcelles en Charentes. Ce dispositif a suivi l'évolution individuelle de chaque cep de vigne d'année en année, avec des notations qualitatives répertoriées au cep. Il compte aujourd'hui 19 608 ceps de vigne décrites sur des périodes longues allant jusqu'à 18 années consécutives. Ce type de données est couramment analysé en épidémiologie humaine grâce à l'analyse de survie, mais cette méthode a été peu pratiquée en épidémiologie végétale. Dans notre cas, l'application de cette méthode a permis de quantifier, en fonction de l'âge du cep de vigne, 1) les probabilités de première expression des deux maladies, 2) la fréquence et la durée des périodes des différentes formes des deux maladies (expressions faibles, forts ou non-réexpression) et 3) l'espérance de vie des pieds malades. L'utilisation de l'analyse de survie en viticulture est innovante mais perfectible, puisqu'elle s'est pour l'instant limitée aux packages R existants pour la mise en œuvre de l'analyse de survie multi-états. Notre objectif est de créer et de rendre accessible une méthode d'analyse de survie adaptée aux spécificités techniques des réseaux d'épidémiosurveillance du dépérissement en viticulture.",Pause Poster,Poster,"épidémiologie, statistique, viticulture, maladies du bois, esca, survie",rr2023
https://rr2023.sciencesconf.org/466168,"Le futur c'est SAS ! Euh. . . non, Sass !",Arthur Bréant,français,"En tant que développeur d'applications Shiny, vous cherchez à améliorer l'efficacité de votre flux de travail tout en créant des applications élégantes et personnalisées. Le CSS est efficace mais plutôt fastidieux à rédiger. Ça vous dirait d'utiliser quelque chose de plus simple ? Essayez Sass !  Je propose de vous montrer comment Sass peut améliorer votre expérience de développement en personnalisant vos applications Shiny, plus rapidement et plus facilement que jamais. Grâce à ses variables et mixins, vous pourrez personnaliser vos styles, créer vos thèmes, tout en évitant la duplication de code. Avec des styles réutilisables et modulaires, la maintenance et l'évolutivité de votre app' seront un jeu d'enfant.  Sass n'est pas vraiment le futur, ce monde est déjà une réalité. Alors quittez le CSS et venez découvrir de nouvelles astuces et des outils pour l'avenir passionnant de la stylisation d'applications Shiny !",Pause Poster,Poster,"Sass, Shiny, Stylisation, Productivité",rr2023
https://rr2023.sciencesconf.org/463843,Ultra R : Comment écrire du code Ultra Efficient ?,Mohamed El Fodil Ihaddaden,français,"Au sein de la communauté R, beaucoup pensent que le langage offre une flexibilité non égalée en termes de traitement des données et de visualisation. Par ailleurs, certains ont constaté que le langage n'était pas des plus efficients. A titre d'exemple, une rumeur très répandue dit que les boucles for sur R sont très lentes. Ce qui est absolument faux. De plus, la majorité des utilisateurs tendent à utiliser des packages offrant une grande simplicité d'utilisation au détriment de l'aspect optimisation. A titre d'exemple, les packages du tidyverse sont excellents. Ils offrent une syntaxe cohérente et simple à utiliser. Cependant, un package comme data.table, avec une syntaxe moins orthodoxe, disons-le, offre une optimisation des ressources beaucoup plus aboutie. Au travers de ma présentation, j'aurais comment objectif d'énumérer les techniques les plus efficaces afin de maintenir un programme R efficient tout en préservant sa robustesse.  ",Pause Poster,Poster,"programmation, data, Package",rr2023
https://rr2023.sciencesconf.org/466468,"Initier 2400 personnes à R par enchantement : une histoire de licornes, potion et génie...logiciel",Murielle Delmotte,français,"Nous avons tous besoin d'un peu de magie dans nos vies, et la formation ne fait pas exception. Par quel prodige ThinkR, organisme de formation spécialisé en R, a formé 2400 moldus en 8 ans avec une équipe d'une dizaine de mages ? Préparez-vous à être ensorcelés par ses secrets de fabrication. À la trappe les support_formation_v2_final.pptx sur clé USB et autres galères d'installations de R et RStudio postes après postes. Évaporée l'obsolescence des contenus dictée par les évolutions incessantes de l'écosystème. La sorcellerie de l'ingénierie logicielle offre des solutions fiables, flexibles et reproductibles (au-delà du simple .Rmd/qmd) qui permettent de former en équipe plusieurs centaines de personnes à R et Shiny par an. Tout cela en distanciel. {unicorn}, {bakacode}, {digiforma}, {formation} .... sont autant d'ingrédients savamment assemblés dans notre potion magique qui nous permettent de : mettre à jour les contenus en continu et en temps réel, collaborativement minimiser autant que possible la charge cognitive en repensant l'expérience apprenant ET formateur s'affranchir des contraintes machines des apprenants en proposant des environnements clef en main. Rien de bien sorcier finalement mais peut-être découvrirez-vous de nouveaux sorts et autres tours de passe-passe pour, vous aussi, (ré)enchanter la transmission des savoir-faiR",Education/enseignement I,Présentation longue,"Teamworks, Génie logiciel, devops, formation",rr2023
https://rr2023.sciencesconf.org/468173,Diffuser la culture de la reproductibilité par une formation aux bonnes pratiques: de la qualité d'un projet aux pipelines de données,"Lino Galiana, Romain Avouac",français,"L'objet de cette communication est de présenter les choix faits pour diffuser la culture de la reproductibilité à l'INSEE avec R à travers une formation ouverte et construite de manière collaborative : https://inseefrlab.github.io/formation-bonnes-pratiques-git-R/L'objectif de cette formation est de sensibiliser des publics aux niveaux de compétences divers à la culture de la reproductibilité et au partage de projets statistiques s'appuyant sur le langage R. Après avoir proposé des éléments généraux sur la lisibilité d'un code et d'un projet statistique en R, cette formation propose une série de choix opinionated: quels formats de données privilégier ? comment gérer dans un projet ouvert des éléments de configuration à ne pas partager comme des jetons ? doit-on systématiquement structurer son projet sous forme de package ? Plutôt que d'insister sur le développement de packages, qui est assez exigeant sur la maintenance de documentation et de tests, cette formation propose plutôt dans le cadre de projets statistiques de privilégier l'apprentissage des environnements virtuels (avec renv) et des pipelines de données (avec targets).",Education/enseignement I,Présentation longue,"Bonnes pratiques, Qualité, Packages, renv, Environnements virtuels, Pipelines, targets",rr2023
https://rr2023.sciencesconf.org/446621,Où trouver de l'aide quand on apprend R ?,Marie Vaugoyeau,français,"Débuter sur R ou simplement apprendre une nouvelle technique (shiny, SIG, random forest...) sur R peut donner de sacrés noeuds au cerveau ou amener à se sentir très seul-e.... L'une des grandes qualités de R est sa communauté francophone très investie et accessible, mais où et comment demander de l'aide ? Lors de cette présentation, la création d'un reprex (exemple reproductible) sera abordé ainsi qu'un tour d'horizon des différents blogs et plateformes disponibles. Quelques bonnes habitudes indispensable seront aussi détaillées.",Education/enseignement I,Présentation longue,"apprentissage, reprex, rnewbies, débutant",rr2023
https://rr2023.sciencesconf.org/470145,Se démarquer avec les thèmes HTML Quarto.,Christophe Dervieux,français,"Quarto (J. J. Allaire et al. 2022) est un outil open source pour la publication scientifique et technique,utilisant le convertisseur universel Pandoc, et basé sur les 10 années d'expérience de l'écosystème R Markdown(J. Allaire et al. 2023).Reprenant les bases de ce que les packages R de l'écosystème R Markdown proposent, il est très facile deproduire des documents HTML et site web de qualité. Quarto vise à prendre le meilleur et permettre d'allerplus loin. Cette présentation propose de s'arrêter sur les thèmes HTML et leur adaptation.Vous souhaitez personnaliser l'apparence de vos documents Quarto au-delà des options de thème HTMLdisponibles par défaut ? Découvrez comment utiliser les thèmes Quarto, basée sur le préprocesseur SASSpour personnaliser les thèmes HTML de vos documents Quarto !Comment modifier les thèmes par défaut selon vos choix afin de rendre vos contenus différents des autresavec l'utilisation d'un fichier de thème Quarto personnalisé ? A la fois par la simplicité des modifications etajouts de variables, que de l'ajout de règles CSS plus complexes créer avec le préprocesseur SASS.Connaitre ces fonctionnalités ouvre des possibilités de différenciations intéressantes pour se démarquerdes styles par défaut, et profiter de la flexibilité offerte par l'intégration Bootstrap dans Quarto.Peu importe que vous utilisiez de simple document ou complex site web, ce talk vous offrira l'occasionde découvrir les fonctionnalités avancées des thèmes Quarto avec SASS.",Reporting,Présentation longue,quarto – rmarkdown – html – css – styles – publication – reproductibilité,rr2023
https://rr2023.sciencesconf.org/464637,Computo: An academic journal promoting reproductibility via Quarto and Continuous Integration,"Julien Chiquet, Chloé-Agathe Azencott, François David Collin, Ghislain Durif, Mathurin Massias, Pierre Neuvial, Nelle Varoquaux",français,"  Computo is a newborn journal published by the French Statistical Society (https://sfds.asso.fr/) which aims at promoting computational/algorithmic contributions in statistics and machine learning. In order to achieve this goal, Computo goes beyond classical static publications by leveraging technical advances in literate programming and scientific reporting. We present in this talk the solution that we put in place so far to support both editorial and scientific reproducibility, that relies on community-based tools like Quarto, Github actions and open review. See our webpage https://computo.sfds.asso.fr/, and github group https://github.com/computorg.  ",Reporting,Présentation longue,"Reproducible research, Quarto, R, Python, Julia, Machine, Learning, Statistics",rr2023
https://rr2023.sciencesconf.org/465031,Synthèse hebdomadaire de la consommation d'électricité française,"Valentin Cadoret, Victor Perrier",français,"Cet hiver a été particulièrement tendu en termes d'approvisionnement d'électricité, avec plusieurs facteurs qui se sont cumulés (crise du gaz, faible disponibilité du parc nucléaire français, prix de l'électricité élevé, ...). RTE en tant que gestionnaire du réseau de Transport d'Electricité se doit de garantir la sécurité d'approvisionnement afin d'éviter le blackout. Afin d'anticiper au mieux les risques, un suivi rapproché de la consommation a été mis en place pour les besoins internes de Rte mais aussi informer au mieux les acteurs institutionnels économiques et le grand public. C'est dans ce cadre qu'une synthèse hebdomadaire de la consommation a vu le jour sur le site web RTE. Ce tableau de bord, développé entièrement avec R à partir de Rmarkdown a répondu au besoin à faible coût. Dans cette présentation, nous détaillerons le contenu de ce tableau de bord et présenterons le workflow mis en place de la récupération des données à la publication sur le site RTE. Nous ferons aussi quelques focus sur des briques qui nous ont été très utiles, notamment avec {blastula}, {httr2} mais aussi la personnalisation du Rmarkdown pour obtenir le rendu final.La synthèse est accessible à cette adresse : https://www.rte-france.com/synthese-hebdomadaire-consommation-electrique-francaise",Reporting,Présentation longue,"Consommation, Electricité, Visualisation, Rmarkdown, pandoc, bslib, blastula, httr2, plotly",rr2023
https://rr2023.sciencesconf.org/461584,Data science without the data,Rhian Davies,anglais,"As data scientists, we sometimes find ourselves faced with the daunting task of writing code without actually seeing the data we are working with. Whether it's due to data privacy concerns, limited access, or simply data that has not yet been collected, we often have to rely on incomplete or synthetic data to develop and test our code. In a recent project, we worked on patient-level data. As such, the controls around the data and analysis (were rightfully) tightly controlled. We'll share how we used dummy data and mock-ups to inform code development, maintaining flexibility and adaptability in the face of changing data requirements. We'll also discuss the importance of and collaboration between developers and subject experts to ensure that code is developed with a deep understanding of the data domain By understanding these challenges and developing effective strategies for overcoming them, we can ensure that our code is robust, reliable, and effective, even in the absence of direct data access.",Keynote II,Keynote,"data science, data pipeline, development",rr2023
https://rr2023.sciencesconf.org/463663,ShinySbm : une application Shiny pour analyser des réseaux à l'aide de modèles à blocs stochastiques,Théodore Vanrenterghem,français,"Nous avons développé l'application ShinySBM, qui facilite la détection de structures et de communautés dans des réseaux via l'application d'un modèle à blocs stochastiques Aubert et al. [2022]. Les réseaux sont composés de nœuds (individus, espèces, téléphone, etc...) et d'arêtes (relation/connexion/etc...). Les réseaux peuvent être écologiques (relation de prédation), sociaux (conseil professionnel), de transport, informatiques, etc... Ils peuvent prendre différentes formes, telles que les réseaux unipartites (ex : un réseau trophique) ou bipartites (ex : un réseau plantes–pollinisateur), dirigés ou non. L'analyse de ces réseaux peut nous aider à comprendre leur structure sous-jacente, à découvrir des communautés et des motifs, et à prédire leur comportement. Cependant, l'analyse statistique de ces données de réseaux peut être complexe et difficile à visualiser. En passant par une représentation matricielle de ces réseaux, il est possible d'inférer un modèle à bloc stochastique (SBM). Le SBM est un modèle qui divise les nœuds du réseau en groupes ou blocs, en fonction de leurs liens. La probabilité que deux nœuds se connectent dépend de leurs groupes d'appartenance. Il est largement utilisé pour étudier/identifier des structures ou des communautés à partir d'un réseau. L'application est basée sur le package sbm Chiquet et al. [2023] qui permet l'inférence d'un tel modèle à bloc stochastique (SBM). L'application ShinySBM permet à des utilisateurs initiés en statistique ou non, d'utiliser le package sans avoir à coder en R mais aussi facilite l'exploitation et l'interprétation des sorties. Enfin des utilisateurs souhaitant aller plus loin peuvent extraire les codes produit par l'application.",Lightning II,Présentation courte,sbm – Shiny – Package – Données de Réseaux – Statistiques appliquées – Graphes – Écologie – Sociologie,rr2023
https://rr2023.sciencesconf.org/467797,"""AHHH #$@% ça marche pas !"" : Aidez votre père dans sa lutte avec l'informatique et devenez un.e meilleur.e développeur.se",Antoine Languillaume,français,"Un après-midi de décembre brumeux, vous entendez les vagues grognements de votre géniteur qui commesouvent est aux prises avec la technologie. Le quintuple best-off de Léo Ferré qu'il vient d'acheter n'est pas reconnu par la base de données Itunes. En lieuet place des titres mioleurs comme : “Pauvre Rutebeuf”, “Le Fleuve Aux Amants” ou encore “L'âme Du Rouquin” lalumière blafarde de l'écran n'affiche qu'une malheureuse série de titre1, titre2, titre3 . . . S'il y a une chose qui vousénerve plus que de jouer le dépanneur informatique pendant vos vacances bien méritées, c'est de ne pas pouvoirsavoir quelle chanson est jouée par l'autoradio. Vous prenez donc en photo le verso de la pochette du CD et dites :“Laisse moi 2h je vais régler ça”. Vous vous enfermez dans votre bureau et c'est parti ! Votre père vient sans s'en rendre compte de vous donnerl'occasion de devenir un bien meilleur programmeur avec un projet hyper ludique ! Comment faire extraire le texte de l'image ? Comment éditer automatiquement les méta données des fichiersaudio ? Et surtout comment rendre le projet reproductible ? Après tout, vous passez votre temps à seriner vos collègueschercheurs sur l'importance de la reproductibilité de leurs projets ? C'est le moment où jamais de leur montrerque c'est possible même pour un projet en apparence insignifiant ! Dans cette courte présentation nous verrons comment un problème de la vie quotidienne, en apparenceanodin, a permis à l'auteur d'intégrer quantité de savoirs en un seul projet très ludique, et d'en faire l'exempleidéal des méthodes de reproductibilité moderne.",Lightning II,Présentation courte,"Reproductibilité, Apprentissage, Interopérabilité R et Python, Conteneurisation, Chanson Française.",rr2023
https://rr2023.sciencesconf.org/467655,Pybind11/reticulate comme alternative à Rcpp,François-David Collin,français,"Selon des enquêtes menées auprès des développeurs, le langage C++ serait le langage « bas-niveau » et haute performance le plus utilisé actuellement. Il est donc naturel de vouloir utiliser ce langage pour développer en R en l'optimisant avec des fonctions en C++, et l'objectif d'un package comme Rcpp est d'en faciliter l'intégration. Dans l'écosystème Python, une démarche similaire est à l'origine de pybind11 pour créer des modules Python à partir de code C++. Pour la même base de code C++, maintenir deux interfaces différentes pour Rcpp et pybind11 constitue une charge de travail importante, nous proposons une alternative fonctionnelle qui partirait uniquement de Python/pybind11 grâce à l'utilisation reticulate, qui permet d'intégrer directement des modules Python depuis R.",Lightning II,Présentation courte,"Python, R, modern C++, Packages, Rcp",rr2023
https://rr2023.sciencesconf.org/466999,SABRE (industrial project),"Antony Pudlicki, Olivier Bernard, Valéry Bourny, Geoffroy Berard, Olivier Durand-Drouhin",français,"Le projet SABRE a pour objectif d'étudier le comportement tribologique des balais frottant sur des bagues et traversés par un fort courant électrique pour les génératrices de forte puissance avec un angle original : l'utilisation des statistiques et de la science des données avec le logiciel R articulée avec les expertises métiers de l'industrie MERSEN. Le frottement, l'usure des balais et l'influence des matériaux sur les propriétés tribologiques du couple bague/balai sont investigués. La spécificité de cette problématique réside dans le fait que le comportement tribologique d'un contact électrifié bague/balai fait intervenir un couplage multi-physique de grande complexité avec une grande variance, et qui est multifactoriel et multi-échelle. Les données nécessaires pour analyser et suivre de manière fine ce comportement sont à dimensionnalité élevée, hétérogènes et formalisées par des séries chronologiques. Dans ce travail, nous présentons l'intégration et l'utilisation de R dans ce contexte industriel. Un système d'information centré sur la valeur de la donnée et son usage efficient a été construit assurant une digitalisation et une traçabilité de la fabrication des balais aux essais en conditions réelles. Celui-ci a été déployé sur un banc d'essais industriel, une génératrice éolienne de très forte puissance , où les nombreux balais de puissance sont suivis simultanément (série horaire de température, courant, usure, etc.) avec des données décrivant les conditions environnementales, les consignes et celles donnant les caractéristiques du système bague/balai (mécaniques, chimiques, propriétés physiques, etc.), soit près de 200 variables collectées par essai (un essai dure 300h). Des outils sont développés (tableaux de bord, génération automatique de rapport, etc.) pour décrire, comparer et modéliser les essais. Ce travail ouvre la voie à l'utilisation d'un large spectre de techniques aussi bien classiques que récentes en traitement de données avec R. Par exemple, des méthodes de classification non-supervisée sont employées pour partitionner les balais.",Lightning II,Présentation courte,R en contexte industriel,rr2023
https://rr2023.sciencesconf.org/467989,MyFamilyRisk: une application R/Shiny pour saisir facilement son histoire familiale de cancer.,Youenn Drouet,français,"L'histoire familiale lue au travers de ses cancers peut aider à évaluer l'opportunité d'une consultation d'oncogénétique. Dans cette perspective, notre équipe a développé le prototype d'application en R/Shiny MyFamilyRisk, qui permet de saisir simplement et de manière anonyme son histoire familiale de cancer, sous la forme d'un arbre généalogique, téléchargeable au format pdf. L'application, en cours de test, est actuellement déployée sur le serveur interne du Centre Léon Bérard via la technologie Docker. Le premier cas d'usage en cours d'étude concerne les patients adressés en consultation d'oncogénétique dans un but thérapeutique. Ces patients atteints de cancer doivent être vus par un oncogénéticien de manière obligatoire et en urgence. Le recueil de l'histoire familiale de cancer qui est indispensable en amont de la consultation d'oncogénétique, nécessite des ressources en personnel importantes. L'outil développé MyFamilyRisk permet le recueil de ces informations directement par le patient, qui peut alors les transmettre immédiatement au service d'oncogénétique, ce qui représente un gain de temps considérable. L'application rendant beaucoup plus rapide l'évaluation du risque, elle ouvrira probablement des perspectives pour de nombreuses structures, pour faire évoluer les pratiques afin de faciliter l'accès à l'oncogénétique. Nous étudions notamment la possibilité de créer une version de l'application à destination du grand public.",Lightning II,Présentation courte,"Oncogénétique, Application Shiny, Histoire familiale de cancer",rr2023
https://rr2023.sciencesconf.org/464393,"{golem} et {fusen}, le combo gagnant pour construire des applications Shiny robustes et faciles à maintenir",Sébastien Rochette,français,"Vous avez besoin de créer des applications Shiny prêtes pour la production qui soient flexibles, maintenables et extensibles ? Alors vous devriez envisager d'utiliser la puissante combinaison des packages {fusen} et {golem}.    {fusen} aide à créer des packages R prêts pour la production en encourageant la documentation, les exemples et les tests unitaires, favorisant du même coup la collaboration. {golem} offre quant à lui un cadre pour la construction d'applications Shiny prêtes pour la production en garantissant une structure de package cohérente et en automatisant les processus de déploiement.      L'utilisation conjointe de {fusen} et de {golem} offre plusieurs avantages lors de la gestion du développement d'applications. {golem} est utilisé pour intégrer le développement d'applications Shiny dans la structure d'un package R, en séparant le développement du cœur de l'application de la partie interactivité de l'interface. {fusen} rend le développement du côté package accessible au plus grand nombre. {fusen} vous encourage à écrire la documentation, les exemples et les tests unitaires associés, veillant ainsi à rendre chaque étape prête pour la mise en production. L'atout supplémentaire, c'est cette documentation statique qui permet de présenter différentes possibilités de sorties, sans perdre de temps à cliquer sur une interface interactive à chaque changement.         Si vous créez des applications Shiny pour d'autres personnes, ce combo vous permettra de leur montrer à quoi ressemblera l'application très tôt dans le développement grâce à l'utilisation d'un document HTML statique qui a été testé et qui comporte des instructions. Cela donne confiance aux utilisateurs et permet souvent de gagner du temps en identifiant les modifications nécessaires le plus tôt possible.       Intéressé.e.s ? Alors venez apprendre comment améliorer votre développement d'applications Shiny avec {fusen} et {golem}.",Lightning II,Présentation courte,"Shiny, golem, fusen, package, workflow",rr2023
https://rr2023.sciencesconf.org/467151,{matreex} : Simuler les dynamiques forestières européeennes,"Maxime Jaunatre, Georges Kunstler",français,"Le package R {matreex} permet de projeter la dynamique de communautés d'arbres en Europe. A partir de fonctions prédisant les taux vitaux : survie, reproduction et croissance paramétrisées sur des inventaires forestiers, ce package simule la dynamique de populations d'arbres et le changement de leurs structures en taille avec des modèles intégré de dynamique de population (IPM). Le modèle prend en compte l'effet du climat et la compétition. A ces simulations s'ajoutent des modules de coupes régulière et irrégulière ainsi que des perturbations. L'utilisation de ces matrices accélère grandement le calcul et autorise donc des simulations sur plusieurs milliers d'années pour l'étude d'équilibres dans la dynamique de population d'espèce arborées.L'objectif est de faciliter l'utilisation de ce modèle au sein d'une équipe de recherche, afin de développer de nouveaux axes d'étude sur les forêts européennes (Kunstler et al. (2021) et Guyennon et al. (2023)).",Lightning II,Présentation courte,"Integral projection model, dynamique des populations, Biologie, ingénieur, Package",rr2023
https://rr2023.sciencesconf.org/450511,"R-Ladies Paris, une communauté engagée garantissant la diversité et l'inclusivité",Mouna Belaid,français,"La lutte contre les disparités des genres fait partie des objectifs de la communauté R-Ladies. Cette présentation a pour objectif de présenter la commaunuté R-Ladies Paris, une section locale de l'organisation mondiale R-Ladies Global. R-Ladies Paris lutte pour la réduction des inégalités des genres et contribue à accroître la visibilité, la participation et la reconnaissance des contributions des genres sous-représentés dans la communauté R. En promettant la diversité des genres dans la communauté R, notre communauté regroupe des membres partageant nos valeurs ainsi qu'une passion pour R. Nous allons ainsi mettre l'accent sur la responsabilité morale que R-Ladies Paris assume en encourageant des initiatives visant la visibilité des utilisateurs de R et la valorisation de leurs travaux. Quand tu es membre de R-Ladies, Il ne suffit pas seulement de t'engager dans notre communauté; il s'agit également de rendre la communauté R plus ouverte, plus diversifiée et plus inclusive. ",Lightning II,Présentation courte,"RLadies, communauté, inclusivité, diversité, égalité",rr2023
https://rr2023.sciencesconf.org/467772,7 Méthodes secrètes des informaticiens pour mieux programmer,Régis Leroy,français,"Un programme R qui ne marche que sur un vieux poste Windows XP et que personne n'arrive à réinstaller ailleurs ? Un informaticien qui grimace en étudiant votre code ? Vous avez des doutes sur le fonctionnement de ce programme que vous aviez écrit il y a 5 ans ? Comment éviter ces situations ?   Le but de cette présentation est de diffuser quelques bonnes pratiques de programmation au sein d'une population composée de profils scientifiques qui pratiquent la programmation sans que cela ne soit leur principale expertise. Cette présentation se base sur des retours d'expérience en audit ou en conseil auprès de différentes communautés scientifiques, avec identification de problèmes récurrents. Constats qui ont donnés lieu à la création d'une formation professionnelle sur les bonnes pratiques de développement destinée spécifiquement au Data Scientists.   La présentation est effectuée par Leroy Régis, DevOp, formateur, spécialiste en sécurité web, bases de données et en développement web Python et PHP. Il pratique parfois le R, le plus souvent pour adapter, corriger, et améliorer des programmes existants.",Infra II,Présentation longue,"Développement, Ingénierie, Bonnes pratiques",rr2023
https://rr2023.sciencesconf.org/467595,R sur OpenBSD,Andre Buskvekster,français,"OpenBSD, c'est le système d'exploitation le plus facile pour moi, donc le système d'exploitation sur lequel j'utilise R. OpenBSD ne se base ni sur GNU ni sur Linux, et nous ne sommes qu'une dixaine qui utilise R sur OpenBSD. Par conséquence il se passe souvent qu'un package R ne fonctionne pas sur OpenBSD, et il faut savoir comment faire lorsque cela ce passe. Cependant, en utilisant R sur OpenBSD on peut profiter d'énormément fonctionnalités qui n'existent que dans OpenBSD.",Infra II,Présentation longue,"pare, feu, installation, configuration, sécurité, communauté, OpenBSD, pf, vmm, Docker, Rserve, tidyverse, RStudio, Posit, PostGIS",rr2023
https://rr2023.sciencesconf.org/467782,meRoo : Un écosystème logiciel pour l'apprentissage des sciences des données installé sur un cluster de Raspberry Pi,"Frédéric Blanchard, Guillaume Dollé, Philippe Regnault",français,"Les projets d'ingénierie reposant sur une volumétrie importante de données nécessitent une collaboration maîtrisée entre les différents acteurs impliqués. Cette collaboration est caractérisée par des flux importants d'informations (données, code, documents, etc) produites et échangées par divers outils, logiciels et langages. La maîtrise de la gestion de ces flux, communément désignée par « workflow » est un enjeu essentiel dans la formation des ingénieurs en sciences des données.La mise en place de tels workflows nécessite une infrastucture matérielle et logicielle qui peut ne pas être facile à déployer dans le cadre de formations académiques. C'est une difficulté à laquelle nous avons été confrontés dans le cadre de nos enseignements au sein du master Statistique et Évaluation pour la Prévision de l'Université de Reims Champagne-Ardenne (URCA). Nous avons pris le parti d'y répondre en privilégiant une approche économique, frugale, accessible et... fun : déployer un ensemble de ressources libres sur un cluster de nano-ordinateurs Raspberry Pi, mises en musique par RStudio Server !Notre « super-nano-calculateur » meRoo, anagramme de Romeo, nom du super-calculateur de l'URCA, est utilisé pour les enseignements depuis quelques mois. Requêtage de bases SQL, noSQL, développement et hébergements d'applications Shiny, calcul parallèle avec R ou python, calcul distribué avec Hadoop/Spark, intégration continue avec GitLab, les possibilités sont étonnantes. Retours sur cette expérience pédagogique enthousiasmante !",Infra II,Présentation longue,"Enseignement, data science, workflow, cluster, Raspberry Pi.",rr2023
https://rr2023.sciencesconf.org/464865,Qualité de l'air ambiant en Wallonie (Belgique) - Visualisation des mesures de la pollution via une app' R-Shiny {golem} dans un environnement ShinyProxy,"Laurent Spanu, Fabian Lenartz",français,"L'ISSeP (Institut Scientifique de Service Public) est une unité d'administration publique sous la tutelle de la Ministre de l'Environnement de la Wallonie (Belgique). Une de ses missions principales est la surveillance de l'environnement, qui inclut la qualité de l'air ambiant. Dans une volonté de se moderniser et de mettre à disposition plus efficacement les données de surveillance de la pollution atmosphérique auprès du grand public mais aussi, des autorités locales, bureaux d'études et autres professionnels, un nouveau site web wallonair.be (https://www.wallonair.be) a été développé et mis en ligne en septembre 2020. Ce site est alimenté par une base de données MS SQL server sur laquelle sont greffées des procédures en langage SQL et R pour le traitement des données. Autour de ce site de référence gravite une application intitulée ""cqaweb"" (https://cqaweb.issep.be) proposant l'historique des mesures de la Cellule Qualité de l'Air. Elle a été développée en R-{Shiny} en utilisant le package {golem}. L'environnement de déploiement utilisé est ShinyProxy dont la structure sous-jacente repose sur Java et Docker. Toute cette structure (staging et production) est déployée en continu (CI/CD) via GitLab. L'objet de cette présentation est de partager l'ensemble de la chaîne mise en place pour faire vivre cet outil principalement orienté open source et dont le but est de mettre à disposition les données de la qualité de l'air ambiant en Wallonie de manière flexible, robuste et fiable.",Geospatial I,Présentation longue,"sciences, qualité de l'air, data, visualisation, shiny, GitLab",rr2023
https://rr2023.sciencesconf.org/467369,Suivi de la réponse des agroécosystèmes au changement climatique. Visualisation sur une application R-Shiny,Alexis Fribault,français,"Les agro-écosystèmes sont sensibles aux changement climatique en tant que milieu mêlant surfaces agricoles et habitats semi-naturels. L'objectif du projet MOMAC consiste à suivre les évolutions de la biodiversité animale et végétale au sein de ces systèmes en réponses aux évolutions du climat. L'intérêt sera d'observer les impacts des changements de pratiques agricoles, afin de s'adapter aux évènements climatiques, sur les écosystèmes environnant à l'échelle de la parcelle mais également du paysage. L'utilisation d'une application Shiny permet de visualiser en temps réel et d'interagir avec les variables étudiées sur les différents sites.",Geospatial I,Présentation longue,"Changement climatique, Shiny, biodiversité, agroécosystèmes",rr2023
https://rr2023.sciencesconf.org/467816,phacochr: un géocodeur pour les géocoder tous - Package R pour réaliser le géocodage d'adresses en Belgique,"Joël Girès, Hugo Périlleux",français,"Nous présentons phacochr: un géocodeur pour la Belgique sous forme de package R. Son principe est de produire de manière simple et rapide, à partir d'une liste d'adresses, une série d'informations nécessaires pour l'analyse spatiale: les coordonnées X-Y mais également d'autres informations utiles comme le secteur statistique (la plus petite unité géographique belge). Le programme fonctionne sur base de données publiques d'adresses quasi-exhaustives pour la Belgique compilées à partir des listes régionales (Région de Bruxelles-Capitale, Région flamande et Région wallonne). Par ailleurs, le géocodage est réalisé entièrement en local, permettant une confidentialité maximale dans le cas de données d'adresse sensibles. phacochr réalise également la cartographie des adresses localisées sur base de shapefiles intégrés. Nous désirons présenter ce package afin d'avoir des retours avisés de la communauté R à propos des solutions techniques choisies et des améliorations possibles.",Geospatial I,Présentation longue,"Package, Géocodage, SIG, fuzzyjoin",rr2023
https://rr2023.sciencesconf.org/468324,R dans l'univers de la Dataviz,Yan Holtz,français,"Avec une vaste gamme d'outils, de cas d'utilisation et de types de graphiques disponibles, il peut être difficile de naviguer dans l'univers de la visualisation de données (dataviz). Dans cette présentation nous explorerons comment la dataviz est utilisée par diverses professions : la recherche, le journalisme de données, la ‘business intelligence', et d'autres. Nous examinerons les différents outils disponibles, en mettant l'accent sur R. Bien que chaque outil ait ses forces et ses faiblesses, R est devenu un choix populaire parmi les scientifiques et analystes de données. Nous explorerons la position de R dans l'écosystème de la dataviz, en mettant en évidence ses avantages et ses limitations. Nous examinerons également d3.js, une bibliothèque JavaScript populaire pour créer des graphiques, et la comparerons à R en termes de ses capacités et limitations. Que vous soyez nouveau dans la visualisation de données ou un praticien expérimenté, cette présentation vous fournira des connaissances précieuses sur l'univers de la dataviz et vous équipera des connaissances nécessaires pour choisir le bon outil pour vos besoins.",Keynote III,Keynote,"R, dataviz, d3.js, shiny, ggplot2",rr2023
https://rr2023.sciencesconf.org/465510,{autoimport} : gérer l'enfer des imports,Dan Chaltiel,français,"Toute personne ayant déjà développé un package le sait, gérer les dépendances est au mieux ennuyant, et au pire franchement pénible.Pour la plupart des packages, les dépendances sont gérées par le package `{roxygen2}` selon deux possibilités. La première est d'utiliser le tag `@import`, qui importe un namespace entier. Cette soluton est est rapide mais expose à des conflits de noms souvent problématiques. La deuxième, ma préférée, est d'utiliser le tag `@importFrom` qui importe chaque fonction indépendamment. Le problème alors, c'est que quand on importe beaucoup de fonctions, gérer tous ces tags devient vite une tâche très chronophage et pas vraiment valorisante.Heureusement, cette tache est automatisable, et `{autoimport}` essaie de s'y attelerg ! Ainsi, en appelant `autoimport()`, toutes les fonctions d'un package sont analysées pour générer une liste des dépendances externes. En fonction des fichiers `NAMESPACE` et `DESCRIPTION`, les bons tags `@importFrom` sont générés et peuvent être insérés facilement dans le code du package. Quand le choix n'est pas univoque, l'utilisateur peut choisir manuellement via la console.Pour plus de sécurité, on utilisera tout de même la fonction `import_review()`, qui propose une interface shiny utilisant `{diffviewer}` et permet de passer en revue toutes les modifications proposées avant de les accepter.  ",Lightning III,Présentation courte,"Package, Statistiques, Documentation, roxygen2",rr2023
https://rr2023.sciencesconf.org/463370,Réaliser ses tableaux avec flextable,David Gohel,français,"'flextable' fournit une grammaire pour créer et personnaliser des tableaux statiques. Les formats de sortie pris en charge sont 'Word', 'RTF', 'PowerPoint', 'PDF', 'HTML' et R 'Grid Graphics'. La syntaxe est la même quel que soit le type de sortie à produire. Un ensemble de fonctions permet la création d'un tableau depuis un ‘data.frame' et un autre ensemble de fonctions 'haut niveau' permettent la création de résumés statistiques ou de tableaux croisés complexes. Nous présenterons par le biais d'illustrations les dernières avancées, notamment l'intégration native avec ‘ggplot2' qui permet d'intégrer des flextable ‘responsive' dans les graphiques ou à côté avec le package ‘patchwork', la compatibilité avec le package ‘tables' qui permet de remplacer la fameuse PROC REPORT de SAS et les avancées réalisées dans le domaine du reporting clinique.",Lightning III,Présentation courte,"tableaux, reporting clinique, agrégations",rr2023
https://rr2023.sciencesconf.org/460429,La modélisation individu-centrée sur R avec le package NetLogoR,"Sarah Bauduin, Eliot Mcintire, Alex Chubaty",français,"NetLogoR est un package permettant de créer et d'exécuter des modèles individu-centré (IBMs – Individual Based Models) sur R. Les IBMs sont des modèles de simulation où les règles de décisions sont définies au niveau de l'individu et les résultats émergent et sont analysés au niveau de la population. NetLogoR suit le même cadre que le logiciel NetLogo (Wilensky 1999) mais n'est pas une fonction d'appel pour utiliser ce logiciel. NetLogoR est une traduction en langage R de la structure et des fonctions de NetLogo. Les utilisateurs de ce package bénéficient du cadre facile de compréhension défini par NetLogo couplé à la polyvalence, la puissance et les nombreuses ressources du langage R pour créer des modèles individu-centrée pouvant aussi être spatialement explicite.",Lightning III,Présentation courte,"Modélisation individu, centrée, Modélisation agent, centrée, NetLogoR, NetLogo, Package R",rr2023
https://rr2023.sciencesconf.org/466443,Combien d'animaux dans mon essai ?,Terence Dechaux,français,"Combien d'animaux je dois mettre dans mon expérimentation ? Voilà une question récurrente que se pose tout expérimentateur. Dans la réponse que leur apportent les statisticiens, il n'y a aucune magie, même si la légende voudrait que leur réponse à tous soit 42. Le calcul d'effectifs répond à des règles très précises où il est nécessaire que l'expérimentateur fournisse des éléments permettant de procéder au calcul. L'application CalculEffectifs a été créée pour répondre à ce besoin. Cette application a été développée avec le package Shiny et peut être utilisée par tout expérimentateur souhaitant dimensionner son essai. L'objectif est de pouvoir garantir une puissance statistique suffisante permettant de détecter des écarts significatifs, tout en optimisant le nombre d'animaux nécessaires. Les contraintes liées à l'élevage comme la mise en lot, les blocs ou les cases sont aussi intégrés pour un calcul optimal. L'application se révèle être un outil indispensable à la préparation d'une expérimentation.",Lightning III,Présentation courte,Statistique – Expérimentation – Echantillon – Tests statistiques – R – Shiny,rr2023
https://rr2023.sciencesconf.org/460269,{happign} : une porte ouverte sur les données IGN,Paul Carteron,français,"Depuis le 1er janvier 2021, l'IGN a ouvert en libre accès ses données sur diverses thématiques : environnementales, topographiques, administrative, ... L'IGN propose différents moyens pour les obtenir. Les données étant majoritairement géospatialisées c'est la technologie des flux WMS et WFS qui est privilégiée mais il existe également des API ou plus classiquement des téléchargements directs type .zip. Le package happign propose une interface unique permettant d'explorer et d'accéder à l'ensemble des données fournies par ces services. Il est possible au sein du même environnement de télécharger et de manipuler la donnée ce qui simplifie les chaines de traitement ; condition nécessaire aux sciences reproductibles. happign répond également aux besoins de transparence des données publiques avec une utilisation simplifiée rendant accessible l'exploration des multiples possibilités offertes par les équipes de l'IGN. Le besoin en données uniformisées, faciles d'accès et largement partagées est grandissant. L'IGN y travaille activement. happign est une pierre à cet ambitieux édifice permettant de démocratiser le fruit de leurs efforts pour les utilisateurs de R.",Lightning III,Présentation courte,"Package, Data, Géospatiale",rr2023
https://rr2023.sciencesconf.org/468153,survivalGPU : Analyses de survie sur cartes graphiques,"Alexis Van Straaten, Jean Feydy, Anne-Sophie Jannot",français,"Une partie de notre travail consiste à réaliser des analyses de survie à partir de bases de données médicales nationales. L'importante volumétrie ne nous permettait pas de réaliser ces analyses en routine. L'objectif était donc de réduire ces temps de calcul en basculant les calculs sur des cartes graphiques (GPU). Pour se faire, nous avons profiler le package survival, servant à réaliser les analyses de survie, pour réécrire notre solveur de Cox, et implémenter un modèle de Cox avec support GPU. Cela nous a conduit à créer un package afin de mettre à disposition de la communauté la possibilité de réaliser des analyses de survie en utilisant les ressources des cartes graphiques. Avec le package survival, le temps d'exécution pour 1000 bootstraps d'un modèle temps dépendant de Cox est de 5 minutes, pour analyser un jeu de données test composé d'environ 77 000 observations (500 individus avec au maximum 365 observations). Avec survivalGPU, le temps d'exécution est de 1.5 secondes. L'autre atout de survivalGPU est qu'il permet de traiter de large bases de données (plusieurs millions d'individus) contrairement aux packages existants sur CPU. Nous avons ensuite mis en place un second modèle pour la détection de signaux dans le cadre de projets sur de la pharmacovigilance, également avec support GPU. survivalGPU est actuellement disponible sur github, et sera soumis très prochainement au CRAN.",Lightning III,Présentation courte,"Package, analyses de survie, épidémiologie, biostatistique",rr2023
https://rr2023.sciencesconf.org/463372,ggiraph et shiny,David Gohel,français,"La sortie graphique offerte par le package ‘ggiraph' est un graphique web dynamique et interactif produit à partir d'un graphique ‘ggplot'. Ces sorties graphiques sont produites par le moteur graphique de R ce qui permet la production d'un graphique interactif identique à ce que produit R en version statique. Il permet tout d'abord d'animer les graphiques, c'est-à-dire d'afficher des tooltips et de présenter des animations déclenchées par le passage du curseur sur les éléments du graphique. Il permet aussi, à l'intérieur d'applications ‘shiny', de travailler avec les interactions de l'utilisateur qui sont rendues disponibles sous forme de valeurs réactives. Nous présenterons d'abord le fonctionnement général. Nous détaillerons ensuite comment ajouter de l'interactivité à un graphique ‘ggiraph' et comment en bénéficier simplement dans une application ‘shiny'.",Dataviz,Présentation longue,"ggplot2, reactive, interactive",rr2023
https://rr2023.sciencesconf.org/466643,Visualisations interactives de données au service de la prise de décision sur les études cliniques de phase précoce en oncologie,Charlotte Cheinin,français,"Dans un contexte de (r)évolution des études cliniques initiée ces dernières années (ex. modifications du cadre réglementaire, déploiement progressif de standards de structure de données internationaux SDTMs/ADaMs, designs d'études multi cohortes, analyses statistiques plus innovantes et médecine plus personnalisée), les équipes de Biostatistics & Programming (B&P) en oncologie de Sanofi ont créés Interactive DEcision Output (IDEO). IDEO est une application RShiny ayant pour objectif d'accélérer les prises de décisions grâce à des visualisations interactives de qualité fondées sur la collecte de données tout au long de la conduite d'études cliniques. A ce jour, IDEO est déployée sur une vingtaine d'études cliniques de phase précoce en oncologie du portefeuille Sanofi, environ 150 utilisateurs participants au process de décision ont accès à leur(s) étude(s) respective(s), et l'application propose plus de 150 visualisations (ex. efficacité, tolérance et événements indésirables, biomarqueurs) qui sont mises à jour en temps quasi réel.",Dataviz,Présentation longue,RShiny – visualisation de données – statistique – étude clinique – multi cohortes – oncologie – prise de décision – GxP,rr2023
https://rr2023.sciencesconf.org/467530,Utiliser R et Python pour le traitement de données : exploration des avantages de Python en matière de visualisation,Mickaël Carlos,français,"Les données jouent un rôle central dans de nombreux domaines et leur traitement est unetâche cruciale pour les scientifiques, les chercheurs et les analystes de données. Le langage R estlargement utilisé pour l'analyse de données en raison de ses capacités statistiques avancées et deses nombreuses bibliothèques dédiées à l'analyse de données. Alors que ggplot2 est, de loin, labibliothèque de visualisation la plus populaire en R, en comparaison Python offre une large gammede bibliothèques de visualisation telles que Matplotlib, Seaborn ou Plotly et bien d'autres quipropose une multitude de types de représentation.Dans cette présentation, nous explorerons un exemple d'utilisation de R et Python pour le trai-tement de données. Par la suite nous explorerons les bibliothèques de visualisation de Python pourcréer des visualisations interactives et dynamiques. Pour ce faire, nous utiliserons un environnementde développement intégré tel que Jupyter Notebook, qui permet d'exécuter du code R et Pythondans un même document.Nous aborderons également la production d'interface par l'utilisation de bibliothèques spécia-lisées telle que Streamlit qui permet de produire des applications web complètes. Cela peut êtreparticulièrement utile pour naviguer dans les données et en personnaliser le traitement, l'analyseet la présentation.Cette conférence s'adresse à toute personne intéressée par l'analyse de données et la visualisa-tion et qui souhaite explorer certains aspects de l'utilisation de Python pour le traitement et lavisualisation de données",Dataviz,Présentation longue,Data science – Python – R – Data Science – Dataviz – Interactivité,rr2023
https://rr2023.sciencesconf.org/467688,Rzine : pour la diffusion et le partage de ressources sur la pratique de R en SHS,Hugues Pecout,français,"Rzine est un projet exploratoire et collaboratif initié en 2018 au sein de la fédération de recherche du Collègue International des Sciences Territoriales (CIST). Au démarrage, ce projet se résume à un collectif d'utilisateur·rices aspirant à produire de la documentation sur R. Mais l'activité déjà bouillonnante de la communauté R francophone ainsi que la riche production qui en découle ont amené le collectif vers des objectifs plus ambitieux. Ainsi, l'équipe Rzine s'est peu à peu renforcée, diversifiée et le projet s'articule aujourd'hui autour de deux axes de travail.D'une part, le développement et l'administration du site rzine.fr a pour finalité de valoriser l'existant et de dessiner les contours de la communauté R selon divers moyens : le référencement de ressources gratuites pour l'utilisation de ce langage, la mise en avant de projets francophones qui favorisent la pratique de R et la diffusion d'informations générales par l'alimentation d'une rubrique d'actualités. Le second axe de travail est la création d'une collection de publications sous la forme de notebooks. Cette revue expérimentale offre à tou·tes un espace de publication innovant pour la valorisation et le partage de méthodes reproductibles de traitement de données dans le champ des sciences humaines, sociales et territoriales. Cette initiative a également pour objectif sous-jacent d'inciter aux bonnes pratiques en matière de partage et de reproductibilité du code produit, notamment par la pratique de la programmation lettrée, du notebook et l'utilisation des plateformes de gestion de versions.L'articulation de ces deux axes de travail permet au projet Rzine de participer à la diffusion de la pratique de R et à la montée en compétence collective dans le champ des recherches en SHS.",Education/enseignement II,Présentation longue,"ressources, collection, notebook, Git, SHS",rr2023
https://rr2023.sciencesconf.org/468076,"Application {shiny} de correction de projets individuels utilisant R, RStudio, GitHub","Guyliann Engels, Philippe Grosjean",français,"Dans le cadre du cours de sciences des données biologiques à l'Université de Mons en Belgique, les étudiants réalisent des projets avec R et RStudio. Les projets sont rédigés en R Markdown et versionnés sur GitHub (organisation BioDataScience-Course) et générés via GitHub Classroom.  La correction des travaux est réalisée sur base de grilles critériées. Cette correction prend beaucoup de temps et nécessite une attention particulière pour obtenir une notation équitable d'un étudiant à l'autre, et si des commentaires constructifs sont ajoutés dans la grille. Nous introduisons une nouvelle application web {shiny} permettant de corriger critère après critère tous les travaux en série. La partie concernée de chaque travail, identifié par un titre ou un label de chunk, est extraite des documents. Ces extraits sont regroupés et triés automatiquement avec un algorithme de calcul de similarité de texte du package {stringdist}. Ainsi, il est plus facile de noter de manière équivalente des réponses similaires. Cette manière de travailler diminue également le temps nécessaire à la correction. Des liens cliquables permettent d'accéder rapidement aux travaux complets, et au contexte éventuel (jeu de données, documents annexes, . . . ), améliorant ainsi encore la vitesse de correction et le confort d'utilisation dans le remplissage des grilles critériées.",Education/enseignement II,Présentation longue,"Science des données biologiques, Application shiny, Pédagogie, Correction, Projet RStudio, GitHub, R Markdown",rr2023
https://rr2023.sciencesconf.org/468117,fRench : R en français,Philippe Grosjean,français,"Depuis sa version 2, R offre la possibilité de traduire les messages (avis, erreurs) de R et de packages R, de l'UI RGui et de l'installeur de R sous Windows dans différentes langues. Le français () est supporté depuis la version R 2.1.1 (voir ). C'est aussi la langue traduite de manière la plus complète à ce jour, hors manuels. Récemment, RStudio propose aussi (en expérimental) une traduction en français qui nécessite encore quelques finalisations. À la suite de cet exposé, vous saurez tout sur la traduction de R en français, l'auteur étant traducteur principal depuis le début. Nous discuterons le pour (utile pour les non-anglophones) et le contre (ne facilite pas les questions vers une communauté qui a largement adopté l'anglais). Des pistes pour la traduction des jeux de données, des graphiques et des tableaux seront aussi discutées.",Education/enseignement II,Présentation longue,"R, Traduction, Français, Public francophone, RStudio, data.io, chart",rr2023
https://rr2023.sciencesconf.org/465363,Et si {shiny} n'existait pas. . . ?,Cervan Girard,français,"... Dis moi comment je coderais ? Imaginez un instant que nous soyons en 2012 et que Joe Cheng, finalement, ne rêve pas {shiny} mais plutôt de partir en voyage au Pérou ! ... il aurait peut être fait un beau voyage mais nous, qu'aurions nous fait ? Nous sommes en 2012, nos besoins en matière de communication sont bien présents, nous devons donc trouver une solution pour communiquer nos résultats au monde entier en dehors de notre terminal ou de notre notepad ! La première partie de la présentation décrit une trajectoire alternative : et si le frère d'express.js en R était devenu roi ? Et si pour communiquer sur les résultats, via des applications web, on utilisait plutôt R et {ambiorix} ? Autrement dit, et si on utilisait des méthodes basées plutôt sur les requêtes HTTP ? Alors que {shiny} est exclusivement basé sur la technologie websocket. Et maintenant, où en sommes nous ? De retour dans le présent, comment fait on dans le monde du web ? Streamlit ? Shiny pour Python ? Durant la présentation, nous ferons un point sur les avantages et les inconvénients des différentes méthodes : - des apps plus proches de ce qui est fait dans le monde du web,- une courbe d'apprentissage plus importante mais un monde du web moins obscur,- la possibilité de masquer beaucoup des problématiques du web grâce à Shiny, et c'est cool ! Et demain ? Avec Wasm et WebR, quelle place peut on imaginer pour {shiny} ?1 partout, balle au centre!",Shiny/plumber II,Présentation longue,"ingénierie, shiny, application web, back to the future",rr2023
https://rr2023.sciencesconf.org/466091,Construiriez-vous votre cuisine sans en avoir fait des plans ?,Arthur Bréant,français,"   Qui ne s'est pas déjà lancé dans le développement d'une application Shiny sans en avoir fait une maquette au préalable ? Et pourtant, le “freestyle” qui devait nous faire gagner du temps s'avère souvent être bien coûteux en essais-erreurs durant le développement. . .   Pourtant, ça ne vous viendrait jamais à l'idée de faire la même chose pour d'autres conceptions ! Imaginons que vous vouliez construire une cuisine. Vous avez tous les outils nécessaires et des matériaux de haute qualité, mais pas de plans. Est-ce que vous commenceriez à travailler immédiatement, au risque de vous retrouver avec une cuisine mal conçue et donc inutilisable ? Et bien c'est exactement ce qui se produit lorsque vous développez une application Shiny sans faire de maquette.    Je vous vois déjà me dire : “Oui, mais une maquette ça prend beaucoup trop de temps par rapport à son apport dans le développement”.   Rappelez vous qu'une maquette doit simplement vous permettre de visualiser les différents éléments de l'interface utilisateur, les graphiques, les tableaux et les différentes fonctionnalités. Et grâce à des outils comme Figma, c'est rapide et pas besoin de sortir d'école d'architecture. Vous pourrez ainsi facilement expérimenter différentes dispositions et configurations pour trouver la meilleure solution et identifier les problèmes potentiels avant de commencer le développement.   Visez juste dans votre développement et économisez temps et argent, tout ça grâce à un bon départ : avec une maquette.   Mais qu'est-ce qu'une bonne maquette ? Quelles en sont les étapes de conception ? Quels outils utiliser ? Comment impliquer les parties prenantes ? On vous montre ça au travers d'un exemple concret : la conception d'une application open-source appelée {signature}.     ",Shiny/plumber II,Présentation longue,"Shiny, Méthode d'optimisation, Maquette, Figma",rr2023
https://rr2023.sciencesconf.org/467846,{mariobox}: des APIs {plumber} à toute épreuve,Antoine Languillaume,français,"  Le package {plumber} apporte beaucoup de valeur à l'écosystème R. Ce package rend très facile le développement d'API REST depuis R. Décorez simplement vos fonctions de commentaires appropriés et rendez ainsi accessible l'environnement R à n'importe quel service via une simple requête HTTP ! Chez ThinkR nous avons eu l'occasion de faire nos armes sur des projets {plumber} d'ampleur qui sont maintenant déployés en production pour des centaines d'utilisateurs. Le fruit de notre expérience est maintenant condensé dans un package: {mariobox}. {mariobox} est en quelque sorte le cousin de {golem}. Il poursuit le même but, celui d'automatiser et de faciliter la création et la mise en production d'API REST comme {golem} le fait pour Shiny. Dans ce talk vous connaîtrez l'histoire de la genèse de {mariobox}. Comment nous l'avons utilisé pour développer des applications devant s'intégrer comme services dans le système informatique d'une grande banque. Mais aussi comment {mariobox} étend {plumber} en découplant plus proprement la logique REST de la logique métier. Nous finirons enfin par exposer la future ""roadmap"" d'un package qui, nous l'espérons apportera autant à la communauté qu'a pu le faire son cousin {golem}.  ",Shiny/plumber II,Présentation longue,"Ingénérie logicielle, API REST, framework, {plumber}",rr2023
https://rr2023.sciencesconf.org/467705,{tabnet} : Un package de deep-learning pour données tabulaires entièrement intégré à tidymodels,Christophe Regouby,français,"{tabnet} est un package d'apprentissage profond sur les données tabulaires d'après Tabnet. Il est entièrement basé sur {torch} et donc sans installation de python et s'intègre dans la suite {tidymodels}. Je démontrerai l'usage du package sur un jeu de donnée d'exemple, étape par étape, depuis la gestion des valeurs manquantes, le pré-entraînement non supervisé puis l'entraînement fin sur la tâche cible, et l'interprétation du modèle. Je vous détaillerai les évolutions en cours du package et vous ferai un retour d'expérience sur le développement à cheval entre deux univers de packages {mlverse} pour le deep-learning et {tidymodels} pour la création de modèles sans faille, et je vous donnerai l'envie de contribuer à la conversion de modèles de deep-learning en R avec {torch}.",Stats/ML/IA,Présentation longue,"Deep, learning, Données tabulaires, torch, IA, Package",rr2023
https://rr2023.sciencesconf.org/468060,fdacluster: Clustering for Functional Data,"Aymeric Stamm, Lise Bellanger, Laura Maria Sangalli, Piercesare Secchi, Simone Vantini",anglais,The fdacluster package provides implementations of the popular ,Stats/ML/IA,Présentation longue,"functional data, amplitude & phase variability, hierarchical clustering, R package.",rr2023
https://rr2023.sciencesconf.org/464435,Manipuler les moyennes mobiles avec R et JDemetra+,Alain Quartier-La-Tente,français,"   Les moyennes mobiles, ou les filtres linéaires, sont omniprésents dans l'analyse des séries temporelles : méthodes de lissage, désaisonnalisation, modélisation ARIMA, régression locale, etc. Ces objets sont toutefois difficilement manipulables sous R et aucune fonction ne permet d'étudier facilement leurs propriétés statistiques. Le package rjd3filters répond à ce besoin en permettant de facilement créer, combiner et appliquer les moyennes mobiles, ce qui facilite notamment l'enseignement des méthodes s'appuyant sur ces objets. Ce package s'inscrit dans le cadre du développement d'une dizaine de nouveaux packages, autour du logiciel JDemetra+, pour le traitement des séries temporelles qui seront présentés de manière succincte : manipulation de séries temporelles, modèles RegARIMA, désaisonnalisation, modèles espace-état, benchmarking.   ",Stats/ML/IA,Présentation longue,"Statistique, séries temporelles, moyennes mobiles, package",rr2023
https://rr2023.sciencesconf.org/461511,L'écosystème spatial de R,Timothée Giraud,français,"Si R permet depuis longtemps de traiter les données spatiales, plusieurs packages assez récents (sf, terra, stars...) ont renouvelé le socle permettant la mise en œuvre de ces traitements. La plupart des développements actuels s'appuient sur ce socle et forment un écosystème robuste qui offre aux utilisateurs la plupart des fonctionnalités autrefois réservées aux Systèmes d'Information Géographique.Lors de cet exposé nous montrerons un panorama de l'écosystème spatial de R. Nous illustrerons ce panorama à travers une série d'exemples mobilisant des données de natures différentes (données vectorielles et données matricielles ou raster) issues de la base de données géographiques libre OpenStreetMap. Nous aborderons notamment l'acquisition, la manipulation et la cartographie de données géographiques, les opérations classiques de géotraitement ainsi que des traitements plus poussés d'analyse spatiale.",Keynote IV,Keynote,"cartographie, analyse spatiale, SIG",rr2023
https://rr2023.sciencesconf.org/464300,"Pastels, paillettes et packages pour accompagner la recherche avec R",Lise Vaudor,français,"Je travaille depuis 12 ans en tant qu'ingénieure en appui à la recherche dans un laboratoire de géographie. Pour accompagner mes collègues chercheurs, enseignants, étudiants dans leurs recherches et les aider dans leurs analyses de données avec R, j'ai recours à divers outils. Le premier et celui qui profite au plus large nombre consiste à créer et proposer des supports pédagogiques (les pastels) : blog, tutoriels en ligne, illustrations, et une offre de formation interne régulière pour les membres de mon laboratoire. Dans certains cas particuliers, quand le niveau de technicité requis par une analyse est trop élevé ou que le besoin d'explorer les données de manière conviviale est fort, je préfère proposer des outils plus « clés en main » comme des applis shiny (les paillettes).  Enfin, dans d'autres cas, mon interlocuteur est un utilisateur de R plus confirmé avec un besoin spécifique et j'analyse ce besoin avec lui pour développer un certain nombre de fonctions dédiées (les packages). J'expliquerai en quoi consiste mon métier au quotidien, en présentant mon parcours personnel et en l'émaillant d'exemples de collaborations.",Keynote V,Keynote,"recherche, pédagogie, illustrations, shiny, package",rr2023
https://rr2023.sciencesconf.org/459469,Lissage spatial avec le package btb,"Kim Antunez, Julien Pramil",français,"Le lissage spatial est une méthode essentielle pour analyser l'organisation spatiale de données disponibles à un niveau géographique fin. Le package btb (« beyond the border »), développé en 2018 par des agents de l'Institut national de la statistique et des études économiques français (Insee), met en œuvre une méthode de lissage spatial par estimation par noyau quadratique à partir de données carroyées. Dans cette présentation, nous présenterons les principales fonctionnalités de btb sur un exemple concret d'application : le prix des logements vendus à Paris en 2021.",Geospatial II,Présentation longue,"Statistique spatiale, Carroyage, Lissage spatial, Statistiques urbaines, Datavisualisation",rr2023
https://rr2023.sciencesconf.org/467809,Quelle géostatistique pour des DPE à la localisation incertaine ?,"Marc Grossouvre, Didier Rullière, Jonathan Villot",français,"Planifier la transition énergétique requiert des décideurs une connaissance approfondie de leur territoire. Ce dernier est étudié à travers des données collectées de sources multiples, à diverses échelles et sous des contraintes de confidentialité. Ces données renseignent des objets, tels que les bâtiments. Ainsi, étudier la performance énergétique des bâtiments demande d'apprendre des Diagnostic de Performance Énergétique (DPE) réalisés, lesquels sont publiés avec un géolocalisation à adresse postale dont la position est incertaine. Ce travail montre que l'apprentissage des DPE observés pour prédire les DPE manquants peut être envisagé comme un problème d'interpolation spatiale. Il propose une manière de traiter le DPE en tant qu'information géolocalisée et de prédire sa valeur à l'échelle du bâtiment. La méthodologie du krigeage est appliquée à des champs aléatoires observés à des emplacements aléatoires pour trouver le meilleur prédicteur linéaire non biaisé (BLUP). Ce nouveau modèle, appelé krigeage de mixtures, estime une moyenne et une variance du DPE pour un bâtiment non observé. Ces estimations fournissent aux décideurs une valeur attendue du DPE ainsi qu'une incertitude sur la prédiction. Le cas spécifique d'une ville française est pris comme exemple. Des applications sur des données simulées sont aussi présentées, suggérant que le krigeage de mixtures puisse être utilisé plus largement pour contrôler la propagation d'incertitude. L'ensemble du travail depuis la collecte des données jusqu'à la production cartographique en passant par la modélisation et l'optimisation a été codé en R.",Geospatial II,Présentation longue,"Géostatistique, climat, rénovation, multi, échelle, MAUP",rr2023
https://rr2023.sciencesconf.org/447430,"Modèle hiérarchique de processus gaussien des plus proches voisins non stationnaire, multivarié, et non séparable, pour la modélisation des polluants atmosphériques",Sébastien Coube,anglais,"Décrire et de prédire l'exposition cumulative aux contaminants atmosphériques malfaisants tels que les oxydes d'azote, l'ozone ou les particules fines est un enjeu sanitaire et social.  Cette présentation propose une structure de modèle bayésien hiérarchique spatio-temporel combinant la nonséparabilité, la multivariabilité, et la nonstationarité. La nonséparabilité permet une description plus fidèle de la répartition des polluants. La multivariabilité permet une interprétation des interactions entre polluants, et augmente la puissance du modèle en ``empruntant de la force'' non seulement entre voisins spatio-temporels mais aussi entre variables. Enfin, la nonstationarité permet de lier des variables naturelles telles que les saisons ou anthropiques telles les limitations de vitesse à des changements de comportements des observations, tels que les pics de pollution. Un modèle avec plusieurs variables d'intérêt ainsi qu'une dimension temporelle est un défi computationnel. Une approximation de Vecchia adaptée au ``cahier des charges"" de nonséparabilité, multivariabilité et nonstationarité est proposée, afin de rendre les calculs faisables pour un grand nombre d'observations. Des algorithmes de Monte-Carlo spécialement adaptés aux modèles spatiaux et aux données de grande taille sont présentés.  La méthode présentée est utilisée sur le territoire de la Communauté Autonome Espagnole d'Euskadi.",Geospatial II,Présentation longue,"Statistique bayésienne, Statistique spatiale : Markov chain Monte, Carlo, Pollution, Processus gaussien des plus proches voisins, Approximation de Vecchia, Nonstationarité, Nonséparabilité, Multivariabilité",rr2023
https://rr2023.sciencesconf.org/447197,"La reproductibilité avec R, ou pourquoi celle-ci est située sur un continuum",Bruno André Rodrigues Coelho,français,"La reproductibilité en science est cruciale, mais elle est assez difficile à mettre en place. Il existe pourtant une multitude d'outils et de paquets pour R qui permettent de rendre un projet reproductible. Dans ma présentation, je vais lister ces outils et fournir des scripts simples, mais fonctionnels, qui vous permettront de commencer rapidement. Je vais aussi expliquer ce qu'il se passe quand l'un d'entre eux, MRAN, cessera d'exister en Juillet 2023. La reproductibilité, ce n'est pas seulement utiliser les bons outils, mais c'est aussi de la gestion des risques. Je vais donc aussi discuter d'un risque majeur qui arrivera je pense bientôt et qui risque d'impacter beaucoup de projets et comment s'en prémunir.",Workflow,Présentation longue,"reproductibilité, gestion des risques",rr2023
https://rr2023.sciencesconf.org/464283,"Faire un package R documenté, testé, versionné et intégré en quelques minutes ? Challenge accepted !",Florence Mounier,français,"L'idée reçue que faire des packages c'est long et compliqué a la vie dure. On se dit que ce n'est pas pour nous, que c'est se compliquer la vie si on n'a que peu de fonctions et que l'on ne veut pas les partager. Un package ne sert pas qu'à diffuser des fonctions, il peut aussi contenir des jeux de données, servir de template de travail au quotidien pour vos analyses et vos graphiques. Il évite souvent bien des erreurs et pertes de temps, même en travaillant seul·e. Et aujourd'hui, grâce à {fusen} et les IDE comme RStudio, plus besoin d'être un ninja pour faire un package documenté, testé et intégré sur une plateforme git. Ainsi, tout le monde peut bénéficier des avantages qui vont avec cette méthode de travail : avoir un travail fiable mais également facile à reproduire, reprendre et modifier, que ce soit par son futur soi-même ou par quelqu'un d'autre. On se propose ici de vous démontrer que faire un package est accessible et rapide en créant avec vous un package documenté, contenant une vignette, un jeu de données et une fonction avec des tests unitaires. Et ""badge sur le package"", tout cela sera partagé et versionné sur GitHub.",Workflow,Présentation longue,"Package, workflow, {fusen}, RStudio, GitHub",rr2023
https://rr2023.sciencesconf.org/464573,"{lozen}, le thermomix de vos projets de développement R",Yohann Mansiaux,français,"Vos projets de développement se ressemblent un peu tous sur Github et Gitlab ? Vous rêvez d'un outil out-of-box pour les initier ? Ou au contraire, peut-être voulez-vous homogénéiser leur fonctionnement pour vous simplifier le quotidien ? Que vous soyez apprenti développeur ou top-chef du code, avec {lozen} tout est présent pour viser un projet 3 étoiles. La recette de cuisine d'un projet aux petits oignons avec {lozen} c'est : Sortez de votre placard un projet déjà existant sur gitlab ou github ou soyons fous, inventez-en un nouveau Ajoutez si besoin les ingrédients de base d'un package R, d'une application shiny ou d'un livre bookdown Incorporez avec délicatesse tout ce qu'il faut pour une gestion efficace du code et de son devenir : templates de commit, outils d'aide à la mise en place du CI/CD N'oubliez pas l'assaisonnement indispensable pour la future dégustation de votre projet avec vous-même, vos collègues ou vos clients : génération de template d'issues (car en cuisine on ne réussit pas tout du premier coup), création et gestion de board gitlab/github et de wiki, création de rapports quotidiens ou hebdomadaires des issues, des milestones, des commits. {lozen} propose ainsi un framework complet de gestion de projet et s'inscrit dans la lignée des autres packages de développement de ThinkR pour favoriser une démarche robuste et reproductible (même si en vrai il ne fait pas la cuisine).",Workflow,Présentation longue,"Package, Gestion de projet, Github, Gitlab",rr2023
https://rr2021.sciencesconf.org/363820.html,Practical AI & Data Science Ethics,Stephanie Locke,English,"The ethical implications of our work can be staggering but how do we balance commercial needs, ethical requirements, and productivity? Taking a pragmatic approach through starting with simple checklists evolving to the use of automation and structured processes, I look at how we can make our work more robust from an ethical",Keynote,Oral presentation,Ethics,rr2021
https://rr2021.sciencesconf.org/356187.html,Scaler une application shiny,Cervan Girard,French,"Ces dernières années, `{shiny}` a trouvé sa place dans le vaste monde du développement d'applications web. Cependant, là où les outils de création et d'extensions font légion, le déploiement à grande échelle reste une thématique intimiste, apparaissant parfois comme une compétence réservée à une poignée d'initié.  Pourtant, les outils existent, et n'attendent que nous pour être utilisés. C'est ce que nous verrons dans cette présentation : comment créer et déployer une application `{shiny}` à grande échelle, et ce sans l'utilisation de RStudio Connect ou de Shinyproxy. Comment ? D'abord, en pensant ""scaling"" dès le développement, notamment en permettant l'utilisation de plusieurs sessions R (et donc plusieurs personnes) sur une même instance de l'application. Pour cela, nous prendrons quelques exemples comme l'utilisation d'un base de données externe, l'intégration d'une API REST, l'intégration de `{future}` et `{promises}`, ainsi que le caching. Pourquoi ces modifications ? Pour déporter au maximum le travail de R, et donc de `{shiny}`. À termes, cette application devient un ""passe-plat"", qui a pour objectif d'interroger une API ou une base de données, laissant uniquement à R les actions pour lesquelles il est bon : graphiques, modélisations, etc. Nous verrons que ces processus doivent être eux aussi optimisés, afin de pouvoir gérer la charge de plusieurs personnes en simultanée. Ensuite, une fois que l'application est optimisée, vient le moment de la déployer à grande échelle. Nous verrons comment déployer cette application sur plusieurs serveurs différents, et comment nous pouvons dispatcher la charge en distribuant les utilisateurs sur les différentes instances de l'application. Des exemples sont disponibles sur le repos suivant : - https://github.com/Cervangirard/scalingshiny - https://github.com/Cervangirard/bddshow",DevOps,Oral presentation,"Shiny, Scalabilité, API, Base de données",rr2021
https://rr2021.sciencesconf.org/354841.html,"Esquisse, une application pour visualiser ses données","Victor Perrier, Fanny Meyer",French,Esquisse est un package R contenant une application permettant de visualiser ses données en générant des graphiques avec le package ggplot2 ainsi que le code associé.,Dataviz,Oral presentation,"Visualisation, dataviz, ggplot2, Application web, shiny, Génération de code",rr2021
https://rr2021.sciencesconf.org/356192.html,IIDEA : Interactive Inference for Differential Expression Analyses,"Nicolas Enjalbert Courrech, Pierre Neuvial",French,"Nous avons développé l'application shiny IIDEA (Interactive Inference for Differential Expression Analyses) pour l'analyse différentielle d'expression de gènes. Celle-ci exploite les développements récents en statistique dans le domaine de l'inférence post hoc, qui fournissent des garanties statistiques plus interprétables que les méthodes classiques comme le contrôle du taux de fausses découvertes (FDR). En particulier, l'utilisateur d'IIDEA peut de façon interactive sélectionner des gènes d'intérêt à l'aide d'un volcano plot ou d'annotations biologiques, et obtenir une garantie sur le nombre ou la proportion de gènes différentiellement exprimés dans cette sélection. IIDEA est déployée sur le lien suivant : \url{https://shiny-iidea-sanssouci.apps.math.cnrs.fr/} .",Dataviz,Oral presentation,"shiny, dataviz, expression différentielle, volcano plot, analyse d'enrichissement, inférence post hoc",rr2021
https://rr2021.sciencesconf.org/356357.html,Conception d'applications Shiny avec {golem},Vincent Guyader,French,"Construire une application en tant que Preuve de concept est facile, mais les choses se compliquent lorsque l'application devient plus grosse et plus complexe, surtout lorsqu'il s'agit d'envoyer cette application en production.{golem} est un package qui offre aux développeurs Shiny un cadre pour créer des applications Shiny dans les règles de l'art.",Shiny,Oral presentation,"shiny, golem",rr2021
https://rr2021.sciencesconf.org/355827.html,Prendre en charge des opérations chronophages depuis Shiny avec Shinybatch,"Thibaut Dubois, Benoit Thieurmel",French,"Il est peu pratique de réaliser de longues opérations dans une application Shiny, car l'application est indisponible pendant tout le temps de la résolution. Pour certains usages cependant, la possibilité de lancer des taches depuis l'application est un atout. Nous proposons une solution packagée comprenant deux modules Shiny. Le premier module permet de paramétrer des opérations qui seront ensuite lancées en tâche de fond par batch. Le second module consiste ensuite en une interface qui permet de suivre la résolution des opérations et facilite la récupération des résultats.",Production-ready R,Oral presentation,"Shiny, opérations chronophages, monitoring",rr2021
https://rr2021.sciencesconf.org/365277.html,S'il-vous-plaît... dessine-moi un projet,Maëlle Salmon,French,"Bien structurer ses projets R, c'est utile, même si l'on n'a pas des collaborateurs ou collaboratrices aussi exigent·e·s que le Petit Prince. Mais on fait comment ? On met le projet dans un boa ou une boîte à trous ? Dans cette présentation, je vous parlerai d'outils qu'il est bon d'apprivoiser : here, renv, targets, devtools... ça vous dit quelque chose ? Faire de tout un paquet R, pour, contre, ou réponse de Normand·e ? Après m'avoir écoutée, vous aurez en poche des astuces à rapporter sur votre planète pour faire fleurir vos roses et mourir vos baobabs, avec la confiance pour développer votre propre manière de jardiner.",Keynote,Oral presentation,Packages,rr2021
https://rr2021.sciencesconf.org/356094.html,Présentation de la démarche PROPRE - PROcessus de Publications REproductibles,"Diane Beldame, Juliette Engelaere-Lefebvre, Maël Theulière",French,"Depuis 2017, le datalab de la DREAL Pays de la Loire a expérimenté de nouvelles méthodes de travailautour du Design Thinking et des méthodes Agiles pour réaliser ses publications statistiques.En 2019, dans le prolongement des mutations plus centrées sur les besoins de ses clients, le datalab opèreun pivot plus technique : d'une culture de la donnée il se tourne vers une culture logicielle et le formalise par ladémarche PROPRE pour PROcessus de Publications REproductibles. Inspiré du Reproductible AnalyticalPipeline du gouvernement britannique, cette approche utilise l'objet technique qu'est le paquet R commevéhicule de la publication statistique. Les développements sont versionnés, factorisés, documentés, testés etintégrés au sein d'une forge logicielle qui permet de mutualiser, rationaliser et sécuriser les productions. Àl'écoute active des besoins de ses clients d'un côté et soucieux de l'opérationnalité en production de l'autre,le statisticien métamorphose son métier vers un continuum DataOps.Cette présentation décrit cette (r)évolution, les principaux résultats et les conditions de sa réussite.",DevOps,Oral presentation,"DevOps, DataOps, Institution publique, package",rr2021
https://rr2021.sciencesconf.org/353570.html,Environnement R et GitLab CI/CD,"Jean-François Rey, Loic Houde",French,"De nos jours, les outils de gestion de projets informatiques sont largement répandus, beaucoupd'entre eux fournissent une partie spécifique de la gestion du cycle de vie des projets ou sont dessolutions tierces. Cela est particulièrement vrai pour l'environnement R. Nous présentons ici notre solution utilisant un seul outil, GitLab CE, un outil open core et libre, quinous permet de faciliter le développement collaboratif de code R, l'automatisation pour la validationet la construction de package R, ainsi que le déploiement d'applications R-Shiny. Cette solution locale dans notre laboratoire nous permet (1) d'accélérer le développement et lepartage de packages R sur différents OS et la soumission au CRAN en réduisant les erreurs possibles.Mais elle permet aussi (2) la mise à disposition d'applications R-Shiny immédiatement accessibles.",DevOps,Oral presentation,"Ingénierie, Intégration, Automatisation, Package, Shiny",rr2021
https://rr2021.sciencesconf.org/356177.html,Construire et maintenir une plateforme de calcul R avec JupyterHub,David Gohel,French,"Utiliser R en production dans une organisation nécessite l'administration d'un écosystème R. La mise à disposition au sein d'un système d'information existant de l'outil R et plus généralement d'outils open source pour la data-science est une tâche complexe. Il faut maîtriser les versions mises à dispositions, permettre l'utilisation et l'accès aux données dans un cadre sécurisé, permettre les mises à jour fréquentes de l'outil et des packages utilisés. Il existe une solution pour aider à cette administration, le projet open source JupyterHub qui va être présenté à travers un cas réel d'utilisation. ",DevOps,Oral presentation,"R, production, serveur, docker, kubernetes",rr2021
https://rr2021.sciencesconf.org/355764.html,{fusen}: Créer un package R à partir de simples fichiers Rmarkdown,Sébastien Rochette,French,"Vous savez comment construire un Rmarkdown pour la reproductibilité, on vous a dit ou vous voudriez mettre votre travail dans un paquet R, mais vous pensez que c'est trop de travail ? Vous ne comprenez pas où mettre quoi et quand ? Et si écrire un Rmd était la même chose qu'écrire un package ? Laissez-moi vous présenter {fusen} pour vous aider dans cette tâche...",DevOps,Oral presentation,"Package, Rmd first, Apprentissage, Développement",rr2021
https://rr2021.sciencesconf.org/356452.html,Développement sous R de la base de données DEEP (Données Economiques des Elevages de Porcs),"Bérengère Lécuyer, Sandrine Lunven",French,"Le pôle économie de l'IFIP (Institut du Porc), avec l'aide de TAC ECONOMICS, a procédé à une refonte de son système d'information en 2020, visant notamment à automatiser l'enregistrement de données économiques et sectorielles. Une quarantaine de connecteurs ont été développé permettant d'extraire automatiquement des données provenant de sources différentes, nationales (INSEE, France AgriMer, RNM etc.) et internationales (Europe, Brésil, Chine, etc.) et de les enregistrer dans la base DEEP. Cette présentation a pour objectif de présenter en détails les aspects techniques de ce projet, développés avec le logiciel R.",Production-ready R,Oral presentation,Connecteurs Data – Economie – Automatisation – Base de données,rr2021
https://rr2021.sciencesconf.org/355209.html,{wedding} : une application Shiny pour aider les futur.e.s marié.e.s dans leurs préparatifs du jour J,Margot Brard,French,"Depuis plusieurs années, des solutions permettant aux futur.e.s marié.e.s de créer un site internet dédié à leur mariage florissent sur la toile. Ces sites ont principalement vocation à informer les invités sur des aspects logistiques liés au déroulement de la journée du mariage. Ils permettent également aux invités d'indiquer leur présence ou non à l'événement grâce à un formulaire. Cependant, aucun de ces sites ne semble proposer aux futur.e.s marié.e.s une double fonctionnalité : 1. informer et échanger avec leurs convives et 2. piloter les préparatifs de leur mariage. {wedding} a été développé dans ce but. Il s'agit d'un package qui lance une application Shiny. En plus des onglets à vocation informative dédiés aux invités, les marié.e.s ont accès - via mot de passe - à un onglet qui leur est dédié. Ils y trouvent un dashboard avec toutes les informations relatives aux préparatifs du mariage : dépenses, liste des invités, nombre de confirmations, etc. L'application est alimentée par des jeux de données stockés sous la forme de Google Sheets, qui sont mis à jour dans le Google Drive selon les interactions de l'utilisateur pendant sa navigation sur l'application. Dans un soucis de cohérence avec les faire-parts du mariage, un template css personnalisé a été créé. L'application Shiny est déployée en production et son accès est sécurisé via un système login/mot de passe. Une version de démo de l'application Shiny est accessible à l'adresse suivante : https://connect.thinkr.fr/wedding (identifiant : welcome, mot de passe : bigday, mot de passe pour l'espace mariés : onlyforbride). Le code du package est disponible à l'adresse suivante : https://github.com/ThinkR-open/wedding.",Production-ready R,Oral presentation,"Application Shiny, Package, Google Drive, Déploiement, Mariage",rr2021
https://rr2021.sciencesconf.org/356160.html,Epistack : Visualisation de profils épigénétiques,"Safia Saci, Laura Morel, Guillaume Devailly",French,"Epistack est un package R (prochainement soumis à Bioconductor) permettant la génération d'une visualisation informative très utilisée en bioinformatique : les piles de profils épigénétiques centrées sur un type de région donnée (promoteurs de gènes, sommets de piques, etc.). Il se veut (un peu) plus simple d'utilisation que les méthodes alternatives existantes, tout en restant suffisamment flexible pour s'adapter à un grand nombre de situations. Une attention particulière a été portée au problème d'overplotting lorsqu'un grand nombre de régions (> 10 000) est visualisée en même temps.",Packages,Lightning talk,"bioinformatique, génomique, épigénétique, Bioconductor, visualisation",rr2021
https://rr2021.sciencesconf.org/355822.html,"Construire, visualiser et télécharger des tableaux croisés avec Shinypivottabler","Benoit Thieurmel, Thibaut Dubois",French,"Le package shinypivottabler propose un module shiny permettant de laisser la possibilité à un utilisateur métier de définir, analyser et télécharger des tableaux croisés. Les calculs se faisant côté server, il permet également l'utilisation de jeux de données conséquent.",Packages,Poster,"Statistique descriptives – Tableaux croisés – Shiny, Visualisation",rr2021
https://rr2021.sciencesconf.org/356116.html,Application Air'shiny pour le suivi des épisodes de pollution,Morgane Salomon,French,"Le programme CARA « Caractérisation chimique et sources des particules » du dispositif national de surveillance de la qualité de l'air a été mis en place en 2008, en réponse au besoin de compréhension et d'information sur l'origine des épisodes de pollution particulaire. Ce dispositif s'appuie à la fois sur des prélèvements in situ et des mesures automatiques réalisées par les AASQAs. Grâce à la centralisation des données d'analyseurs automatiques (ACSM et AE33) sur la base nationale de données de qualité de l'air appelée Geod'Air, un outil de visualisation en quasi-temps réel a pu être développé en 2018 sur R-Shiny. Cet outil permet d'échanger plus rapidement afin de comprendre les épisodes de pollution.",Shiny,Lightning talk,"Episodes de pollution – CARA – ACSM – AE33 – Particules, RShiny",rr2021
https://rr2021.sciencesconf.org/356475.html,Création de rapports automatisés avec bookdown et GitLab Pages pour le suivi de projet,Marion Louveaux,French,"Pour faciliter les échanges avec les utilisateurs et le suivi des projets dont j'ai la responsabilité sur la plateforme d'analyse d'images de l'institut Pasteur, j'ai mis en place un cadre de travail basé sur des rapports bookdown, git et GitLab Pages. Les rapports créés ont une structure commune qui (1) présente le projet, (2) décrit les méthodes d'analyses, (3) présente les résultats, mais aussi (4) recense les échanges avec les utilisateurs, ainsi que les moments clés du projet, ce qui limite la perte d'information et permet d'avancer dans un cadre serein. Comme j'utilise toujours la même structure de projet, et que certaines informations sont répétées d'un rapport à un autre, j'ai créé le package R {bookprep}, pour automatiser la création de ce cadre de travail.",DevOps,Lightning talk,"reproductibilité, RMarkdown, bookdown, GitLab Pages",rr2021
https://rr2021.sciencesconf.org/356439.html,Gouvdown - Une implémentation de la marque État,"Thomas Vroylandt, Romain Lesur, Theuière Maël",French,"Les services du Gouvernement ont renové en 2020 la [marque de l'État français](https://www.gouvernement.fr/marque-Etat. Ils proposent une charte graphique complète et cohérente articulée autour de couleurs,d'éléments typographiques (dont la police Marianne) ainsi que de blocs-marques pour chaque administration.Inspirés par les travaux réalisés outre-Manche autour du package govdown qui permet d'utiliser directementdans R les éléments de la charte publique britannique, le package gouvdown a été créé par des agents publicspour proposer une prise en main et une implémentation facilitée des éléments de la marque État. Cetteprésentation a pour objectif de détailler le contenu de ce package et d'en présenter quelques exemplesd'utilisations.",R for administration,Lightning talk,"RMarkdown, Design, Service Public",rr2021
https://rr2021.sciencesconf.org/363677.html,It's raining R packages,Colin Gillespie,English,"If you have the good fortune to work in an organisation that uses R, you are probably familiar with the very sensible R dogma that everything should be a package. Your analysis should be an R package. Your Shiny app should be an R package. Your weekly R markdown should be an R package. While this is definitely the way to go, it is easy to create a package war zone. Everywhere you look, you'll find packages in various states of creation. How do you manage this chaos? This talk will discuss practical steps in taming the R package monster. I'll discuss methods for keeping on top of your teams' packages, how to separate out dev / prod and how to ensure insecure practices don't slip in.",Keynote,Oral presentation,Good practices R dev,rr2021
https://rr2021.sciencesconf.org/363681.html,"RENKU, une plate-forme libre et ouverte pour une science des données collaborative et reproductible",Christine Choirat,French,"Renku (https://renkulab.io/) est un logiciel libre développé par le Swiss Data Science Center de l'ETH Zürich et de l'EPFL (https://datascience.ch/) pour faciliter le travail collaboratif et la reproductibilité en science des données. Rendu s'appuie sur des logiciels établis tels que git et Docker pour fournir les outils nécessaires pour travailler de manière reproductible, tout en offrant la flexibilité de laisser les utilisateurs utiliser e langage de leur choix, R bien sûr, mais aussi par exemple Python ou Julia.Dans ce workshop, nous expliquerons l'architecture de la plateforme Renku et de la place centrale qu'occupe le Knowledge Graph. Nous montrerons comment Rendu peut interagir l'écosystème de R, en particulier pour la gestion et la création de packages. Une fois que nous aurons mis en place un projet, nous travaillerons sur un exemple de construction d'un workflow R reproductible.Ces outils qui permettent un travail reproductible peuvent aussi être utilisés pour résoudre certains des problèmes rencontrés lors de l'enseignement d'une classe à de nombreux étudiants. A titre d'illustration, nous présenterons une configuration qui peut être utilisée pour enseigner une classe avec R et fournirons une comparaison de Renku par rapport à des alternatives comme Binder.",Workshop: Reproducible Science,Oral presentation,Science reproductible,rr2021
https://rr2021.sciencesconf.org/354661.html,Empirical and non-parametric copula models with the cort package,Oskar Laverny,English,"The R package cort implements object-oriented classes and methods to estimate, simulate and visualize certain types of non-parametric copulas. The classic empirical checkerboard copula, and the empirical chekerboard copula with known multivariate margins are avalailables. The core of the package is the Cort algorithm, for Copula Recursive Trees. This algorithm performs a recursive local splitting of the unit hypercube, much like the CART regression algorithm, to fit a piecewise constant copula density. We also provide an efficient way of mixing copulas, allowing to bag the previous algorithms into forests. The algorithms implemented in this package and the corresponding implementation choices will be developped. ","Statistics, ML, AI",Oral presentation,"Dependence structure, copula, non, parametric estimation, checkerboard, cort, piecewise linear distribution functions",rr2021
https://rr2021.sciencesconf.org/356230.html,"aRchéologie : les usages disciplinaires de R, entre recours génériques et développement de packages spécifiques. Un état des lieux en archéologie",Sébastien Plutniak,French,"L'adoption de R dans les différentes disciplines scientifiques est menée en tension entre, d'une part, le recours aux méthodes génériques de transformation, d'analyse et de visualisation de données et, d'autre part, le développement de packages spécifiques. Cette tension sera illustrée à partir du cas de l'archéologie, en abordant: 1) l'historique des recours à R dans ce domaine au cours des vingt dernières années ; 2) un état des lieux actuel des usages, de la communauté, et des packages disponibles pour des problèmes spécifiques à l'archéologie ; 3) la présentation de l'un de ces packages, archeofrag, permettant d'évaluer la robustesse de distinctions spatiales (e.g., entre couches archéologiques) à partir des relations entre les fragments d'objets matériels brisés et dispersés dans l'espace d'un site archéologiques.",Packages,Oral presentation,"archéologie, packages, interdisciplinarité, analyse spatiale",rr2021
https://rr2021.sciencesconf.org/356468.html,Pagedown - utilisations possibles et création de thèmes,Thomas Vroylandt,French,"La génération de PDF paginés depuis RMarkdown est souvent passée par LaTeX (comme le prouve leprésent résumé). Depuis la création du package {pagedown}, d'autres possibilités sont offertes aux utilisateurspour créer des documents de qualité, plus abordable dans leur développement puisqu'utilisant des technologiesWeb (HTML, CSS, JS) et visuellement attractifs.L'objet de cette présentation est de décrire les possibilités offertes par {pagedown}, d'en montrer quelquesutilisations, et d'aborder la personnalisation de son propre template.",Packages,Oral presentation,"RMarkdown, Pagedown, Design",rr2021
https://rr2021.sciencesconf.org/356229.html,utilitR: une documentation utile pour R,"Lino Galiana, Olivier Meslin",French,"La documentation utilitR est un projet open source, collaboratif, destiné à tout utilisateur de R dans le cadre d'un usage courant d'analyse de données. Le projet utilitR se distingue d'une documentation classique en proposant une approche par tâche (importer, manipuler des données, réaliser des graphiques, cartes, etc.), sur données réelles, avec des recommandations précises sur les packages à privilégier et des conseils sur les bonnes pratiques ou la démarche à adopter face à un problème. Les fonctionnalités les plus avancées de l'écosystème R Markdown (principalement bookdown, blogdown et pagedown) sont mobilisées afin de produire, avec les mêmes fichiers sources, un site web actualisé en continu (https://www.utilitr.org), une version paginée de chaque chapitre pour une impression simplifiée et une version complète de la documentation dans un PDF de plus de 350 pages. utilitR sert également de laboratoire aux méthodes d'intégration et de déploiements continus à l'Insee. En acculturant une vingtaine de contributeurs à mener un projet open source exigeant, utilitR préfigure les futures méthodes de diffusion des travaux statistiques.",R for administration,Oral presentation,"Documentation, Open Source, R Markdown",rr2021
https://rr2021.sciencesconf.org/353816.html,R in support of Environmental Risk Assessment,"Sandrine Charles, Virgile Baudrot",English,"Package `morse` is devoted to the analysis of experimental data collected from standard toxicity tests [@Baudrot2021]. It provides ready-to-use functions to visualize raw data and to estimate several toxicity indices to be subsequently used in support of environmental risk assessment in full compliance with regulatory requirements. Such toxicity indices are indeed classically requested by standardized regulatory guidelines on which national agencies base their evaluation of applications for marketing authorisation of active chemical substances.Package `morse` can be used to get estimates of $LC_x$ ($x$\% Lethal Concentrations) or $EC_x$ ($x$\% Effective Concentrations) by fitting standard dose-response models on toxicity test data. Risk indicator estimates as well as model parameters are provided along with the quantification of their uncertainty. Package `morse` can also be used to get estimates of $NEC$ (No Effect Concentrations) by fitting a Toxicokinetic-Toxicodynamic (TKTD) model (namely `GUTS` models, that is *General Unified Threshold models of Survival*). Using `GUTS` models also allows to get estimates of $LC_{(x,t)}$ (whatever $x$ and $t$) and $LP_{(x,t)}$ ($x$\% Lethal Profile), this later being defined by the European Foof Safety Authority as the $x$\% multiplication factor leading to an additional reduction of $x$\% in survival at the end of an exposure profile. Above all, `GUTS` models can be used under environmentally realistic time-variable exposure profiles, package `morse` providing all features to easily perform prediction of the survival over time associated with the uncertainty, propagated from a previous calibration process.This talk will illustrate a typical use of package with survival data collected over time and at different increasing exposure concentrations, analysed with the reduced version of GUTS models based on the stochastic death hypothesis (namely, the `GUTS-RED-SD` model). This case studies can then be followed step-by-step to analyse any new data set, as long as the data set is correctly formatted.",Packages,Oral presentation,"Toxicity indices, Modelling, Bayesian inference, R, package",rr2021
https://rr2021.sciencesconf.org/365381.html,Science de données humanitaire avec R,Ahmadou Dicko,French, Comment développer des rapports humanitaires reproductibles,Keynote,Oral presentation,Reproductibilité,rr2021
https://rr2021.sciencesconf.org/356189.html,"Clustering-based models in R, with application on univariate Gaussian mixtures: review, evaluation and extensions","Bastien Chassagnol, Gregory Nuel, Pierre-Henri Wuillemin, Mickaël Guedj, Etienne Becht",English,"Finite mixture models are increasingly used for modeling and dealing with stochastic problems such asclustering, classification and regression, with many applications in biological fields. Unsurprisingly, manypackages have been developed to fit mixture models, arising the natural question which is the best suited one,depending on the use case.However, to our knowledge, no review describing the main features offered by these packages and comparingtheir computational and statistical performances has been performed. In this talk, we focus on packagesimplementing the EM algorithm on univariate Gaussian mixture distributions, being the most common use case.","Statistics, ML, AI",Oral presentation,"modèles de mélange, clustering, algorithme EM, benchmark",rr2021
https://rr2021.sciencesconf.org/351152.html,Modèles de Processus Gaussiens des plus proches voisins non stationaires : architecture hiérarchique et méthodes MCMC,"Sébastien Coube, Sudipto Banerjee, Benoit Liquet",French,"La modélisation spatiale non stationnaire est une approche intéressante et prometteuse, mais elle souffre de plusieurs problèmes : son coût computationel, la complexité et le manque de lisibilité de modèles hiérarchiques à plusieurs étages, et la difficulté de sélectionner un modèle. Nous répondons à ces trois problèmes en introduisant un modèle non stationnaire utilisant les processus gaussiens des plus proches voisins (NNGP, pour Nearest Neighbor Gaussian Process). Les NNGP, précis et économiques, sont un bon départ pour répondre au problème du temps de calcul.Nous étudions le comportement des NNGP utilisant une fonction de covariance non stationnaire analytiquement et empiriquement. Nous introduisons une architecture de modèle lisible afin de faciliter la compréhension des résultats et la sélection de modèles. En particulier, nous créons une famille de modèles cohérente qui rassemble les processus spatiaux avec portée stationnaire, les processus non stationnaires avec des paramètres de portée circulaires, et ceux avec des paramètres de portée elliptiques. Nous tirons parti de notre architecture hiérarchique et de l'utilisation des NNGP en proposant un algorithme de Langevin ajusté par un pas de Metropolis. Nous améliorons cet algorithme en utilisant la méthode de l'entremêlement de paramétrisations. Nous implémentons nos méthodes en R et les testons avec des jeux de données synthétiques pour trouver des règles empiriques concernant le choix des hyperparamètres et la sélection de modèle.Nous les utilisons pour analyser un jeu de donnés de pollution au plomb aux États-Unis d'Amérique.","Statistics, ML, AI",Oral presentation,"Processus gaussien des Plus Proches Voisins, Modèle spatial non stationnaire, MCMC",rr2021
https://rr2021.sciencesconf.org/354669.html,Clustering sparse des données mixtes avec le package R vimpclust,"Alex Mourer, Marie Chavent, Madalina Olteanu, Jérôme Lacaille",French,"Cette présentation s'intéresse à la sélection de variables dans le contexte du clustering et plus précisément au clustering sparse des données mixtes (mélange de variables numériques et catégorielles). Nous illustrons une méthode que nous avons déjà introduite dans une publication, qui combine un pré-traitement des variables catégorielles et une extension de l'algorithme des K-means sparse au cas group-sparse. Cette méthode est implémentée dans le package R vimpclust disponible sur le CRAN vimpclust.","Statistics, ML, AI",Oral presentation,"clustering sparse, $K$, means pondéré, données mixtes",rr2021
https://rr2021.sciencesconf.org/364367.html,Tours for the dynamic visualization of high-dimensional data,Ursula Laa,English,"Data commonly comes with more than two measured variables, making it complicated to plot on a page. With tour methods we can view data in more than three dimensions, as an animated sequence of interpolated low-dimensional projections. This talk will briefly review tour methods, explain how to use them in practice via the R implementation in the tourr package, and show some of the recent developments and applications. The discussion is based on the review of the state-of-the-art of tours (preprint available in arXiv:2104.08016).","Statistics, ML, AI",Oral presentation,"tours, data visualization, high, dimensional data, data science, exploratory data analysis",rr2021
https://rr2021.sciencesconf.org/355802.html,IcaRius et Funcamp : un jeu vidéo d'apprentissage de la langue des Runes,"Arnaud Degorre, Diane Beldame",French,"Afin de placer R au cœur de son environnement de traitement de la donnée, l'Insee a engagé ces dernières années un ambitieux plan de formation de ses collaborateurs. La découverte de R est parfois entravée par des barrières psychologiques pour celles et ceux qui, habitués à des environnements plus fermés - et donc plus guidés – y voient un environnement de programmation complexe. Afin de lever ces obstacles, l'Insee, aidé par la communauté des statisticiens publics et par l'organisme de formation ThinkR, a créé un serious game proposant une nouvelle expérience d'apprentissage. Ce serious game propose de combiner un jeu vidéo et des challenges d'apprentissage via des tutoriels interactifs R. Proposé en Open Source et publié sur le compte Github InseeFrLab, il se compose d'un volet pédagogique avec un package R et son orchestration conteneurisée via une plateforme Cloud, et un volet ludique avec un Role Playing Game programmé en Lua via le moteur Solarus. Une centaine de stagiaires dans les établissements de l'Insee en région ont suivi avec succès le funcampR en 2020 et début 2021, pour la plupart dans un format complétement dématérialisé.",R and teaching,Oral presentation,"serious game, apprentissage, pédagogie, jeu vidéo, tutoriel",rr2021
https://rr2021.sciencesconf.org/355271.html,Utilisation du package learnr pour enseigner l'élevage de précision sous la forme d'escapes games numériques,"Adrien Lebreton, Anaëlle Bouqueau, Maxime Dumesny, Marie-Pierre Etienne, Yannick Le Cozler, Maxime Legris, Estelle Leroux, Amélie Fischer",French,"L'augmentation de l'implication des nouvelles technologies dans le pilotage de l'élevage (élevage de précision) implique que les futurs acteurs de la filière devront avoir des compétences en science des données. La science des données et l'utilisation du logiciel R, bien qu'enseignées en école d'agronomie, rebutent certains étudiants, y compris ceux intéressés par l'élevage de précision. Apprendre en jouant permet de lever certains de ces obstacles. C'est pourquoi, nous avons développé deux escapes games sérieux et numériques (EGSN) sous le logiciel R via le package learnr [1]. Ce travail présente la démarche de conception, les séquences pédagogiques des EGSN, les résultats des premiers tests, et les avantages et limites de l'utilisation de R pour faciliter l'apprentissage. Ces EGSN immergent les étudiants dans les séquences d'apprentissage, via un tutoriel interactif ludique afin d'aborder différentes notions zootechniques et de science des données. Chaque EGSN contient une introduction, une période de jeu et une période de débriefing entre les enseignants et les étudiants pour ancrer les connaissances. L'évaluation du jeu lors des premiers tests montre un fort investissement et une forte adhésion des étudiants à ce mode d'apprentissage. La prochaine étape concernera le développement d'une méthode d'évaluation pour vérifier la validation des acquis.",R and teaching,Oral presentation,Enseignement – Jeu sérieux – Science des données – Elevage de précision –– Learnr,rr2021
https://rr2021.sciencesconf.org/356473.html,Retour d'expérience sur l'enseignement de la science des données biologiques en classe inversée,"Guyliann Engels, Philippe Grosjean",French,"R est enseigné dans les cours de science des données du cursus en biologie de l'Université de Mons, en Belgique. Cinq cours en classe inversée et apprentissage par projet sont dispensés sur les quatre dernières années de la formation (du deuxième bachelier à la seconde années de Master). Nous utilisons le package {learnitdown} afin de gérer nos différents outils d'apprentissage {bookdown}, h5p, {learnr}, {shiny} et les projets individuels ou de groupes sur GitHub. L'ensemble de ces activités sont analysées afin d'obtenir un suivi précis en temps réel de l'évolution de chaque étudiant. Ces derniers peuvent également consulter un rapport de progression individuelle à tout moment. Cet exposé s'intéresse l'apprentissage des étudiants analysé au travers de ces données.",R and teaching,Oral presentation,"Science des données biologiques, suivi de l'apprentissage, classe inversée, learnitdown",rr2021
https://rr2021.sciencesconf.org/356477.html,Perception de R et RStudio par des apprenants dans des cours de science des données biologiques,Philippe Grosjean,French,"Faut-il enseigner les statistiques ou les sciences des données à des apprenants ""non techniques"", c'est-à-dire, potentiellement réticents à l'utilisation d'un ordinateur et à la programmation, avec un environnement logiciel constitué de R, RStudio, R Markdown et git\ ? Notre expérience de trois années d'enseignement des sciences de données biologiques en classe inversée et par projets dans un cursus universitaire (voir pour le matériel en ligne) donne de bons résultats. Cependant, la question relative à la perception de ces outils par les apprenants n'a, à notre connaissance, pas encore été abordée. Cet exposé présente l'utilisabilité perçue de ces logiciels, la charge cognitive liée à l'utilisation de tutoriels {learnr} pour assurer la transition entre théorie et pratique, ainsi que l'émotion prédominante à l'utilisation d'un tel environnement logiciel. Le caractère pointu de ces outils est clairement perçu et peut générer un stress perceptible chez les primo-apprenants (durant notre premier cours en second Bachelier). Mais une pédagogie sur la durée (au moins trois quadrimestres successifs) et évolutive évitent une confrontation brutale aux fonctions les plus techniques, ce qui amène les apprenants à s'approprier progressivement ces logiciels avec au final, une perception positive de leur expérience.",R and teaching,Oral presentation,"RStudio IDE, Science des données, Apprentissage, Perception, Environnement logiciel",rr2021
https://rr2021.sciencesconf.org/352894.html,mFD: an R package to compute and plot Functional Diversity,Camille Magneville,English,"Functional diversity (FD), the diversity of organisms attributes that relates to their interactions with the abiotic and biotic environments, is a core biodiversity component. FD has been increasingly assessed for the last two decades in ecology to unravel the response of species assemblages to natural or anthropogenic pressures and their effects on ecosystem functioning. FD is multifaceted and to measure its facets, several frameworks and indices have been proposed. The mFD package is an R package which provides a set of “user-friendly” functions covering all the steps of FD-based analyzes to compute 16 functional diversity indices with, in addition, customizable graphical representation of key outputs based on ggplot2 framework. mFD comes with a dedicated website that provides a set of tutorials to help new-comers in the field to compute and analyze FD .",Packages,Lightning talk,"R Package, Functional Traits, Alpha Diversity, Beta Diversity, Functional Space",rr2021
https://rr2021.sciencesconf.org/353929.html,Vulgariser la méthode de Cross-Entropy. De la résolution du Mastermind à l'admission d'étudiants dans des universités,"Kim Antunez, Alain Quartier-La-Tente",French,La Cross-Entropy est une méthode adaptée pour résoudre des problèmes d'optimisation combinatoire. Nous avons implémenté l'algorithme en langage R et l'avons ensuite appliqué sur deux cas pratiques : la résolution du Mastermind et la répartition d'étudiants dans des universités.,"Statistics, ML, AI",Lightning talk,"Statistique, Optimisation combinatoire, R, Rstats",rr2021
https://rr2021.sciencesconf.org/356038.html,graph4lg: un package R pour construire et analyser des graphes en écologie du paysage et génétique des populations,Paul Savary,French,"Modéliser la connectivité écologique des habitats et son influence sur la biodiversité est nécessaire pour améliorer la compréhension des processus écologiques et guider les mesures de conservation de la biodiversité. Cela requiert d'analyser des données spatiales afin de cartographier les espaces contribuant à cette connectivité. Les réseaux d'habitat des espèces étudiées peuvent être représentés sous la forme de graphes paysagers dont les noeuds correspondent aux taches d'habitat et les liens aux chemins de dispersion potentiels entre ces taches. Ces graphes permettent de calculer des métriques pour guider la gestion des espaces naturels ou pour des analyses statistiques ultérieures. En effet, les graphes paysagers peuvent être confrontés à des données empiriques issues du terrain pour (i) valider leur réalisme écologique ou (ii) tester des hypothèses sur le lien entre la connectivité des habitats et des réponses biologiques. Les données génétiques sont particulièrement adaptées à ces analyses dans la mesure où la structure génétique des populations est influencée par la connectivité de leurs habitats. Ces données peuvent également être analysées sous forme de graphes génétiques, dont les noeuds correspondent à des populations composées de plusieurs individus et les liens aux échanges génétiques les plus significatifs entre populations. Des progrès conséquents ont amélioré l'utilisation des graphes génétiques et paysagers mais un outil réunissant une large gamme de paramètres de construction et d'analyse de ces deux types de graphes faisait défaut. Par ailleurs, malgré la complémentarité de ces graphes, peu de méthodes d'analyse permettent de les comparer. Nous avons donc développé un package R pour faciliter et encourager l'utilisation de ces graphes. Il intègre des fonctions dédiées à la conversion et à l'import de données génétiques et au calcul de distances génétiques, de distances géodésiques, mais aussi de distances-coût. Ces dernières intégrent la résistance du paysage au déplacement des espèces. Une gamme importante de paramètres peuvent ensuite être utilisés pour créer les graphes, notamment des méthodes d'élagage différentes. Nous avons rendu accessible le logiciel Graphab aux utilisateurs de R pour faciliter la construction et l'analyse de graphes paysagers dans cet environnement. L'utilisation de programmes codés en Java à l'aide de R permet l'intégration de Graphab au package est sans que l'utilisateur ait à changer d'environnement.Par ailleurs, les fonctions du package réalisent des analyses préliminaires ayant pour but d'adapter les méthodes de construction des graphes aux questions de recherche. Les graphes génétiques et paysagers ainsi créés peuvent être analysés avec des métriques calculées au niveau des noeuds ou partitionnés en modules. Les utilisateurs visualisent et/ou cartographient les résultats de ces analyses. Une des principales originalités de graph4lg repose sur ses fonctions dédiées à la comparaison de graphes. Cette comparaison s'effectue au niveau des noeuds, des liens ou des modules de deux graphes. Enfin, l'utilisateur peut exporter les graphes sous forme de couches shapefile pour faciliter leur intégration à un SIG. graph4lg contribue au potentiel des graphes génétiques et paysagers pour l'analyse de la connectivité écologique des habitats, tout en encourageant de futures recherches sur les aspects méthodologiques relatifs à ces outils.","Statistics, ML, AI",Lightning talk,"Connectivité écologique, Théorie des graphes, Génétique des populations, Ecologie du paysage",rr2021
https://rr2021.sciencesconf.org/353751.html,"Erreurs d'annotation en deep learning, et quantification statistique des interactions prédateurs-proies en écologie.",Olivier Gimenez,French,"Les interactions prédateurs-proies façonnent les communautés animales. Le piégeage photographique permet d'étudier ces relations à partir de l'identification des espèces sur les photographies prises en conditions naturelles. Pour annoter automatiquement de grandes quantités de photographies, le deep learning est de plus en plus utilisé. Deux difficultés se posent toutefois. Premièrement, la reconnaissance n'est pas parfaite, et les taux d'erreur ne sont pas nuls. Deuxièmement, le principal langage du deep learning, Python, est peu connu des écologues. Dans cette communication, on se pose la question de l'effet du taux d'erreur dans l'identification des espèces sur l'inférence des interactions entre elles. L'analyse est faite entièrement sous R, un langage bien connu des écologues. ","Statistics, ML, AI",Lightning talk,"Ecologie Statistique, Relations prédateurs, proies, Modèles d'occupancy, Deep Learning, Traitement d'images",rr2021
https://rr2021.sciencesconf.org/356135.html,linmodel – Un package fournissant une application shiny pour les modèles linéaires et les tests non paramétriques,"Pierre Santagostini, Angelina El Ghaziri",French,"Le package linmodel fournit une application shiny pour appliquer les modèles linéaires (analyse de la variance, régression) et les tests non paramétriques (Kruskal Wallis, Friedman) d'une manière structurée, grâce à une interface simple. L'ensemble des résultats associés aux modèles linéaires sont affichés suivant une logique en trois étapes : (1) description des données, (2) ajustement du modèle et vérification des postulats et (3) test et comparaisons multiples pour l'ANOVA ou prédiction pour la régression. Quand les conditions d'application des modèles linéaires ne sont pas vérifiées, les tests non paramétriques sont proposés.",R and teaching,Lightning talk,"Modèles linéaires, Régression, Analyse de la variance, Test non paramétrique, Comparaisons multiples",rr2021
https://r2016-toulouse.sciencesconf.org/106695.html,Package BlockSeg pour la détection rapide des frontières des blocs d'une matrice constante par blocs bruitée,"Vincent Brault, Julien Chiquet, Céline Lévy-Leduc",Applications,"Dans différents contextes, on peut être amené à partitionner les lignes et les colonnes d'une matrice pour former un quadrillage de blocs homogènes sans effectuer de permutations ; c'est notamment le cas pour l'analyse des données Hi-C qui mesurent le degré d'interaction physique entre différentes positions du génome (Dixon et al.). En effet, ces données peuvent être modélisées comme une matrice constante par blocs bruitée. Toutefois, ce problème peut être compliqué pour plusieurs raisons : les méthodes utilisées en segmentation unidimensionnelle comme l'algorithme de programmation dynamique ne s'appliquent pas dans ce cas et la taille importante des données nécessite le développement et la mise en place d'algorithmes performants. Notre approche est la suivante : nous montrons que ce problème peut être ramené à celui d'un modèle linéaire parcimonieux de grande dimension pour lequel nous proposons une méthode de sélection de variables rapide et efficace. Dans cet exposé, nous présenterons le package blockseg où sont implémentées les méthodes. Après avoir rappelé le modèle et les estimations, nous illustrerons le comportement de l'algorithme à l'aide de film puis nous expliciterons les différents programmes et sorties graphiques associées.  ",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/107034.html,Classification hiérarchique d'une matrice de distance avec contrainte d'adjacence,"Alia Dehman, Pierre Neuvial, Guillem Rigaill, Michel Koskas, Christophe Ambroise",Analyse de données,"Contexte: détection de blocs de déséquilibre de liaison dans les études d'association Les études d'association génome entier (GWAS pour Genome-Wide Association Studies) visent à identifier des marqueurs génétiques associés à un trait phénotypique, par exemple une maladie. Les marqueurs génétiques étudiés sont généralement des polymorphismes d'un seul nucléotide (SNP pour Single Nucleotide Polymorphism). Les expériences de puces à ADN ou de séquençage permettent de mesurer le génotype d'un très grand nombre (p=10^5 à 10^6) de SNP chez un grand nombre d'individus (n=10^2 à 10^4). Ces p variables ont une structure de dépendance par blocs le long du génome, liée au phénomène de déséquilibre de liaison (DL) dû à la recombinaison génétique. Nous avons récemment proposé une méthode permettant l'identification de blocs de LD associés à un phénotype d'intérêt [1]. Cette méthode repose sur une première étape de classification ascendante hiérarchique avec contrainte d'adjacence sur la base d'une similarité entre SNP induite par le LD. Une limitation pratique de cette méthode est que l'algorithme de classification est intrinsèquement quadratique en p, à la fois en temps et en espace. Cette complexité rend difficile, voire impossible, le traitement de problèmes où p=10^5 à 10^6.  Idée: exploiter la structure en bande de la matrice des distances Nous proposons d'exploiter une information biologique supplémentaire: le fait que la taille maximale h des blocs de DL est généralement inférieure à p de plusieurs ordres de grandeurs. Cette propriété biologique est illustrée sur la Figure (voir résumé pdf), qui illustre la structure bloc-diagonale du DL entre les 50 premiers SNP du chromosome 22 dans le cas d'une étude sur le VIH [2]. Contribution: un algorithme de classification sous-quadratique La prise en compte de cette information biologique permet d'obtenir un algorithme approché dont la complexité est sous-quadratique. Cet algorithme est donc applicable à des données où p est “grand”. L'algorithme proposé prend entrée la matrice (creuse) des distances entre tous les couples de variables dont les indices sont distants de moins de h, où h est fixé à l'avance. Grâce (i) au pré-calcul de certaines sommes cumulatives des distances, et (ii) à une structure de tas binaire pour le stockage des fusions successives entre classes, l'algorithme proposé a une complexité O(p(h+log(p))) en temps et O(ph) en espace. Nous proposons une implémentation en R de cet algorithme, faisant appel à du C++. Nos expériences numériques réalisées à partir de données réelles montrent que cet algorithme fournit une très bonne approximation de la solution obtenue sans la contrainte de bande sur-diagonale. Références [1] Dehman, A. Ambroise, C. and Neuvial, P. (2015). Performance of a blockwise approach in variable selection using linkage disequilibrium information. BMC Bioinformatics 16:148. [2] Dalmasso, C et al. (2008) Distinct genetic loci control plasma HIV-RNA and cellular HIV-DNA levels in HIV-1 infection: the ANRS Genome Wide Association 01 study. PloS One 3(12):3907.",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/105918.html,Classification en présence d'outliers (données aberrantes) avec RMixmod (package de classification par modèles de mélanges),Florent Langrognet,Analyse de données,"Les modèles de mélanges offrent un cadre probabiliste flexible et efficace pour traiter des problématiques de classification supervisée ou non supervisée. L'objectif du projet MIXMOD est de diffuser un ensemble logiciel de classification des données par modèles de mélanges à un large spectre d'utilisateurs via plusieurs composants logiciels. La bibliothèque de calcul mixmodLib (C++) en est la pierre angulaire, résultat d'un travail de 15 ans sur la robustesse et la rapidité de calcul. Le package RMixmod, ensemble de fonctions pour R, interfacé avec mixmodLib (grâce à RCPP) est devenu un outil de référence pour la classification des données. Intégrant de nombreuses fonctionnalités (algorithmes de type EM, critères de sélection, modèles parcimonieux, stratégies d'initialisation, ...), cet ensemble logiciel permet de traiter des données quantitatives, qualitatives et mixtes, y compris dans des situations complexes.Lorsque le jeu de données contient des individus parasites (c'est-à-dire ayant des valeurs aberrantes, encore appelés outliers) la classification devient alors particulièrement difficile (trouver le bon nombre de classes, affecter le bon label aux vrais individus, ...).En présence d'outliers, il peut être tentant d'appliquer un pré-traitement pour nettoyer le jeu de données avant de le soumettre à un logiciel de classification. Mais ces méthodes sont généralement peu efficaces.A l'opposé, on peut considérer que la classification doit s'effectuer sur l'ensemble des individus avec une classe supplémentaire (celle des outliers). L'étude consiste à mettre à l'épreuve RMixmod sur ce type de problématique. Nous nous intéressons plus particulièrement au cas où des outliers, répartis selon une loi uniforme, viennent s'ajouter à des individus issus de 2 lois gaussiennes. La flexibilité des modèes de mélanges (ici gaussiens) permet non seulement de retrouver les classes d'origine mais également de faire apparaître une classe contenant les outliers. RMixmod peut donc être utilisé efficacement sur des jeux de données contenant des outliers.",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/109160.html,Modèles de mutation : estimation paramétrique,Adrien Mazoyer,Modélisation,(cf pièce jointes),NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/106933.html,VAM un package R pour l'analyse de Modèles d'Age Virtuel,"Rémy Drouilhet, Laurent Doyen",Modélisation,   Nous présentons VAM un package R qui permet dans le cadre le fiabilité de simuler et d'estimer des Modèles d'Age Virtuel (Virtual Age Model).    ,NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/91964.html,Tendance nationale de l'Indice Poisson Rivière (IPR) estimée par un Modèle Additif Généralisé (GAM),"Michael Levi-Valensin, Pascal Irz",Modélisation,"L'IPR ou Indice Poisson Rivière produit par l'Onema (Oce national de l'eau et des milieux aquatiques) décrit l'écart entreles caractéristiques du peuplement observé lors d'une pêche et les valeurs de référence. À partir de cet indice synthétique et composite, notre objectif est d'évaluer si l'état des cours d'eau tend à s' améliorer, ou à se dégrader sur le long terme. La modélisation statistique des mesures a pour principaux avantages de permettre la prise en compte de covariables et de fournir des statistiques de diagnostic.Les prédicteurs sont l'identiant de la station, l'année et une ou plusieurs covariables comme effets fixes ou aléatoires: dans tous les cas, la tendance estimée correspond à l'effet lié à la variable année. Notre choix s'est porté sur le package mgcv (Mixed GAM Computation Vehicle) qui autorise des effets aléatoires ainsi que des relations additives, supposées non linéaires avec les options de lissage de la fonction spline (bs=cc,bs=re). La fonction bam s'applique à des données volumineuses et permet des traitements plus rapides que la fonction gam surtout en présence d'effets aléatoires. Deux options sont envisageables pour inclure l'année : en variable qualitative et quantier l'effet annuel comme un écart à une année de référence ou par une fonction spline de la variable quantitative qui représente une courbe lissée de la tendance annuelle et des effets journaliers tenant compte de la saisonnalité.    ",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/101513.html,airGR : un package pour l'utilisation de modèles hydrologiques pluie-débit,Olivier Delaigue,Modélisation,"airGR est un package dédié à l'utilisation de modèles hydrologiques de type pluie-débit. Appliqués à l'échelle des bassins versants, ces derniers permettent de prédire les débits à partir des précipitations. Ils sont relativement aisés d'utilisation, car ils requièrent très peu de données d'entrées (précipitations, évapotranspiration potentielle et éventuellement température pour les bassins fortement enneigés). Ces modèles dits ""conceptuels"" sont parcimonieux, et permettent de simuler de manière performante le fonctionnement hydrologique des bassins versants avec une complexité limitée (e.g. évapotranspiration, ruissellement, pertes souterraines), sans nécessiter une connaissance fine du fonctionnement physique du bassin (e.g. géologie, urbanisation). Depuis une trentaine d'années, l'équipe Hydrologie des bassins versants d'IRSTEA a développé toute une famille de modèles hydrologiques (connus sous le nom de ""modèles GR"") permettant de prédire au mieux les débits des cours d'eau (simulation hydrologique), et ce sur une très grande variété de bassins versants (régions enneigées, arides, etc.), tout en ne requérant que très peu de variables d'entrée et aisément disponibles (notamment dans les réanalyses météorologiques). Ces modèles permettent de travailler à différents pas de temps possibles (de l'heure à l'année) et dans des contextes d'utilisations variés (évaluation de la ressource en eau, projections hydrologiques en climat futur, etc.). L'utilisation de ces modèles est déjà relativement répandue tant dans le monde de la recherche académique (université Pierre et Marie Curie – Paris 6, université de Nice Sophia Antipolis) que dans les services opérationnels (Services de prévision des crues [S.P.C.] en France, Bureau of Meteorology [B.O.M.] en Australie) ou dans le monde privé (bureaux d'études, EDF). Cependant, la diffusion des codes de ces modèles tels qu'ils avaient été développés depuis les années 1980 restait délicate. Récemment, IRSTEA a implémenté ses modèles dans un package appelé airGR, afin de les diffuser plus largement et de rendre leur utilisation plus aisée par le public. Ce package a été pensé pour faciliter la prise en main de ces modèles hydrologiques par les non spécialistes (e.g. les étudiants). Les personnes plus familiarisées avec ce type d'outil, quant à elles, y trouveront toutes les fonctionnalités nécessaires à une utilisation plus fine (e.g. choix des critères d'évaluation ou des algorithmes de calage des modèles). Les modèles pouvant êtres appelés un très grand nombre de fois, notamment lors du calage (un appel par pas de temps) et sur un grand nombre de bassins versants, les coeurs des modèle du package airGR ont été codés en Fortran, s'assurant ainsi d'une bonne vitesse d'exécution. Les fonctionnalités périphériques, quant à elles, sont codées en R. Afin de laisser un maximum de souplesse à l'utilisateur, le package airGR laisse la possibilité à ce dernier de se servir de ses propres modèles, algorithmes de calage ou critères de performance. Par ailleurs, des sorties graphiques synthétiques ont été préprogrammées pour faciliter la visualisation des données et des résultat.",NA,poster,,rr2016
https://r2016-toulouse.sciencesconf.org/103212.html,"Comparing without gridding species distributions: calculating pairwise intersection, union and similarity between range maps in R","A. Marcia Barbosa, Alba Estrada",Analyse de données,"The comparison of species' distributions and the definition of typical or shared distribution patterns (chorotypes) have important applications in ecology, biogeography and conservation [1]. They are usually based on indices of pair-wise binary similarity between species presence/absence data on a grid of operative geographic units (OGUs). These OGUs can be administrative (e.g. provinces, counties), natural (e.g. watersheds) or arbitrary (e.g. rectangular grids), all of which can have various shapes and sizes. A previous study compared the effects of using different OGUs on the definition of chorotypes, in order to identify the type of gridding or territorial partition that produced the least fuzzy and most ecologically interpretable patterns. The results showed that the smallest OGUs produced the best results [2]. In fact, any gridding or partitioning involves some distortion of the data, since it artificially changes the borders of the species' known distribution ranges, usually overestimating them (Figure 1). For example, two species with relatively close distribution areas will be considered to overlap at least partially if both intersect a given grid cell, even if there is really no overlap and those species are physically separated by a geographical barrier that crosses that grid cell. Gridding is especially problematic when the study area includes islands, where, for example, a single grid cell may include parts of different islands or even nearby continents, and a small island can be artificially divided into more than one grid cell (Figure 1). This problem can be minimized by treating islands differently when defining the OGUs, but this can be very laborious, poorly reproducible, involves arbitrary decisions, and does not solve the effect of the grid on the rest of the study area. The most objective solution is not to grid the study area into OGUs, but rather to calculate distribution similarities directly on the distribution range maps. We propose an adaptation of the binary similarity indices commonly used in the comparison of species distributions, so that they use the size of the intersections and unions between range maps rather than the numbers of shared and non-shared presences on a grid. This allows the analysis of distribution range maps directly without gridding them into OGUs, therefore avoiding the problems associated with islands and barriers and with the choice of the best OGU. It thus eliminates some methodological artefacts in the definition of chorotypes or other analyses that require comparing species distributions based on range maps. This method is implemented within the fuzzySim R package [3], namely in functions pairwiseRangemaps and rangemapSim, which calculate pair-wise similarity matrices directly from range map polygons (e.g., in ESRI shapefile format) [4]. For large map sets, this process (namely the map intersections) can be computationally intensive and cumulatively slow. However, there is the option for parallel computing and for calculating the matrix in chunks, cleaning the memory between each chunk and the next, and assembling them all in the end.  ",NA,poster,,rr2016
https://r2016-toulouse.sciencesconf.org/105362.html,Descente de gradient stochastique sur le modèle de Cox : données longitudinales et coefficients dépendants du temps,"Thibault Allart, Agathe Guilloux",Analyse de données,"Nous proposons un nouvel algorithme pour le Modèle de Cox permettant à la fois de traiter des données de grande dimension (nombreuses variables) et de grande taille (grand nombre d'observations), mais aussi de prendre en compte des covariables longitudidales et des coefficients dépendants du temps.",NA,poster,,rr2016
https://r2016-toulouse.sciencesconf.org/106732.html,Etude de l'impact des covariables sur la qualité de prédiction des modèles d'interactions génotype x environnement,"Vanessa Choisi, Célia Pontet",Applications,"L'évolution des conditions climatiques et la diversification des pratiques culturales génèrent des conditions de culture de plus en plus hétérogènes, avec une plus grande expression des stress environnementaux. Dans ce contexte, il devient de plus en plus important de comprendre la variabilité du comportement des variétés face à ces stress afin de pouvoir mieux adapter le choix variétal au milieu de culture. Pour ce faire, il est nécessaire d'être capable de comprendre et de prédire les interactions entre génotype et milieu (IGE) dans les réseaux d'essais variétaux. Des travaux sur l'analyse des IGE ont été réalisés. Différentes méthodes statistiques telles que la régression PLS ou les forêts aléatoires ont permis jusqu'à maintenant d'expliquer une part significative des IGE. Cependant, une évaluation des performances de prédiction de ces modèles montre au travers d'indicateurs divers qu'elles ne sont pas satisfaisantes. Or, pour que ces modèles soient utiles au préconisateur, il est nécessaire de pouvoir prédire le comportement des variétés face aux stress dans des environnements non expérimentés. On se propose donc dans cette étude d'évaluer la qualité prédictive des modèles statistiques d'IGE en s'intéressant particulièrement aux covariables utilisées pour mesurer les niveaux des stress dans les environnements. Les données exploitées dans cette étude sont issues du réseau d'essais variété tournesol 2015. Il est composé d'une dizaine de lieux, sur lesquels sont cultivées une dizaine de variétés, réparties de manière aléatoire en 3 répétitions. Pour chaque variété sur un lieu et une répétition, on mesure le rendement, qui correspond au poids de graines de tournesol par surface récoltée. Dans un premier temps, un modèle mixte est réalisé. Les termes d'interactions sont ensuite extraits de ce modèle pour être modélisés. Afin d'expliquer ces IGE, chaque environnement est caractérisé à l'aide de covariables quantifiant les stress qui se sont appliqués sur chacun d'eux (déficit ou excès d'eau, de températures, de rayonnement, d'azote). On compare dans cette étude trois types de calcul de covariables : 1) Calculées sur les stades sensibles du cycle du tournesol : levée, végétation, floraison, remplissage Les dates clé du cycle sont estimées à partir des sommes de températures nécessaires pour atteindre chaque stade. Les covariables calculées rendent compte surtout des stress climatiques Le modèle de culture SUNFLO est utilisé afin de simuler l'évolution de la culture au cours de son cycle. Les dates clés sont estimées par le modèle de culture, qui donne également accès à des stress importants comme le stress azoté 2) Calculées de manière automatique, sur des périodes indépendantes des stades, par décades ou par mois. Le terme « environnement » du modèle est alors décomposé en somme des covariables. La qualité prédictive de ce modèle sera évaluée grâce à l'analyse des erreurs de prédictions (procédure de validation croisée), résumée à l'aide de différents critères tels que le coefficient de Spearman ou la RMSEP (Root Mean Square Error of Prediction). Nous présenterons alors les résultats de cette évaluation en fonction des trois listes de covariables étudiées. Plusieurs méthodes statistiques seront également utilisées : régression PLS, régression Lasso, régression Ridge et forêts aléatoires.",NA,poster,,rr2016
https://r2016-toulouse.sciencesconf.org/106741.html,Feasibility of particle genetics in humans,"Claire Burny, Gérard Triqueneaux, Orsolya Symmons, Gaël Yvert",Analyse de données,"Our ability to predict the phenotype from the genotype is limited; even clonal cells grown in the same environment display cell ­to ­cell variability in their expression patterns. Clonal populations allow to identify and study the genetic determinant of stochastic variation after having eliminated environment and genetic interactions as confounding factors. We are exploring how the statistical properties of gene expression (distri­­bution of single ­cell expression levels) are affected by the genotype using cell lines from different individuals. Using a dedicated R pipeline of single cell data analysis, we observed inter-cell line differences in CV (Coefficient of Variation) values suggesting intra variability within population. This approach provides a basis for the identification of genetic loci that influence the statistical distribution of protein expression levels.",NA,poster,,rr2016
https://r2016-toulouse.sciencesconf.org/106370.html,Handling Missing Rows in Multi-Omics Data Integration: Multiple Imputation in Multiple Factor Analysis Framework,"Valentin Voillet, Philippe Besse, Laurence Liaubet, Magali Sancristobal, Ignacio Gonzalez",Analyse de données,"In omics data integration studies, it is common, for a variety of reasons, that some individuals are not present in all data tables. Missing row values are challenging to deal with because most statistical methods cannot be directly applied to incomplete datasets. To overcome this issue, we propose a multiple imputation (MI) approach in a multiple factor analysis (MFA) framework. MI involves filling the missing rows with plausible values, resulting in m completed datasets. MFA is then applied to each completed dataset leading to m different component configurations. Finally, the m configurations are combined to yield one consensus solution. We showed that MI-MFA configurations were closer to the true configuration (obtained from the original data) even when a significant number of individuals were missing, thus providing improved results. ",NA,poster,,rr2016
https://r2016-toulouse.sciencesconf.org/109899.html,lncRNAs potentially implicated in inflammation related anemia: back and forth between bench and R.,"Anthoula Gaigneaux, Sebastien Chateauvieux, Marion Orsini, Franck Morceau, Mario Dicato, Marc Diederich",Analyse de données,"Anemia, characterized by decreased erythrocyte and hemoglobin production, occurs in chronic inflammatory diseases and cancer, affecting more than 30% of cancer patients. Chronic inflammation is one of the main causes and overproduction of pro-inflammatory cytokine TNFα has been incriminated in this process. It has been shown to affect molecular mechanisms of erythropoiesis, including transcription factor and regulatory RNA activities [1]. Based on our recent studies involving microRNAs, we hypothesized that also long non-coding RNAs (lncRNAs) could be targeted by TNFα, contributing to inhibition of erythropoiesis. Long noncoding RNAs have been shown to play a role at several levels of gene expression. Those regulators are involved in transcriptional gene silencing by regulating chromatin structure, RNA processing and by controlling post-transcriptional regulatory steps [2]. To support our hypothesis and discover potential lncRNAs implicated in TNFα-related anemia, we set up a microarray analysis in erythroid differentiation inducible TF-1 cells. The experimental design compared cells treated with EPO (human recombinant erythropoietin, triggering differentiation), or GM-CSF (basal condition) to cells co-treated with TNFα. Our results will describe the analysis pipeline, alternating from bench to computer, from microarray data to finding candidates, confirming them and going further using public data. Statistical analysis of our microarray dataset revealed that many probes were regulated by both EPO and TNFα, and interestingly, TNFα counteracted the effect of EPO for 137 probes, meaning that those could be part of the process preventing erythropoiesis under inflammation. A smaller number of candidates were selected for bench confirmation and further experiments. To select them, we used two strategies based on correlations, first with known actors of inflammation and erythroid differentiation, and second we computed a sliding correlation with sequence neighbors to find cluster of co-regulated probes. One of the most relevant candidates was ENST00000517927. This lncRNAs was up-regulated about 20 times by TNFα but that no modulation by EPO occurred. In addition, its sequence contained sequences of two microRNAs, miR3142 and miR146a, the second being associated to inflammation by targeting its effector NF-κB. Experiments confirmed the link between this candidate and inflammation in several cell lines, including hematopoietic stem/progenitor cells. As very little was known about miR3142, we used public data to show that microRNA was expressed, and that its expression was correlated to our candidate expression.Potential targets of those microRNAs were retrieved and annotations allowed to further select those targets associated with inflammation or differentiation for bench confirmation. Our perspectives include bench analysis of miR3142 and its targets. Références 1. Morceau, F., M. Dicato, and M. Diederich, Pro-inflammatory cytokine-mediated anemia: regarding molecular mechanisms of erythropoiesis. Mediators Inflamm, 2009. 2009: p. 405016. 2. Morceau, F., et al., Long and Short Non-Coding RNAs as Regulators of Hematopoietic Differentiation. Int J Mol Sci, 2013. 14(7): p. 14744-70.",NA,poster,,rr2016
https://r2016-toulouse.sciencesconf.org/106735.html,Recherche de variables environnementales explicatives de la qualité des graines de colza,"Cindy Lanoix, Célia Pontet",Applications,"Avec plus de 6 millions d'hectares et 20 millions de tonnes de production par an, le colza est la première culture oléagineuse Européenne. Un de ses principaux débouchés est l'alimentation humaine, avec la possibilité de produire une huile de haute qualité, riche en acides gras omega3. Par ailleurs les tourteaux, coproduits de la trituration des graines de colza (extraction de l'huile), constituent une source de protéines de qualité pour les bovins, ovins et porcins. Ces produits issus des graines de colza représentent des productions à haute valeur ajoutée, soumises à des cahiers des charges précis. Or, le contexte actuel de changement climatique et de réduction des intrants, conduit à une diversification des milieux de cultures, avec une plus grande expression des stress. Afin de remplir les cahiers des charges qui leur sont imposés, les agriculteurs doivent alors se placer dans des conditions favorables en adaptant le choix de la variété au milieu de culture. Cela implique de comprendre et prédire les interactions génotype x environnement x conduite (IGEC) [1] s'appliquant sur la qualité de la graine. L'objectif de cette étude, réalisé dans le cadre du projet POLYGONE, est alors de rechercher un ensemble de variables environnementales explicatives de la qualité des graines. Les données utilisées sont issues d'un réseau de 10 lieux sur lesquels 8 variétés de colza ont étés cultivées. Pour chaque individu, autrement dit chaque variété dans un lieu, la qualité des graines est définie par les teneurs en huile, protéines et glucosinolates, ainsi que par leur profil en acide gras, dont particulièrement les acides oléique (C18:1 ω-9), linoléique (C18:2 ω-6) et linolénique (C18:3 ω-3) [2]. Chaque lieu est caractérisé par un ensemble de variables candidates calculées à partir de données météorologiques, quantifiant les stress rencontrés, comme le déficit hydrique [3], les fortes ou très basses températures [4], et ceci sur les stades sensibles de culture [5]. L'ensemble des 40 variables explicatives candidates, sont très corrélées entre elles (cf. figure ci-dessous). Les méthodes statistiques linéaires sont donc à proscrire dans un premier temps. Nous ferons donc appel à des méthodes telles que la régression PLS [6] et LASSO [7] [8]. Ces approches nous permettrons de restreindre par régularisation l'espace des solutions, afin de limiter l'effet de la multicolinéarité des covariables. Aussi, divers critères comme R² ajusté, PRESS, RMSE, VIP seront utilisés afin d'évaluer la qualité explicative de chaque variables, pour ainsi sélectionner les plus pertinentes. Dans le but d'améliorer le conseil variétal, cette étude représente l'étape préliminaire indispensable à l'analyse des interactions génotype x environnement x conduite, appliquée à la qualité des graines de colza.",NA,poster,,rr2016
https://r2016-toulouse.sciencesconf.org/105817.html,Tests d'adéquation basés sur le maximum d'entropie : le package MaxEntGOFTest,"Justine Lequesne, Philippe Regnault",Analyse de données,"Dans la littérature, des tests d'adéquation utilisant l'entropie de Shannon ou la divergence de Kullback-Leibler, concepts fondamentaux de la théorie de l'information, ont été construits pour la plupart des lois les plus usuelles. Le premier est le test de normalité de Vasicek [1] qui utilise la propriété de maximum d'entropie de la loi normale parmi les lois à espérance et variance fixées pour proposer comme statistique de test une différence d'entropies. Plus récemment, Song [2] utilise directement la divergence de Kullback-Leibler pour des tests d'adéquation à des lois réelles très générales. Le lien entre ces deux techniques est démontré dans Lequesne [3] grâce à une égalité de Pythagore appliquée aux lois à maximum d'entropie, impliquant une unique procédure de tests d'adéquation à de nombreuses familles de lois. Dans ce poster, nous présentons le package MaxEntGOFTest destiné à appliquer ces tests. En particulier, ce package contient une fonction estimant l'entropie de Shannon d'un échantillon par l'estimateur introduit par Vasicek [1] et une fonction permettant de tester l'adéquation d'un échantillon aux familles de lois uniformes, normales, exponentielles, Gamma, Weibull, Pareto, Fisher, Laplace et Beta. Une application à des données réelles issues d'une étude portant sur la réplication d'ADN est également présentée.  [1] Vasicek, O. (1976) A test of normality based on sample entropy. J. Roy. Statist. Soc. Ser. B V.38(1), p 54-59.[2] Song, K. S. (2002) Goodness-of-fit tests based on Kullback-Leibler discrimination information. Information Theory, IEEE Transactions on, V.48(5), p 1103-1117.[3] Lequesne, J. (2015) Tests statistiques basés sur la théorie de l'information, applications en biologie et en démographie. Mémoire de thèse de l'Université de Caen. ",NA,poster,,rr2016
https://r2016-toulouse.sciencesconf.org/102840.html,Traitement des données manquantes dans un projet participatif sur la biodiversité des sols agricoles.,Mario Cannavacciuolo,Analyse de données,"Le sol, à travers sa composante biologique, joue un rôle essentiel dans le fonctionnement des agrosystèmes. Dans un contexte de développement durable, il apparaît indispensable de se doter d'outils permettant d'appréhender les impacts des systèmes de culture sur les organismes du sol. AgrInnov est un projet participatif français associant chercheurs et agriculteurs ; il vise à développer des outils opérationnels de caractérisation de la biodiversité dans les sols ainsi qu'à la construction de référentiels d'interprétation de cette biodiversité. Les bio-indicateurs retenus ciblent trois grands groupes d'organismes du sol : les vers de terre, les nématodes et les communautés microbiennes. En parallèle, des indicateurs d'évaluation agronomique sont mis en place : analyses physicochimiques du sol, observation de la structure du sol, évaluation de l'activité de décomposition de la matière organique. Le projet s'appuie sur un réseau de 248 parcelles viticoles et de grandes cultures qui intègre une grande diversité de situations pédoclimatiques et culturales à l'échelle du territoire français. Les agriculteurs ont réalisé eux-mêmes l'échantillonnage de leur sol. Les projets de sciences participatives présentent souvent des données erronées ou manquantes. Dans la cadre du projet AgrInnov, les données manquantes constituent un frein au diagnostic de l'impact des pratiques agricoles sur les caractéristiques biologiques et agronomiques du sol. Il est donc nécessaire de définir une stratégie de traitement des données manquantes (élimination de l'individu ou remplacement de la donnée manquante) afin de limiter leur impact dans l'analyse des données. Les méthodes d'imputation de données manquantes sont préférées à la suppression d'individus ou de variables car toute l'information disponible est conservée [4]. Ainsi, les méthodes d'imputation multiple [2], les méthodes basées sur les forêts aléatoires et les méthodes d'imputation factorielles [1] induisent généralement de bonnes estimations des données manquantes. Deux méthodes d'imputation factorielles (fonctions imputePCA et imputeMFA du package missMDA [3]), une méthode d'imputation multiple par « Predictive Mean Matching » (fonction mice du package mice [6]) et une méthode d'imputation par le plus proche voisin (fonction missForest du package missForest [5]) sont comparées, par le biais de simulations numériques sur un jeu de données sans données manquantes, afin de sélectionner celle qui induit les meilleures estimations.  Lorsque les données manquantes sont de type MAR (Missing At Random), une imputation multiple par PMM semble la plus pertinente. En effet, en prenant en compte le pourcentage de données manquantes par variables, cette méthode d'imputation minimise le NRMSE (Normalized Root Mean Square Error) et le critère de la moyenne des écarts à la matrice de corrélation par rapport aux trois autres méthodes testées (imputations factorielles et imputation par le plus proche voisin). Cette méthode reconstitue mieux les données et déforme moins les relations linéaires entre les variables.",NA,poster,,rr2016
https://r2016-toulouse.sciencesconf.org/103060.html,"Traitement, analyse et classification de signaux expérimentaux d'émission acoustique avec le langage R.","Oumar Issiaka Traore, Laurent Pantera, Nathalie Favretto Cristini, Sylvie Vigier Pla",Applications,"L'accident d'injection de réactivité «Reactivity Initiated Accident» (RIA) est un accident dit de type grave, caractérisé par une insertion de réactivité dans le coeur d'un réacteur nucléaire. Il induit une excursion de puissance quasi-instantanée, avec un dépôt significatif d'énergie dans les crayons de combustibles, soumettant ainsi ceux-ci à une situation de stress extrême. Dans le cadre de l'étude d'accidents de ce type, le centre CEA de Cadarache, à travers son Laboratoire de Préparation et de Réalisation des Essais (LPRE), exploite un réacteur de recherche de type piscine destiné à reproduire sur un crayon de combustible irradié, prélevé dans une centrale en activité, une situation de stress équivalente à celle d'un accident de type RIA. Le LPRE développe un atelier de dépouillement autour de l'analyse de ces signaux en s'appuyant sur le langage R pour réaliser les opérations de stockage des informations, de traitement du signal et d'analyse statistique.  Nous présentons ici la mise en oeuvre de l'étape de débruitage du signal acquis lors de l'essai. C'est l'étape importante du processus d'ensemble dans la mesure où elle impacte fortement la qualité de détection des phénomènes, de leur localisation, et finalement de leur classification. Nous avons choisi de mettre en oeuvre deux méthodes. Parmi lesquelles la méthode dite de Soustraction de Spectre (SS). De manière intuitive, elle peut être considérée comme une méthode qui, au travers d'un estimateur du bruit permet de restaurer un signal source en s'appuyant sur une comparaison de densités spectrales en module ou en énergie. Les résultats obtenus permettent de conclure à une très bonne adéquation de la SS en termes d'amélioration du rapport signal sur bruit (SNR) et de préservation de la forme d'onde pour les segments du signal reçu correspondant à des phénomènes physiques d'intérêt. Par ailleurs, nous avons également choisi de mettre en oeuvre une méthode qui nous permettrait de moins dépendre de la connaissance du bruit de fond. C'est une approche basée sur une décomposition en valeurs singulières du signal reçu «Sigular Spectral Analysis» (SSA). Nous testons la capacité d'une telle analyse exploratoire à orienter l'extraction du bruit de fond. Nous comparons les résultats à ceux obtenus par la méthode SS que nous prenons comme référence.",NA,poster,,rr2016
https://r2016-toulouse.sciencesconf.org/109544.html,Forêts aléatoires pour l'apprentissage de données massives,"Robin Genuer, Jean-Michel Poggi, Christine Tuleau-Malot, Nathalie Villa-Vialaneix",Big data,"Les forêts aléatoires (Breiman, 2001) sont une méthode d'apprentissage largement utilisée dans le cadre de problèmes de régression ou de classification en raison de leur flexibilité et de leurs bonnes performances de prédiction. Dans cette proposition de communication, nous présentons les résultats de simulations comparant les diverses approches permettant d'utiliser l'algorithme de forêts aléatoires dans le contexte de données massives.",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/108093.html,R dans le développement d'une cellule Big Data et Analytics,Sylvain Coppéré,Applications,Nous vous proposons une présentation de l'impact de R dans le développement actuel d'une cellule Big Data et Analytics avec des retours d'expérience clients sur des cas d'applications concrets.,NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/106877.html,Améliorer la qualité de son package R avec l'intégration continue,Géraud Duge De Bernonville,Applications,"Lorsque l'on publie un package R, il est important de fournir une application qui réponde à un certain niveau de qualité.L'intégration continue est une démarche du développement logiciel permettant de garantir la qualité du code source d'une application, etce à chaque modification du code source[1]. Elle repose sur l'exécution de tests automatisés, développés en même temps que lecode source du logiciel. L'objectif de ce _Lightning Talk_ est de montrer comment mettre en oeuvre une chaîne d'intégration continue afin d'améliorerla qualité de votre package R. Pour cela nous utiliserons le package _testthat_ pour l'implémentation des tests unitaires et l'outil d'intégration continue TravisCI. Ces deux outils sont pris à titre d'exemple mais la démarche présentée reste applicableavec d'autres outils.",NA,lightning talk,,rr2016
https://r2016-toulouse.sciencesconf.org/105612.html,Outils pour chercher de l'information sur R et se former,"Nathalie Villa-Vialaneix, Christophe Bontemps, Sébastien Déjean",Enseignement,"Dans cette proposition de communications, nous nous proposons de faire le tour de ressources disponibles en ligne pour rechercher des informations sur R, son installation, son utilisation ainsi que de celles qui permettent de se former. Notre ambition n'est pas de fournir une liste exhaustive de ces ressources mais, devant le foisonnement et le développement de sites web, blogs et ressources diverses concernant le logiciel, de faire un descriptif organisé de celles que nous avons utilisées ou appréciées.",NA,lightning talk,,rr2016
https://r2016-toulouse.sciencesconf.org/105503.html,The R Graph Gallery: une core-collection de graphiques R,Yan Holtz,Visualisation,"La visualisation de données englobe l'ensemble des techniques de représentation graphique permettant de traduire un ensemble de données brutes en informations décisives. Face à la masse des données disponibles aujourd'hui, la capacité à extraire des informations pertinentes et à les représenter est indispensable pour un scientifique. R est tout à fait approprié à la réalisation de graphiques, même si ces derniers peuvent parfois paraître difficiles à réaliser.   « The R Graph Gallery » (www.r-graph-gallery.com) est un site web répertoriant plus de 150 graphiques réalisés sous R, toujours avec le code source reproductible associé. L'objectif est double. D'une part, c'est une plateforme d'aide permettant aux utilisateurs de réaliser le graph désiré. D'autre part, c'est une source d'inspiration permettant de découvrir de nouveaux types de représentation.   Ce « lightening talk » a pour but de présenter brièvement cette galerie, tout en donnant un état de l'art des possibilités de graphiques sous R. Les différents types de représentation ainsi que les outils indispensables sont présentés au travers d'exemples. Le talk est structuré suivant les grandes sections du site :   - Les basiques: plot, boxplot, histogrammes etc.. - Les paramètres graphiques permettant de personnaliser les plots. - Ggplot2 (1) - La visualisation interactive des données : shiny (2) et plotly (3) - L'esthétique poussée à l'extrême ou le « DataArt »   Une occasion de repartir avec des idées de visualisation à tester sur vos données !",NA,lightning talk,,rr2016
https://r2016-toulouse.sciencesconf.org/103385.html,Deep Learning avec R et H2O,Géraud Duge De Bernonville,Analyse de données,"Le Deep Learning fait de plus en plus le buzz ces derniers années avec des utilisations dans la reconnaissanced'image[1], le traitement du langage[2] et le jeu de Go[3].Le langage R n'est pas en reste car il existe des outils permettant d'entraîner des modèles Deep Learning à partir de R. H2O[4] fait partie de ces outils. Initialement développé en Java, H2O fournit des API permettantde s'intégrer à d'autres outils et langages tels que Python, Java et bien évidemment R.Au travers de ce _Lightning Talk_, nous allons présenter un aperçu des possibilités de H2O qui ont été mises enoeuvre pour la résolution d'un challenge de Data Science. ## Références[1] Wu, R., Yan, S., Shan, Y., Dang, Q., & Sun, G. (2015). Deep image: Scaling up image recognition. arXiv preprint arXiv:1501.02876, 22, 388.[2] Christopher Olah (2014). Deep Learning, NLP, and Representations. http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/.[3] Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., van den Driessche, G., ... & Dieleman, S. (2016). Mastering the game of Go with deep neural networks and tree search. Nature, 529(7587), 484-489.[4] Aiello, S., Eckstrand, E., Fu, A., Landry, M., Lanford, J., and Aboyoun, P. (Aug. 2015) Fast Scalable R with H2O. http://h2o.ai/resources.",Big data,lightning talk,,rr2016
https://r2016-toulouse.sciencesconf.org/94530.html,Groupe de Travail « Analyse des données textuelles sous R »,Nicolas Turenne,Enseignement,"En extraction et gestion des connaissances, une partie de la recherche se préoccupe d'analyser des données non structurées et multivariées afin d'extraire des connaissances et de les restituer à des utilisateurs. Les corpus de textes d'origine variée (archives, web 1.0, web 2.0, objets connectés) ont une place prédominante dans ces données non structurées.   S'il existe des API pour analyser des données textuelles dans de nombreux langages (perl, python par exemple), R possède une bibliothèque d'algorithmes très riche pour aborder des sujets de linguistique quantitative. L'analyse statistique des données textuelles était peu pratiquée avant ces 5 dernières années, si ce n'est pour une analyse théorique des distributions [1]. Depuis lors, on trouve désormais des modules typiquement adaptés aux données textuelles pour se créer un corpus, pour découper un corpus et manipuler les segments textuels dans des représentations directement exploitables par des algorithmes d'analyse de données génériques (ou transversaux à tout type de problème et de données : comme une analyse factorielle par exemple)[2]. Cette concomitance de disposer d'un Atelier de Génie logiciel largement utilisé, d'une transformation des représentations qualitatif-quantitatif, de la présence récente de bibliothèques typiquement adaptées au texte tout en garantissant l'utilisation d'une vaste bibliothèque d'algorithmes génériques suscite un intérêt grandissant de R parmi les experts de traitement automatique du langage naturel [3][4][5][6][7].   En janvier 2016, un groupe de travail https://www.facebook.com/groups/rTextData/ a été créé pour dynamiser les activités et la promotion de R par ces experts. Il réunit 77 abonnés intéressés par l'usage de R pour l'analyse des corpus textuels. Le groupe a pour ambition de faire connaître les pratiques sur R mais aussi d'animer des activités autour de ces pratiques (formation flash à un module par exemple, création de synergies monde académique-monde entrepreneurial).",NA,lightning talk,,rr2016
https://r2016-toulouse.sciencesconf.org/108856.html,Etude de cas avec le package R rvest,Amélie Neveux,Analyse de données,"Mise en œuvre d'une démarche analytique permettant de répondre à la question : Quelles sont les compétences les plus recherchées sur le marché de la DATA ? Et quels sont les profils les plus appétents ? Pour répondre à cette question, nous avons entrepris une démarche de récupération et d'analyse des offres d'emploi publiées sur le web avec pour objectif de bâtir un modèle de recommandation de profil pour chaque offre. Cette recommandation est ensuite mise à disposition auprès des utilisateurs de l'application qui qualifient la pertinence de la réponse (OK / KO) et peuvent indiquer la caractéristique expliquant le refus (ceci dans le but d'améliorer par la suite la pertinence du modèle).",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/105855.html,Analyse de parcours client en mode multicanal,"Romain Anne, Chrystel Galissie, Frédéric Bomy, Patrice Michel",Analyse de données,"Le parcours client peut, pour un produit ou service donné, désigner la relation et les interactions entre le client et l'entreprise à partir du moment où il constate son besoin jusqu'à celui où il passe à l'achat. Il consiste avant tout à décomposer chaque étape et à comprendre les objectifs du client, ce qu'il fait ou ne fait pas et pourquoi. Le parcours client peut également comprendre des éléments post-achat (utilisation, commentaires sur les réseaux sociaux, etc.). En d'autres termes, le parcours client est un ensemble d'étapes et d'enchainements d'événements qui définissent son processus d'achat (ou de non achat). Dans notre modélisation, nous avons introduit le fait que le parcours d'un client correspondait à une séquence d'événements. Chaque événement est une interaction du client avec la marque, ces événements étant ordonnés dans le temps : ils forment donc une séquence. Les méthodes d'Optimal Matching Analysis (OMA), ou méthodes d'appariement optimal en français, définissent une mesure afin de calculer une distance entre des séquences. Ces méthodes sont implémentées dans les packages TraMineR et TraMineRextras du logiciel R. L'idée générale consiste à mesurer la dissimilarité entre deux séquences en transformant l'une en l'autre au moyen d'opérations élémentaires. Notre présentation consistera à décrire notre démarche, et les algorithmes que nous avons utilisé dans R.  ",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/106664.html,Utilisation du carroyage INSEE combiné avec les communes,Anne Gayet,Applications,"R permet de traiter l'open data même de grande volumétrie, et de standardiser des process de traitement à haute valeur ajoutée marketing. Nous verrons comment utiliser le carroyage INSEE, niveau très fin de découpage du territoire et des populations, en le combinant avec le découpage communal pour obtenir une analyse géographique et cartographique à deux niveaux.",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/106112.html,Présentation du package rAmCharts,"Benoit Thieurmel, Jeffery Petit, Elena Salette, Titouan Robert",Visualisation,"La visualisation prend une part de plus en plus importante dans la restitution des résultats statistiques. Dans ce domaine il ne s'agit pas simplement d'exposer les résultats mais aussi de trouver une manière ludique et parlante au plus grand nombre. Le package htmlwidgets a démocratisé l'utilisation des librairies Javascript avec R, il permet notamment d'enrichir les visualisations usuelles avec de l'interactivité. Dans ce courant nous développons le package rAmCharts qui est basé sur la librairie amcharts.js., avec comme objectif d'apporter aux utilisateurs R une interface simple permettant la réalisation d'une multitude de graphiques.",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/106470.html,Observatoire des prix des carburants : Visualisation Shiny app,Ignacio Inoa,Visualisation,"Dans un contexte de baisse des cours du pétrole, le cabinet d'analyse Microeconomix a créé une application web avec R et Shiny, ouvert au public et accessible à l'adresse www.prixdescarburants.info, qui permet de suivre, comparer et analyser les prix des carburants en France métropolitaine. En interaction avec des librairies JavaScript Leaflet, Highcharts et dygraphs, l'application propose des visualisations de qualité avec positionnement des stations sur une carte interactive et recherche des prix par commune. ",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/107355.html,"R++, the Next Step",Christophe Genolini,Analyse de données,"En 1870, le nutritionniste E. von Wolf chargé de mesuré le taux de fer des épinards a fait un travail d'une grande qualité, qu'il a malheureusement conclut par une erreur de recopie. Il a involontairement multiplié le taux de fer des épinards par 10. De nos jours, les logiciels d'analyse statistiques sont des outils formidables qui apportent une aide précieuse dans les analyses. Mais au niveau de l'export des données, nous sommes encore très proche de la recopie manuelle...  R++, the Next Step est un projet de développement d'une nouvelle implémentation de R. Il a pour vocation d'être compilable, d'intégrer en natif la gestion du parallélisme et de permettre l'exploitation des bases de données de grande dimension. Mais surtout, R++ est intégré dans une interface homme machine dédiée, spécifiquement conçue pour les analyses statistiques. Dans cette présentation, nous vous proposons un nouvel axe de l'interface homme machine dédié spécifiquement à l'export des données. Nous présenterons différentes solutions qui permettent de ne plus copier-coller les résultats mais de les exporter directement vers différent support, dont les articles scientifique.",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/105925.html,mbbefd: modélisation des taux de destruction en actuariat non vie,Christophe Dutang,Modélisation,"   Dans le jargon actuariel, une courbe d'exposition est définie comme le ratio de l'espérance de perte limitée à différentes limites et de l'espérance de perte. Nous présentons des modèles de taux de destructions, soit définis par leur fonction de répartition soit de manière équivalente définis par leur courbe d'exposition.  Une attention toute particulière est porté aux lois de probabilité ""gonflées"" ou ""inflatées"" en 1 et aux lois MBBEFD. L'estimation des paramètres de ces modèles est réalisée par la méthode de maximum de vraisemblance et la méthode des moments. Les propriétés des estimateurs sont ensuite étudiées de manière théorique et empirique. Enfin, nous présentons le package mbbefd implémentant toutes ces fonctionnalités.    ",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/103316.html,extremefit : un package pour estimer les probabilités et quantiles conditionnels extrêmes,"Gilles Durrieu, Ion Grama, Kévin Jaunâtre, Jean-Marie Tricot, Quang-Khoai Pham",Modélisation,"La modélisation et l'estimation des valeurs extrêmes jouent un rôle important dans de nombreux domaines tel que la finance, la biologie, etc. Des packages R tels que evir, evd, fExtremes, traitent déjà de certains problèmes liés aux extrêmes. Nous introduisons ici un nouveau package, extremefit, pour la détermination des quantiles et probabilités conditionnels extrêmes. Nous présentons brièvement la méthode d'estimation des quantiles conditionnels extrêmes utilisée et nous expliquons les concepts statistiques afférents. Nous donnons un exemple d'utilisation du package extremefit et nous indiquons son intérêt par rapport aux autres packages.",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/108793.html,Group and Sparse Group Partial Least Square Approaches Applied in Genomics Context,Benoit Liquet,Big data,"The association between two blocks of 'omics' data brings challenging issues in computational biology due to their size and complexity. Here, we focus on a class of multivariate statistical methods called partial least square (PLS). Sparse version of PLS (sPLS) operate integration of two data-sets while simultaneously selecting the contributing variables. However, these methods do not take into account the important structural or group effects due to the relationship between markers among biological pathways. Hence considering the predefined groups of markers (e.g., genesets), this could improve the relevance and the efficacy of the PLS approach.  We propose two PLS extensions called group PLS (gPLS) and sparse group PLS (sgPLS). Our algorithm enables to study the relationship between two different types of omics data (e.g., SNP and gene expression) or between an omics dataset and multivariate phenotypes (e.g., cytokine secretion). We demonstrate the good performance of gPLS and sgPLS compared to the sPLS in the context of grouped data. Then, these methods are compared through an HIV therapeutic vaccine trial. Our approaches provide parsimonious models to reveal the relationship between gene abundance and the immunological response to the vaccine.  The approach is implemented in a comprehensive R package called sgPLS available on the CRAN.  ",NA,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/103403.html,mixMint: A multivariate integrative approach to identify a reproducible biomarker signature across multiple experiments and platforms,Florian Rohart,Analyse de données,"The reproducibility of biomarker identification across transcriptomics independent studies is often limited by small sample size experiments. One solution is to increase statistical power by combining those studies in an integrative approach. In addition, the advantage is to enable data sharing across research groups and benchmark studies. However, such analysis is not straightforward due to the unwanted systematic variation arising from the use of different commercial platforms in different laboratories with different protocols. We propose a novel multivariate integration method, MINT that accommodates for unwanted systematic variation, builds an accurate multivariate linear classifier based on a small subset of key discriminative biomarkers. We illustrate the benefits of combining transcriptomics data sets (microarray and RNA-sequencing) with MINT on two case studies and show that the gene signatures obtained are highly predictive, as validated on external studies, and are therefore highly reproducible. MINT compares favourably to two-steps batch effect removal and classification procedures, and provides insightful study-specific outputs to quality control each study to be integrated in the analysis.The MINT algorithm is implemented as part of the mixOmics R package available on CRAN (http://cran.r-project.org/web/packages/mixOmics/, http://www.mixOmics.org/). ",Applications,oral,,rr2016
https://r2016-toulouse.sciencesconf.org/106945.html,La méthode shock : réduction de dimension en inférence de réseaux,"Mélina Gallopin, Emilie Devijver",Analyse de données,"Les modèles graphiques gaussiens permettent d'inférer et de visualiser les dépendances entre des variables. Ces modèles sont difficiles à estimer lorsque la taille de l'échantillon est plus petite que le nombre de variables. Afin de réduire la dimension du problème, nous proposons une procédure de sélection de modèle non-asymptotique: nous approchons la matrice de covariance par une matrice diagonale par blocs. Pour détecter la structure de cette matrice, nous seuillons la matrice de covariance empirique, le seuil étant choisi à l'aide de l'heuristique de pente. Grâce à cette structure, le problème d'estimation est décomposé en plusieurs sous-problèmes indépendants : dans chaque bloc, nous inférons les dépendances entre variables à l'aide du graphical Lasso. Cette méthode est implémentée dans le package shock (Slope Heuristic blOCK diagonal covariance selection). Dans ce ""lightning talk"", nous exposerons ce package et l'intérêt de son utilisation.",NA,lightning talk,,rr2016
https://r2016-toulouse.sciencesconf.org/105952.html,MixAll: Un logiciel de classification non-supervisée,Serge Iovleff,Analyse de données,"Le package MixAll permet de faire de la classification des données mixtes en proposant des modèles de mélanges Gaussiens, gamma, poisson et catégoriel. Il permet aussi de prendre en compte les données manquantes. Les traitements sont réalisés en utilisant le code C++ du projet ""Clustering"" de la librairie STK++ (The Statistical ToolKit, http://www.stkpp.org). STK++ est une librairie écrite en C++ dédiée aux statistiques. La librairie est divisée en différent projets. Le noyau est distribué à travers le package rtkore dont dépend donc le package MixAll.",NA,lightning talk,,rr2016
https://r2016-toulouse.sciencesconf.org/105404.html,tess3r : un package R pour l'estimation de la structure génétique des populations spatialisées,"Kevin Caye, Olivier Francois, Michel Olivier",Analyse de données,Une étape importante lors de l'étude de données de grande dimension est la recherche d'une structure de faible dimension mettant en évidence les principales caractéristiques des données. Cette étape est très importante en génétique des populations. Le package tess3r permet d'estimer la structure génétique des populations spatialisées à partir de la matrice de génotype et des positions spatiales des individus. Le package permet de plus de représenter la structure calculée et de faire un balayage pangénomique afin de détecter des gènes potentiellement responsables d'une adaptation à l'environnement.,NA,lightning talk,,rr2016
https://r2016-toulouse.sciencesconf.org/106292.html,Outils pour l'analyse et la simulation de données RNA-seq,"Alyssa Imbert, Nathalie Villa-Vialaneix",Applications,"Dans cette proposition de communication, nous présentons les packages R qui permettent d'analyser et de simuler des données issues des technologies de séquençage du transcriptome (RNA-seq). Dans un premier temps, nous ferons un tour rapide des packages qui permettent d'effectuer la normalisation et l'analyse différentielle. Puis, nous discuterons des méthodes pour inférer un réseau de gènes à partir de telles données et les packages R associés. Enfin, nous présenterons quels packages permettent de simuler des réseaux et des données transcriptomiques à partir de ces réseaux.",NA,lightning talk,,rr2016
https://r2016-toulouse.sciencesconf.org/105909.html,BRCAnegApp : une application web Shiny pour aider les oncogénéticiens à classer les familles BRCA1/2 négatives selon leur risque de cancer du sein.,"Youenn Drouet, Valérie Bonadona, Sophie Dussart, Christine Lasset",Applications,"Plus de la moitié des familles suspectées de prédisposition héréditaire au cancer du sein ou de l'ovaire sont dites « BRCA1/2 négatives » (BRCAneg) en l'absence de mutation des gènes BRCA1 et 2 identifiée chez le cas index (femme atteinte de cancer ayant bénéficié du test génétique). En raison de facteurs génétiques inconnus ou non pris en compte dans les tests actuels, le risque de cancer du sein est plus élevé dans ces familles que dans la population générale, et certaines pourraient même être exposées à un risque comparable aux familles BRCA1/2 mutées. Afin de leur proposer un dépistage adapté, la Haute Autorité de Santé (HAS) recommande ainsi de les classer en « risque élevé » ou « risque très élevé » de cancer du sein. Dans cette optique, nous avons récemment développé une méthode originale de classification non supervisée [1]. Brièvement, 6 descripteurs reflétant la sévérité de l'histoire familiale étaient calculés pour 399 familles BRCAneg, puis résumés par les deux premiers axes d'une Analyse en Composantes Principales (ACP). La distance euclidienne sur la carte factorielle correspondante était utilisée comme métrique de similarité dans une classification non supervisée en troisgroupes (algorithme des K-means). Deux groupes étaient clairement séparés et considérés à risque élevé (n=157) et risque très élevé (n=67). Les familles du troisième groupe (n=175), dit « intermédiaire » car situé entre les 2 groupes précédents, nécessitaient une évaluation au cas pas cas en réunion multidisciplinaire (RCP). Nous présentons ici l'application BRCAnegApp associée à cette nouvelle méthode, qui permet de calculer les coordonnées sur la carte factorielle et le groupe d'appartenance d'une nouvelle famille (Figure 1). Cette application, qui peut être exécutée sur un terminal mobile, est actuellement utilisée (en phase de test) comme outil d'aide à la décision par les oncogénéticiens duCentre Léon Bérard (Lyon). Nous aborderons les aspects techniques liés à son développement et donnerons un premier retour d'expérience sur son utilisation. Références[1] Y. Drouet, V. Bonadona, E. Gargano, E. Kardous, H. Chauvin, I. Girerd-Genessay, S.Dussart, S. Handallou, C. Lasset. Classification des familles de type sein-ovaire sans mutationconstitutionnelle de BRCA1/2 identifiée, pour le niveau de risque de cancer du sein : apportd'une stratégie d'évaluation multicritères s'appuyant sur une méthode d'analyse factorielle, inactes des 8es Assises de Génétique Humaine et Médicale, Lyon, 2016.",NA,lightning talk,,rr2016
https://r2014-mtp.sciencesconf.org/46913.html,Interfaces graphiques,Thomas Verron,français,NA,tutoriels,Communication orale,interfaces graphiques,rr2014
https://r2014-mtp.sciencesconf.org/46914.html,La contruction de greffons Rcommander,Milan Bouchet-Valat,français,NA,tutoriels,Communication orale,"greffons, Rcommander",rr2014
https://r2014-mtp.sciencesconf.org/40837.html,Interactive graphics with ggvis,Winston Chang,anglais,NA,Conférence invitée,Communication orale,Interactive graphics with ggvis,rr2014
https://r2014-mtp.sciencesconf.org/37665.html,Open Reproducible Science in Ecology,Olivier Flores,anglais,NA,Statistiques en sciences de la vie,Communication orale,"reproducible research, open science, workflow, litterate programing",rr2014
https://r2014-mtp.sciencesconf.org/38399.html,mvMORPH : an R package for the fitting of multivariate evolutionary models to morphometric data,"Julien Clavel, Gilles Escarguel, Gildas Merceron",anglais,NA,Statistiques en sciences de la vie,Communication orale,"Brownian motion, Ornstein, Uhlenbeck, Multivariate comparative methods, stochastic mapping, phenotypic evolution, paleotrees.",rr2014
https://r2014-mtp.sciencesconf.org/43780.html,"Santé, Nutrition et Big Data : Optimisation de packages R","Ndeye Aram Gaye, Jean-Michel Batto, Nahid Emad",français,NA,Statistiques en sciences de la vie,Communication orale,"métagénomique, Big data, HPC, R, GPU, Xeon Phi",rr2014
https://r2014-mtp.sciencesconf.org/37642.html,R et C++,Romain Francois,français,NA,Développement informatique,Communication orale,"Performance, C++, C++11",rr2014
https://r2014-mtp.sciencesconf.org/38351.html,Using ontologies for R functions management,"Yuan Lin, Pascal Neveu, Caroline Domerg, Juliette Fabre, Alexandre Granier, Anne Tireau, Vincent Negre, Isabelle Mirbel, Olivier Corby, Catherine Faron-Zucker",anglais,NA,Développement informatique,Communication orale,"Capitalization of R Functions, Ontology, Knowledge Management, Semantic Web",rr2014
https://r2014-mtp.sciencesconf.org/38335.html,"R++, the Next Step","Christophe Genolini, Joël Falcou, Ronan Tournier",français,NA,Développement informatique,Communication orale,"Big data, parallélisme, interface homme machine, logiciel métier",rr2014
https://r2014-mtp.sciencesconf.org/37378.html,Estimation de quantiles conditionnels basée sur la quantification optimale sous R,"Isabelle Charlier, Davy Paindaveine, Jerôme Saracco",français,NA,Apprentissage,Communication orale,"Quantile conditionnel, Estimation non, paramétrique, Quantification optimale",rr2014
https://r2014-mtp.sciencesconf.org/38319.html,Développement de l'application logicielle pour l'évaluation du stock de seiche de Manche.,Edouard Duhem,français,NA,Apprentissage,Communication orale,"Seiche, Manche, Delta, GLM, Modèle, biomasse, package",rr2014
https://r2014-mtp.sciencesconf.org/39435.html,Choosing a gold standard: support of Bayesian inference methods for diagnostic accuracy of new biomarkers in pediatric urinary tract infection,"Sophie Bastide, Paul Landais, Sandrine Leroy",anglais,NA,Poster,Poster,"sensitivity and specificity, Bayesian inference methods, pediatric urinary tract infection",rr2014
https://r2014-mtp.sciencesconf.org/37601.html,fuzzySim: an R package for analysing fuzzy similarity in species occurrence patterns,A. Marcia Barbosa,anglais,NA,Poster,Poster,"Statistique, Ecologie, Distribution des espèces, Similitude, Logique floue",rr2014
https://r2014-mtp.sciencesconf.org/37462.html,L'écotoxicologie rencontre la phylogénie dans l'écosystème R,"François Keck, Floriane Larras, Bernard Montuelle, Frédéric Rimet, Alain Franc, Agnès Bouchez",français,NA,Poster,Poster,"Écotoxicologie, Phylogénie, Approche interdisciplinaire",rr2014
https://r2014-mtp.sciencesconf.org/37320.html,Plans d'expériences D-optimaux pour modèles non linéaires,Stéphane Hattou,français,NA,Poster,Poster,"Matrice Jacobienne, Plan D, optimal, Modèle non linéaire, Algorithme de Fedorov",rr2014
https://r2014-mtp.sciencesconf.org/40836.html,The R Development Process: status and prospects,Roger Bivand,anglais,NA,Conférence invitée,Communication orale,R Development Process: status and prospects,rr2014
https://r2014-mtp.sciencesconf.org/37607.html,Développement d'une application web interactive sous R avec le package 'Shiny' pour la comparaison des résultats NGS (Next Generation Sequencing) d'IMGT/HighV-QUEST des récepteurs d'antigènes,"Safa Aouinti, Dhafer Malouche, Marie-Paule Lefranc",français,NA,Lightning talks,Lightning talks,"Statistique, package Shiny, test de comparaison de deux proportions, intervalle de conﬁance pour une diﬀérence de deux proportions, visualisation, IMGT/HighVQUEST.",rr2014
https://r2014-mtp.sciencesconf.org/37603.html,Sensitivity analysis of dynamic crop models to assist crop science: assessing the impact of multiple traits on yield in Australian wheat.,"Pierre Casadebaig, Karine Chenu, Robert Faivre",anglais,NA,Lightning talks,Lightning talks,"genotype, environment interactions, modelling, sensitivity analysis, wheat, drought",rr2014
https://r2014-mtp.sciencesconf.org/37620.html,"Valorisation web par l'outil “Shiny”, d'analyse d'enquêtes utilisateurs de solutions TIC du projet Intelligible CityForAll","Neska El Haouij, Dhafer Malouche, Sylvie Ghalila",français,NA,Lightning talks,Lightning talks,"Outil “Shiny”, Analyse des données, I'CityForAll.",rr2014
https://r2014-mtp.sciencesconf.org/37630.html,Comparaison entre Julia et le package Rmpfr de R sur la précision de calculs numériques,"Constance Vagne, Bénédicte Fontez",français,NA,Lightning talks,Lightning talks,"précision, Rmpfr, virgule flotante, Julia, MPFR",rr2014
https://r2014-mtp.sciencesconf.org/36062.html,Legislative Network Visualization with R,François Briatte,anglais,NA,Lightning talks,Lightning talks,"Social Networks, Political Science, Graph Visualization",rr2014
https://r2014-mtp.sciencesconf.org/38301.html,Données longitudinales en grande dimension : état des lieux des packages R,"Perrine Soret, Marta Avalos",français,NA,Lightning talks,Lightning talks,"longitudinal data, high, dimensionality, Statistical Machine Learning",rr2014
https://r2014-mtp.sciencesconf.org/39101.html,Alimentation en ligne d'une base de données à partir d'un fichier Excel,"Marie-Claude Quidoz, Juliette Fabre",français,NA,Lightning talks,Lightning talks,"tableur, base de données, web",rr2014
https://r2014-mtp.sciencesconf.org/40838.html,Packages (Re)Dice_ pour les computer experiments,"Olivier Roustant, Yves Deville",français,NA,Conférence invitée,Communication orale,Packages (Re)Dice_ pour les computer experiments,rr2014
https://r2014-mtp.sciencesconf.org/39523.html,Snake Search : méthode de recherche d'empreintes,"Robert Sabatier, Christelle Reynes",français,NA,Données longitudinales,Communication orale,"reconnaissance automatique de signal, alignement de profils, interface graphique",rr2014
https://r2014-mtp.sciencesconf.org/38157.html,Modélisation conjointe de données longitudinales et de données issues d'un processus multi-états,"Loïc Ferrer, Cécile Proust-Lima",français,NA,Données longitudinales,Communication orale,"Modélisation conjointe, Processus multi états, Processus longitudinal, Packages nlme, mstate et JM",rr2014
https://r2014-mtp.sciencesconf.org/39257.html,Joint modelling of longitudinal CD4 counts and survival of HIV-infected patients initiated on antiretroviral therapy in sub-Saharan Africa.,"Mathieu Bastard, David Maman, Jean-François Etard",anglais,NA,Données longitudinales,Communication orale,"Joint modelling, R package, latent class model, HIV, sub, Saharan Africa",rr2014
https://r2014-mtp.sciencesconf.org/37516.html,VSURF : un package R pour la sélection de variables à l'aide de forêts aléatoires,"Robin Genuer, Jean-Michel Poggi, Christine Tuleau-Malot",anglais,NA,Big Data,Communication orale,"Forêts aléatoires, Sélection de variables, Package R, Apprentissage statistique, Données de grande dimension",rr2014
https://r2014-mtp.sciencesconf.org/37706.html,Travailler avec des matrices creuses sous R,Benoit Thieurmel,français,NA,Big Data,Communication orale,"matrices creuses, sparse",rr2014
https://r2014-mtp.sciencesconf.org/38300.html,Sélection de variables pour la construction d'indicateurs de qualité de vie pour des données mixtes structurées en groupes,"Amaury Labenne, Marie Chavent, Vanessa Kuentz-Simonet, Jerôme Saracco",français,NA,Big Data,Communication orale,"analyse factorielle multiple, données mixtes, stabilité, closest submodel selection",rr2014
https://r2014-mtp.sciencesconf.org/38324.html,BALD : Etude d'association par blocs de déséquilibre de liaison,"Alia Dehman, Pierre Neuvial, Christophe Ambroise",français,NA,Big Data,Communication orale,"Bioinformatique, Etudes d'association génome entier, Déséquilibre de liaison, Group Lasso.",rr2014
https://r2014-mtp.sciencesconf.org/37632.html,ClustVarLV : un package pour la classification de variables autour de variables latentes,"Evelyne Vigneau, Mingkun Chen, El Mostafa Qannari",français,NA,Analyse de données,Communication orale,"Classification de variables, variables latentes, données externes",rr2014
https://r2014-mtp.sciencesconf.org/37629.html,"""blockberry"" : Un package expérimental sous R pour matrices structurées en blocs",Mohamed Hanafi,français,NA,Analyse de données,Communication orale,"Tableaux multiples, algèbre matricielle, R.",rr2014
https://r2014-mtp.sciencesconf.org/39454.html,SCGLR : un package R pour la régression linéaire généralisée sur composantes supervisées,"Catherine Trottier, Guillaume Cornu, Frédéric Mortier, Xavier Bry",français,NA,Analyse de données,Communication orale,"Modèles linéaires généralisés multivariés, Modèles à composantes, Régression PLS, Algorithme des scores de Fisher",rr2014
https://r2014-mtp.sciencesconf.org/39481.html,THEME : Une méthode et un logiciel pour l'analyse exploratoire multidimensionnelle d'un modèle structurel.,"Xavier Bry, Thomas Verron, Patrick Redont",français,NA,Analyse de données,Communication orale,"Approche PLS, Equations structurelles, PLS, SEER, THEME",rr2014
https://r2014-mtp.sciencesconf.org/37644.html,EBSpat un package R autour des processus ponctuels de Gibbs de type plus proches voisins,Rémy Drouilhet,français,NA,Statistiques spatiales,Communication orale,"Probabilités, Statistique, Processus ponctuels spatiaux",rr2014
https://r2014-mtp.sciencesconf.org/37486.html,rleafmap : cartographie interactive avec R et Leaflet,François Keck,français,NA,Statistiques spatiales,Communication orale,"Cartographie, Données spatialisées, Leaflet",rr2014
https://r2014-mtp.sciencesconf.org/37843.html,The SPNET package: Plotting social networks on maps with R,"Emmanuel Rousseaux, Marion Deville, Gilbert Ritschard",anglais,NA,Statistiques spatiales,Communication orale,"Network Data, Spatial analysis, Data Visualization, Social Sciences",rr2014
https://r2013-lyon.sciencesconf.org/19361.html,Visualising big data in R,Hadley Wickham,Invited conference,NA,NA,invited conference,"Visualisation, Big data",rr2013
https://r2013-lyon.sciencesconf.org/18935.html,L'analyse de données avec FactoMineR : les nouveautés,François Husson,Graphics & Visualization,NA,NA,oral,"Analyse de données, module graphique, FactoMineR, données manquantes",rr2013
https://r2013-lyon.sciencesconf.org/18844.html,"rCarto, un package de cartographie statistique",Timothée Giraud,Graphics & Visualization,NA,NA,oral,"Géographie, Cartographie, Sémiologie graphique, Visualisation, Carte, Graphique",rr2013
https://r2013-lyon.sciencesconf.org/19218.html,adegraphics : un package pour la représentation et l'analyse de données multivariées,"Aurélie Siberchicot, Alice Julien-Laferriere, Jean Thioulouse, Stéphane Dray",Graphics & Visualization,NA,NA,oral,"Analyse multivariée, Graphique, Visualisation",rr2013
https://r2013-lyon.sciencesconf.org/18866.html,Développement d'une application sous R pour la Surveillance Observationnelle des Problèmes de Santé au Travail,"Delphine Rieutort, Régis De Gaudemaris, Dominique Bicout",Applied statistics,NA,NA,oral,"maladies professionnelles, surveillance observationnelle, modélisation, programmation, logiciel R",rr2013
https://r2013-lyon.sciencesconf.org/19159.html,Estimation des données manquantes en morphométrie : quelle limite choisir ?,"Julien Clavel, Gildas Merceron, Gilles Escarguel",Applied statistics,NA,NA,oral,"Imputations multiples, données manquantes, morphométrie, simulations, ordinations, superimpositions procrustes",rr2013
https://r2013-lyon.sciencesconf.org/19269.html,Prédiction de la réactivité du glycérol sur les catalyseurs métalliques,"Jeremie Zaffran, Carine Michel, Francoise Delbecq, Philippe Sautet",Applied statistics,NA,NA,oral,"régression linéaire, prédiction, erreurs, boite à moustaches, catalyse, DFT",rr2013
https://r2013-lyon.sciencesconf.org/17872.html,"What a statistician might want to know about human color vision, but was afraid to ask!",Kenneth Knoblauch,sess_4216,NA,NA,oral,"visualisation, graphiques, couleur",rr2013
https://r2013-lyon.sciencesconf.org/18422.html,KmL3D: K-means pour données longitudinales jointes,"Christophe Genolini, Jean-Baptiste Pingault, Bruno Falissard",sess_4216,NA,NA,oral,"K, means, trajectoires jointes, partitionnement, interface graphique, graphes 3D dynamiques.",rr2013
https://r2013-lyon.sciencesconf.org/19104.html,MFAMIX : une extension de l'analyse factorielle multiple pour des groupes de variables mixtes,Amaury Labenne,Data Analysis,NA,NA,oral,"analyse factorielle multiple, méthode PCAMIX, analyse de la qualité de vie",rr2013
https://r2013-lyon.sciencesconf.org/19237.html,Méthodes de couplage de deux K-tableaux et collections de graphiques,"Jean Thioulouse, Aurélie Siberchicot, Alice Julien Laferrière, Anne-Béatrice Dufour, Stéphane Dray",Data Analysis,NA,NA,oral,"Analyse de données, Ecologie, ade4",rr2013
https://r2013-lyon.sciencesconf.org/19164.html,aste: An R package for the adaptive estimation the right tail,Frederico Caeiro,Poster,NA,NA,poster,"Extreme value index, semi, parametric estimation, bias reduction.",rr2013
https://r2013-lyon.sciencesconf.org/19247.html,Cascade : un package R pour étudier la dispersion d'un signal dans un réseau de gènes.,"Nicolas Jung, Laurent Vallat, Seiamak Bahram, Maumy-Bertrand Myriam, Frédéric Bertrand",Poster,NA,NA,poster,"Statistique, Biologie, Lasso, Réseau de régulation génique",rr2013
https://r2013-lyon.sciencesconf.org/19287.html,Corrélations entre maillages 3D au moyen du logiciel R application à l'imagerie par IRM de l'accident vasculaire cérébral,"Anaïs Rouanet, Carole Frindel, David Rousseau",Poster,NA,NA,poster,"Imagerie, Neuroscience, Corrélation",rr2013
https://r2013-lyon.sciencesconf.org/18850.html,Corrélations entre signaux EEG : un code d'analyse parallélisé,"Anne Cheylus, Raphaël Fargier, Tatjana Nazir",Poster,NA,NA,poster,"Statistiques, EEG, Corrélations, Test de permutations, Calcul parallèle",rr2013
https://r2013-lyon.sciencesconf.org/19240.html,Parallel Computing in R using the Bot Package,Florent Chuffart,Poster,NA,NA,poster,"Distributed Computing, Bag of Tasks, Parameter Sweep",rr2013
https://r2013-lyon.sciencesconf.org/19806.html,Un package pour utiliser les Cumulative Distribution Networks,"Van Trung Pham, Gildas Mazo",Poster,NA,NA,poster,"Cumulative Distribution Networks, graphe, vraisemblance, fonction de répartition multivariée",rr2013
https://r2013-lyon.sciencesconf.org/17623.html,Visualisation de processus spatiaux à l'aide de la correction de Ripley,"Arthur Charpentier, Ewen Gallic",Poster,NA,NA,poster,"effets de bord, estimation par noyau, GIS, méthode de la circonférence de Ripley, polygones, processus spatiaux",rr2013
https://r2013-lyon.sciencesconf.org/18934.html,Visualisation et cartographie des données de capteurs météorologiques à l'échelle des terroirs viticoles,"Malika Madelin, Cyril Bonnefoy",Poster,NA,NA,poster,"web mapping, climatologie, vignoble",rr2013
https://r2013-lyon.sciencesconf.org/19165.html,R and the Cloud,Karim Chine,Invited conference,NA,NA,invited conference,"Cloud Computing, EC2, e, Learning, distant education, e, Science, Collaboration, Science Gateways, Big data, Analytics, as, a, Service",rr2013
https://r2013-lyon.sciencesconf.org/19259.html,R2GUESS: a GPU-based R package for sparse Bayesian variable selection,Habib Saadi,High performance computing,NA,NA,oral,"Biologie, Genomique, Bayesien, Selection de Variable, GPU, Statistiques en Grande Dimension.",rr2013
https://r2013-lyon.sciencesconf.org/18893.html,An R package using HPC for entropy estimation and MCMC evaluation,"Didier Chauveau, Pierre Vandekerkhove",High performance computing,NA,NA,oral,"Entropy estimation, High Performance Computing, Kullback divergence, MCMC algorithms, Nonparametric statistics, Rmpi",rr2013
https://r2013-lyon.sciencesconf.org/19061.html,Intégration R et C++ avec Rcpp,Romain Francois,High performance computing,NA,NA,oral,"R, Rcpp, c++",rr2013
https://r2013-lyon.sciencesconf.org/18235.html,frailtypack : Un package pour l'analyse de données de survie corrélées,"Alexandre Laurent, Yassin Mazroui, Audrey Mauguen, Virginie Rondeau",Health & biostatistics,NA,NA,oral,"Survie, Modèle à fragilité, Modèle conjoint, Evénements récurrents",rr2013
https://r2013-lyon.sciencesconf.org/19131.html,The Dataset Project: Handling survey data in R,"Emmanuel Rousseaux, Gilbert Ritschard",Health & biostatistics,NA,Human and social sciences,oral,"Survey, Data Management, Data processing, Data analysis, Panel Data.",rr2013
https://r2013-lyon.sciencesconf.org/19125.html,Sample Size Determination and Data Analysis in the context of continuous co-primary endpoints in clinical trials.,Jeremie Riou,Health & biostatistics,NA,NA,oral,"Sample Size Determination, Co, primary endpoints, Multiple testing, Clinical trials",rr2013
https://r2013-lyon.sciencesconf.org/18000.html,R as a sound system,Jérôme Sueur,Invited conference,NA,NA,invited conference,"acoustique, son, audio, série temporelle, temps, fréquence",rr2013
https://r2013-lyon.sciencesconf.org/18927.html,L'approche par comparaison de modèles avec R2STATS dans l'enseignement des statistiques en sciences humaines,Yvonnick Noel,Invited conference,NA,NA,invited conference,"Interfaces graphiques, GLM(M), facteur de Bayes, comparaison de modèles",rr2013
https://r2013-lyon.sciencesconf.org/19054.html,Un site web d'enseignement R automatisé et à gestion partagée,"Simon Penel, Stéphane Dray, Anne-Béatrice Dufour, Jean Lobry, Sylvain Mousset",Teaching,NA,NA,oral,"Statistique, Biologie, Enseignement",rr2013
https://r2013-lyon.sciencesconf.org/19035.html,Génération automatique de documents pédagogiques avec R pour l'enseignement et l'évaluation des étudiants.,Sylvain Mousset,Teaching,NA,NA,oral,"Pédagogie, génération automatique de documents, questionnaires à choix multiples",rr2013
https://r2013-lyon.sciencesconf.org/19163.html,Pistes de réflexion pour la mise en œuvre d'un enseignement à distance sur le test du khi carré d'indépendance pour des étudiants en master de sciences de l'éducation,Mehdi Khaneboubi,Teaching,NA,NA,oral,"initiation, enseignements à distance, sciences de l'éducation, khi deux",rr2013
https://r2013-lyon.sciencesconf.org/19357.html,De la biologie à l'algèbre linéaire ... en passant par R. Expérimenter la notion de projection.,"Anne-Béatrice Dufour, Stéphane Dray, Jean Lobry, Jean Thioulouse",Teaching,NA,NA,oral,"Enseignement, Biologie Humaine, Algèbre linéaire, Projection",rr2013
https://r2013-lyon.sciencesconf.org/18900.html,metaRNASeq: un package pour la méta-analyse de données RNASeq,"Guillemette Marot, Florence Jaffrézic, Andrea Rau",Genomic data analysis,NA,NA,oral,"méta analyse, analyse différentielle, RNA seq, transcriptomique, séquençage haut débit",rr2013
https://r2013-lyon.sciencesconf.org/19189.html,jointSeg : Segmentation de données génomiques en cancérologie,Morgane Pierre-Jean,Genomic data analysis,NA,NA,oral,"Bioinformatique, CNV, Cancer, Nombre de copies, Fraction d'allèle B, biostatistique, détection de ruptures",rr2013
https://r2013-lyon.sciencesconf.org/18944.html,HTSFilter: An independent data-based filter for replicated high-throughput transcriptome sequencing experiments,"Andrea Rau, Mélina Gallopin, Gilles Celeux, Florence Jaffrézic",Genomic data analysis,NA,NA,oral,"Independent filter, gene expression, RNA, seq, differential analysis",rr2013
https://r2013-lyon.sciencesconf.org/18876.html,Aspects de cartographie thématique pour les sciences sociales avec R,Joël Gombin,Spatial statistics,NA,Human and social sciences,Lightning talk,"Cartographie, Sciences sociales",rr2013
https://r2013-lyon.sciencesconf.org/18818.html,Nouvelles fonctionnalités du package fitdistrplus,"Marie Laure Delignette-Muller, Christophe Dutang",sess_4217,NA,NA,Lightning talk,"ajustement de distributions, bootstrap, données censurées",rr2013
https://r2013-lyon.sciencesconf.org/18849.html,SesIndexCreatoR : Un package R pour la création et la visualisation d'indices socioéconomiques,"Benoit Lalloué, Séverine Deguen, Jean-Marie Monnez, Cindy Padilla, Wahida Kihal, Denis Zmirou-Navier, Nolwenn Le Meur",sess_4217,NA,NA,Lightning talk,"Analyse en composantes principales, Classification Ascendante Hiérarchique, Statut socioéconomique",rr2013
https://r2013-lyon.sciencesconf.org/18878.html,PNN : une nouvelle bibliothèque R pour la modélisation d'un réseau de neurones probabilistes de Specht,Pierre-Olivier Chasset,sess_4217,NA,NA,Lightning talk,"Réseau de neurones artificiels, Probabilité",rr2013
https://r2013-lyon.sciencesconf.org/18912.html,Estimation des risques dans les formes familiales de cancer.,"Youenn Drouet, Valérie Bonadona, Christine Lasset",sess_4217,NA,NA,Lightning talk,"Statistique en génétique, Données familiales, Risque de cancer.",rr2013
https://r2013-lyon.sciencesconf.org/19030.html,Prévision de consommation électrique avec R,Raphaël Nedellec,sess_4217,NA,NA,Lightning talk,"Consommation électrique, GAM, modélisation",rr2013
https://r2013-lyon.sciencesconf.org/19272.html,autoplot : ready-made plots with ggplot2,Jean-Olivier Irisson,sess_4217,NA,NA,Lightning talk,"Visualisation, Versatility, Multivariate data analysis",rr2013
https://r2013-lyon.sciencesconf.org/18812.html,Des analyses exploratoires multidimensionnelles pour prédire la progression des patients en thérapie,"Tiba Delespierre, Céline Piedvache, Jean-Michel Thurin, Monique Thurin, Bruno Falissard",sess_4218,NA,NA,Lightning talk,"Analyse en Composantes Principales, ACP, Classification Ascendante Hiérarchique, CAH, RRFPP, psychothérapie, autisme, ECAR, EPCA, CPQ",rr2013
https://r2013-lyon.sciencesconf.org/18843.html,R au secours des écotoxicologues,"Guillaume Kon Kam King, Philippe Veber, Marie Laure Delignette-Muller, Sandrine Charles",sess_4218,NA,NA,Lightning talk,"interfaçage web, analyse de données de bioessais, distribution de sensibilité des espèces",rr2013
https://r2013-lyon.sciencesconf.org/18862.html,Analyse et datation d'artefacts archéolgiques: R et les cachets circulaires hittites,Nehemie Strupler,sess_4218,NA,NA,Lightning talk,"Statistique, Archéologie, Chronologie",rr2013
https://r2013-lyon.sciencesconf.org/18923.html,Teaching R to social science undergraduates,"François Briatte, Ivaylo Petev",sess_4218,NA,NA,Lightning talk,"Statistiques, Enseignement, Sciences Humaines et Sociales",rr2013
https://r2013-lyon.sciencesconf.org/19069.html,R tools for spatial point pattern analysis applied to fluorescence localization nanoscopy,"Julien Godet, Halina Anton, Yves Mely",sess_4218,NA,NA,Lightning talk,"Nanoscopie, Imagerie, Statistiques Spatiales, R",rr2013
https://r2013-lyon.sciencesconf.org/19342.html,"Traiter des données de tracking – navigation web, suivi d'enquête – avec R",Anne Gayet,sess_4218,NA,NA,Lightning talk,"séquences d'événements, règles d'association, motifs séquentiels, coclustering, trajectoires, données de tracking, webmining",rr2013
https://r2013-lyon.sciencesconf.org/18790.html,Rendre R plus accessible aux utilisateurs non-informaticiens,"Jean-Paul Maalouf, Sandrine Longis, Séverine Montaudouin, Caroline Vieuille, Gilles Le Pape",sess_4218,NA,NA,Lightning talk,"convivialité, débutants, interfaces graphiques, non informaticiens, R Commander, synthèse",rr2013
https://r2013-lyon.sciencesconf.org/19057.html,TraMineR : Une boite à outils pour l'exploration et la visualisation de séquences,Gilbert Ritschard,Invited conference,NA,NA,invited conference,"séquences, trajectoires, séquences d'états, séquences d'événements, visualisation, dissimilarités, analyse basée sur les dissimilarités",rr2013
https://r2013-lyon.sciencesconf.org/19207.html,multlcmm : fonction d'estimation de modèles mixtes à processus latent pour données longitudinales,"Viviane Philipps, Cécile Proust-Lima",Mixed models,NA,NA,oral,"modèles mixtes multivariés, processus latent, données longitudinales",rr2013
https://r2013-lyon.sciencesconf.org/19350.html,Prédiction d'un événement binaire à partir de données fonctionnelles : Application aux bovins laitiers,"Cécile Sauder, Hervé Cardot",Mixed models,NA,NA,oral,"Prédiction, régression logistique, données fonctionnelles",rr2013
https://r2013-lyon.sciencesconf.org/19238.html,Données tronquées sous R dans les modèles linéaires simples et à effets mixtes,"Djeneba Thiam, Gregory Nuel",Mixed models,NA,NA,oral,"Données tronquées, modèle Tobit, modèles mixtes, algorithme EM",rr2013
https://r2013-lyon.sciencesconf.org/18426.html,Rankclust: An R package for clustering multivariate partial rankings,"Quentin Grimonprez, Julien Jacques, Christophe Biernacki",Clustering,NA,NA,oral,"model, based clustering, multivariate ranking, partial ranking",rr2013
https://r2013-lyon.sciencesconf.org/18831.html,SOMbrero: Cartes auto-organisatrices stochastiques pour l'intégration de données décrites par des tableaux de dissimilarités,"Laura Bendhaïba, Madalina Olteanu, Nathalie Villa-Vialaneix",Clustering,NA,NA,oral,"classification, visualisation, carte auto, organisatrice, données non euclidiennes, dissimilarité",rr2013
https://r2013-lyon.sciencesconf.org/19327.html,The data.sample package: sampling as a big data mining tool,"Matthieu Cornec, Jean Das Nieves",Clustering,NA,NA,oral,"Big Data, sampling",rr2013
https://r2013-lyon.sciencesconf.org/19101.html,Génération de documents Word à partir de R : utilisation du package R2DOCX dans une plateforme statistique en milieu industriel.,"David Gohel, Jean-François Collin",Dynamic document & Graphical interface,NA,NA,oral,"reporting, word, rapport",rr2013
https://r2013-lyon.sciencesconf.org/19161.html,sexy-rgtk: a package for programming RGtk2 GUI in a user-friendly manner,"Damien Leroux, Nathalie Villa-Vialaneix",Dynamic document & Graphical interface,NA,NA,oral,"Gtk2, RGtk2, GUI",rr2013
https://r2013-lyon.sciencesconf.org/18910.html,R-dyndoc une alternative à Sweave,Rémy Drouilhet,Dynamic document & Graphical interface,NA,NA,oral,Génération de rapport automatique,rr2013
https://rr2024.sciencesconf.org/560087,Dérivation automatique et optimisation avec la libraire torch,Tristan Mary-Huard,français,NA,"Tutoriel ""Dérivation automatique et optimisation avec la libraire Torch""",Tutoriel (invité),"Statistique, Ingéniérie, IA",rr2024
https://rr2024.sciencesconf.org/557106,Créez des environements reproductibles avec rix,Bruno André Rodrigues Coelho,français,NA,"Tutoriel ""Créez des environements reproductibles avec rix""",Tutoriel (invité),"Package, reproductibilité",rr2024
https://rr2024.sciencesconf.org/557302,Modélisation conjointe de données longitudinales et de temps d'événements sous R,Cécile Proust-Lima,français,NA,Conférence plénière de Cécile Proust-Lima,Conférence (invité),"biostatistique, modèles mixtes, classes latentes, forêts aléatoires, modèles conjoints",rr2024
https://rr2024.sciencesconf.org/544031,Extending code from the saemix package to fit parametric joint models in R,"Alexandra Lavalley-Morelle, France Mentré, Jimmy Mullaert, Emmanuelle Comets",anglais,NA,Biostatistique,Présentation longue,"Non, linear mixed effect models, Stochastic Approximation EM algorithm, Package, Model evaluation, Non Gaussian outcomes",rr2024
https://rr2024.sciencesconf.org/543907,Mise en oeuvre de méthodes semi-Bayésiennes de calcul des erreurs standards pour les données éparses dans le package saemix,"Mélanie Guhl, Lucie Fayette, Julie Bertrand, Emmanuelle Comets",français,NA,Biostatistique,Présentation longue,"Package saemix, Modèles non linéaires à effets mixtes, Erreurs standards, Inférence semi, Bayésienne, Données éparses",rr2024
https://rr2024.sciencesconf.org/544071,"BeQut, un package R pour l'estimation bayésienne de modèles de régression quantile à effets mixtes via JAGS","Antoine Barbieri, Christophe Tzourio, Hélène Jacqmin-Gadda",français,NA,Biostatistique,Présentation longue,"Régression quantile, Effets mixtes, Modélisation conjointe, JAGS, package R",rr2024
https://rr2024.sciencesconf.org/543291,Garantir des analyses fiables avec les packages R : perspectives de la recherche clinique,Yann Féat,français,NA,Reproductibilité,Présentation longue,"Validation, Package, DevOps, Reproductibilité, Collaboration",rr2024
https://rr2024.sciencesconf.org/541228,Créez des environements reproductibles avec rix,Bruno André Rodrigues Coelho,français,NA,Reproductibilité,Présentation longue,"Package, reproductibilité",rr2024
https://rr2024.sciencesconf.org/541832,Une enquête auprès des métiers de la « data » : quelle place pour R et ses utilisateurs ?,Antoine Girard,français,NA,Courte 1,Présentation courte,enquete data R,rr2024
https://rr2024.sciencesconf.org/542632,Pour un namespace tout en souplesse,Swann Floc'hlay,français,NA,Courte 1,Présentation courte,"Package, Reproductibilité, Integration Continue, Dépendances, Namespace",rr2024
https://rr2024.sciencesconf.org/546677,ProteoBayes : un cadre bayésien pour l'analyse protéomique différentielle,"Marie Chion, Arthur Leroy",français,NA,Courte 1,Présentation courte,"Biostatistique, Statistique Bayésienne, Package, Shiny",rr2024
https://rr2024.sciencesconf.org/546935,Cadre R chez IMPACT Initiatives,Yann Say,français,NA,Courte 1,Présentation courte,"Data, Humanitaire, Process",rr2024
https://rr2024.sciencesconf.org/538685,Comment les communautés autour de R peuvent changer vos pRojets,Marie Vaugoyeau,français,NA,Courte 1,Présentation courte,"Enseignement, Retours d'expérience, Projet",rr2024
https://rr2024.sciencesconf.org/541324,hubeau: un package pour interroger les APIs du Système d'Information sur l'eau en France,"David Dorchies, Pascal Irz",français,NA,Poster et cocktail dinatoire,Poster,"Eau, Data, Package, Reproductibilité",rr2024
https://rr2024.sciencesconf.org/538547,SK8 : Un service institutionnel de gestion et d'hébergement d'applications Shiny,"Jean-François Rey, Élise Maigné, Isabelle Sanchez, David Carayon, Joseph Tran",français,NA,Poster et cocktail dinatoire,Poster,"Shiny, hébergement",rr2024
https://rr2024.sciencesconf.org/543714,"Créer un site pour partager sa recherche avec R, blogdown et Hugo",Fanny Ollivier,français,NA,Poster et cocktail dinatoire,Poster,"Site internet, Communication, Education, Blogdown, Hugo",rr2024
https://rr2024.sciencesconf.org/544034,Les packages autour de JDemetra+ (rjd3) : une boîte à outils complète pour l'analyse des séries temporelles,Tanguy Barthelemy,français,NA,Poster et cocktail dinatoire,Poster,"Statistique, Package",rr2024
https://rr2024.sciencesconf.org/545195,Poster autour du package {datamods},"Samra Goumri, Victor Perrier",français,NA,Poster et cocktail dinatoire,Poster,"package, shiny, data",rr2024
https://rr2024.sciencesconf.org/543724,Distance/Divergence entre distributions t multivariées,"Pierre Santagostini, Nizar Bouhlel",français,NA,Poster et cocktail dinatoire,Poster,"Package, Divergence de Rényi, Divergence de Kullback Leibler, Distribution t multivariée",rr2024
https://rr2024.sciencesconf.org/546658,A survey translation tool to easily migrate from Qualtrics to LimeSurvey,Camille Straboni,français,NA,Poster et cocktail dinatoire,Poster,"package, open, source, Qualtrics, survey, online experiment, LimeSurvey",rr2024
https://rr2024.sciencesconf.org/541278,RecForest : Forêts aléatoires de survie pour l'analyse des événements récurrents en R,"Juliette Murris, Sandrine Katsahian, Audrey Lavenu",français,NA,Poster et cocktail dinatoire,Poster,"Biostatistique, Analyse de survie, Santé",rr2024
https://rr2024.sciencesconf.org/544062,Des tableaux et des graphiques prêts à publication avec les packages R {tabularise} et {chart} de la suite SciViews,"Guyliann Engels, Philippe Grosjean",français,NA,Poster et cocktail dinatoire,Poster,"Prêt à publication, Tableau, Graphique, tabularise, chart, SciViews",rr2024
https://rr2024.sciencesconf.org/558418,R POUR L'OCÉANO-MÉTÉO ET L'INGÉNIERIE MARINE,Nicolas Raillard,français,NA,Conférence plénière de Nicolas Raillard,Conférence (invité),"Ingénérie marine, Etats de mer, Valeurs extrêmes, Package R",rr2024
https://rr2024.sciencesconf.org/543678,telraamStats : visualisation des mobilités pour la recherche et les citoyen·ne·s,"Ketsia Guichard-Sustowski, Ioana Gavra, Pascal Irz, Loïc Le Marrec, Véronique Thelen",français,NA,Dataviz,Présentation longue,"Package, Données ouvertes, Shiny, Sciences citoyennes, Données spatiotemporelles",rr2024
https://rr2024.sciencesconf.org/544008,Collecter et cartographier les données du bilan carbone d'un congrès,"Chloé Friguet, François Husson",français,NA,Dataviz,Présentation longue,"Questionnaire, Dataviz, Cartographie, R, Shiny",rr2024
https://rr2024.sciencesconf.org/548415,Estimation de quantiles conditionnels extrêmes : Package Extremefit,"Gilles Durrieu, Ion Grama",français,NA,Méthode statistique,Présentation longue,"Valeurs extrêmes, Modèle semi, paramétrique, Statistique, écologie, Package R",rr2024
https://rr2024.sciencesconf.org/539419,Clustering sur données incomplètes avec clusterMI,Vincent Audigier,français,NA,Méthode statistique,Présentation longue,"Clustering, Données manquantes, Imputation multiple",rr2024
https://rr2024.sciencesconf.org/543866,Créer son propre package d'extension {recipes}: retour d'expérience de {scimo},"Antoine Bichat, Julie Aubert",français,NA,Méthode statistique,Présentation longue,"Tidymodels, Package, Statistique, Biostatistique, Données omiques",rr2024
https://rr2024.sciencesconf.org/543892,Smooth testing and clustering of copulas,"Yves Ismaël Ngounou Bakam, Denys Pommeret",anglais,NA,Méthode statistique,Présentation longue,"Copula coefficients, Data, driven, Smooth test, Legendre polynomials, Nonparametric clustering, Package Kcop",rr2024
https://rr2024.sciencesconf.org/557097,SK8 : Pour des applications shiny qui se déploient comment sur des roulettes,Elise Maigné,français,NA,Conférence plénière d'Elise Maigné,Conférence (invité),"R – Shiny – CI/CD – Docker, Kubernetes, Reproductibilité – Applications – Déploiement",rr2024
https://rr2024.sciencesconf.org/544051,Explorer et comparer des cartes de zones climatiques locales avec le paquet lczexplore,"Matthieu Gousseff, Elisabeth Le Saux - Wiederhold, Erwan Bocher, Baptiste Alglave, Jérémy Bernard, François Leconte",français,NA,Courte 2,Présentation courte,"Information Géographique, sf, Statistique Spatiale, Dataviz",rr2024
https://rr2024.sciencesconf.org/543812,Des applications Shiny qui facilitent la vie,Terence Dechaux,français,NA,Courte 2,Présentation courte,Statistique – R – Shiny,rr2024
https://rr2024.sciencesconf.org/543823,Application Shiny XPBlocs - Création de blocs en expérimentation,Maxime Legris,français,NA,Courte 2,Présentation courte,"Biostatistique, Expérimentation, Shiny",rr2024
https://rr2024.sciencesconf.org/539452,Utilisation du package {flexdashboard} pour le contrôle des données de biologie dans un entrepôt de données de santé,"Morgane Pierre-Jean, Guillaume Bouzillé",français,NA,Courte 2,Présentation courte,"reporting, flexdashboard, données de santé, visualisation",rr2024
https://rr2024.sciencesconf.org/548790,easy16S : une application Shiny pour explorer ses données métagénomiques,"Cédric Midoux, Mahendra Mariadassou",français,NA,Courte 2,Présentation courte,"Bioinformatique, Métagénomique, Visualisation, Shiny",rr2024
https://rr2024.sciencesconf.org/547938,Human in the deep: Converting research activities pressures into ecological impact assessment.,"Riwan Leroux, JozÉe Sarrazin, Marjolaine Matabos",français,NA,Statistique pour l'environnement,Présentation longue,Statistique – Ecologie – Statistique Spatiale – Environnements profonds,rr2024
https://rr2024.sciencesconf.org/544010,Maturation de codes scientifiques R de traitement de données liées à l'Eau au BRGM (initiative MATUREAU),"Marc Laurencelle, Théophile Lohier",français,NA,Statistique pour l'environnement,Présentation longue,"maturation, traitement de données, outil, package, eau, hydrogéologie, série temporelle, indicateurs, clustering, tendance, modularisation",rr2024
https://rr2024.sciencesconf.org/543486,"Un suivi régionalisé et actualisé des étiages des petits cours d'eau, c'est possible avec R, Hub'Eau et GitHub !","Benoît Richard, Cédric Mondy, Pascal Irz, Antonio Andrade, Céline Nowak",français,NA,Statistique pour l'environnement,Présentation longue,"Reproductibilité, Visualisation, Data, Eau",rr2024
https://rr2024.sciencesconf.org/543675,Sécurisation des analyses statistiques avec R : retour d'expérience,"Aurore Philibert, Julien Dugas",français,NA,"Gestion de projet R, bonnes pratiques",Présentation longue,"Maintenance, Reproductibilité, Plateforme, Biostatistique",rr2024
https://rr2024.sciencesconf.org/543491,"Refactoring : du code qui marche, c'est bien, mais du code maintenable, c'est mieux",Vincent Guyader,français,NA,"Gestion de projet R, bonnes pratiques",Présentation longue,"Refactoring, Bonnes pratiques, Maintenabilité, Développement logiciel",rr2024
https://rr2024.sciencesconf.org/543985,Une vie polyamoureuse entre R et Julia,Remy Drouilhet,français,NA,"Gestion de projet R, bonnes pratiques",Présentation longue,"Package R, Julia",rr2024
https://rr2024.sciencesconf.org/542773,Un petit coup de polish - Nettoyage de fichiers Excel avec R,Thomas Vroylandt,français,NA,Aide à la vie de tous les jours et à l'enseignement,Présentation longue,"Excel, Data Cleaning, Nettoyage de données",rr2024
https://rr2024.sciencesconf.org/536842,"{saperlipopette}, un paquet R pour progresser en Git en toute sérénité",Maëlle Salmon,français,NA,Aide à la vie de tous les jours et à l'enseignement,Présentation longue,"Git, Package, Enseignement, Bonnes pratiques, Développement",rr2024
https://rr2024.sciencesconf.org/543706,Génération aléatoire d'exercices de biostatistiques pour Moodle via le package SARP.Moodle de R,"Emmanuel Curis, Virginie Lasserre",français,NA,Aide à la vie de tous les jours et à l'enseignement,Présentation longue,"SARP.moodle, Moodle, XML, exercices aléatoires",rr2024
https://rr2024.sciencesconf.org/544084,Microstructure Information from Diffusion Imaging,Aymeric Stamm,anglais,NA,Shiny,Présentation longue,"brain imaging, diffusion MRI, biophysical tissue models, Shiny, R6",rr2024
https://rr2024.sciencesconf.org/546550,"Esquisse, un outil de visualisation",Victor Perrier,français,NA,Shiny,Présentation longue,"visualisation, ggplot2, shiny",rr2024
https://rr2024.sciencesconf.org/537480,"webR, et le futur des apps web avec R",Colin Fay,français,NA,Shiny,Présentation longue,"webr, API, shiny",rr2024
https://rr2024.sciencesconf.org/558616,Apprendre R et les statistiques... grâce à R,Philippe Grosjean,français,NA,Conférence plénière de Philippe Grosjean,Conférence (invité),"Apprentissage hybride, Statistique, Science des données, Outils pédagogiques, Cours en ligne interactif",rr2024
https://rr2025.sciencesconf.org/628989,"Introduction pratique à R : les fondamentaux pour organiser, analyser et visualiser",Claire Della-Vedova,"Tutoriel Introduction pratique à R : les fondamentaux pour organiser, analyser et visualiser",NA,NA,Tutoriel,,rr2025
https://rr2025.sciencesconf.org/628997,Conception d'applications Shiny avec {golem},"Vincent Guyader, Colin Fay, Laurent Spanu",Tutoriel Conception d'applications Shiny avec {golem},NA,NA,Tutoriel,,rr2025
https://rr2025.sciencesconf.org/628996,Tutoriel {data.table},Toby Dylan Hocking,Tutoriel {data.table},NA,NA,Tutoriel,,rr2025
https://rr2025.sciencesconf.org/628986,"{torch}, {tabnet} et l'apprentissage profond par l'usage",Christophe Regouby,R et son écosystème,NA,"Tutoriel {torch}, {tabnet} et l'apprentissage profond par l'usage",Tutoriel,,rr2025
https://rr2025.sciencesconf.org/628991,R and CRAN on Ubuntu With r2u,Dirk Eddelbuettel,R et son écosystème,NA,NA,Communication plénière de 40min,,rr2025
https://rr2025.sciencesconf.org/621704,"Air, un nouveau formateur de code pour R",Lionel Henry,R et son écosystème,NA,NA,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/617092,Sharing data science artifacts across teams using Crane,Lucianos Lionakis,R et son écosystème,NA,NA,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/622929,"Simplifiez, fiabilisez et accélérez vos workflows R complexes avec {targets}",Vincent Guyader,R et son écosystème,NA,NA,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/615901,Rajouter l'interactivité à vos ggplots avec animint2,Toby Dylan Hocking,R et son écosystème,NA,Visualisation et cartographie,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/621628,De la carte aux modèles spatiaux,Corentin Visée,Pédagogie et apprentissage de R,NA,Visualisation et cartographie,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/621568,PhaochR : géocoder des adresses belges avec R,"Hugo Périlleux, Joël Girès",Applications de R et des statistiques en sciences humaines,NA,Visualisation et cartographie,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/621710,RProtoBuf: sérialiser pour communiquer,Tanguy Barthelemy,R et son écosystème,NA,Interopérabilité,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/621694,Le format Parquet et l'écosystème DuckDB: l'essayer c'est l'adopter!,Lino Galiana,R et son écosystème,NA,Interopérabilité,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/622133,Créer des applications RAG-LLM avancées avec R Shiny,Mohamed El Fodil Ihaddaden,R et son écosystème,NA,Interopérabilité,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/621311,"Développement de workflows en R pour le nettoyage, la validation et la visualisation de données spatiales en écologie",Jordan Benrezkallah,Présentations courtes 1,NA,NA,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/625998,PATAPI : un outil de planification des pesées de bovins développé avec R,Maxime Legris,Présentations courtes 1,NA,NA,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/621687,Framework d'import de base de données en fichiers pour la recherche clinique : le package {EDCimport},Dan Chaltiel,Présentations courtes 1,NA,NA,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/621563,Transition SAS à R en recherche clinique : traduction et validation de macros SAS,"Nusaibah Ibrahimi, Livia Pierotti, Dan Chaltiel",Présentations courtes 1,NA,NA,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/617741,"{microinverterdata}, la collecte de données de votre souveraineté énergétique",Christophe Regouby,Présentations courtes 1,NA,NA,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/621674,Approche morphométrique 3D par Analyse Procrustes Généralisée sous R,"Nicolas Neels, Kevin Tougeron, Christophe Mallet",Présentations courtes 1,NA,NA,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/616762,"Rescuelog : Collecte numérique et reporting des interventions de sauveteurs à l'océan avec (ru)ODK, Shiny et SK8","David Carayon, Jeoffrey Dehez, Bruno Castelle",Applications de R et des statistiques en sciences humaines,NA,Posters + Q/R des présentations courtes 1 et cocktail dinatoire,Poster,,rr2025
https://rr2025.sciencesconf.org/616827,dbreportR : Un package R pour la documentation automatisée des bases de données,"Sébastien Boutry, David Carayon",Applications de R et des statistiques en écologie et sciences de l’environnement,NA,Posters + Q/R des présentations courtes 1 et cocktail dinatoire,Poster,,rr2025
https://rr2025.sciencesconf.org/618204,Détection et quantification de manipulations comptables autour d'un seuil psychologique avec R,"Marie Chavent, Véronique Darmendrail, Delphine Féral, Frédéric Pourtier, Jerome Saracco",Applications de R et des statistiques en sciences humaines,NA,Posters + Q/R des présentations courtes 1 et cocktail dinatoire,Poster,,rr2025
https://rr2025.sciencesconf.org/620335,Workflow automatisé d'intégration et d'analyse de données en Shiny,"Mélanie Demeure, Véronique Kowandy, Emmanuelle Mauger","Applications de R en médecine, pharmacie et biotechnologies",NA,Posters + Q/R des présentations courtes 1 et cocktail dinatoire,Poster,,rr2025
https://rr2025.sciencesconf.org/621715,Faciliter la prise en compte des risques économiques en agriculture grâce à R et Shiny,"Morgane Topart, Aïcha Ronceux",Applications de R et des statistiques en écologie et sciences de l’environnement,NA,Posters + Q/R des présentations courtes 1 et cocktail dinatoire,Poster,,rr2025
https://rr2025.sciencesconf.org/621865,Pages d'aide simplifiées et en français dans R grâce à l'IA,"Guyliann Engels, Philippe Grosjean",Pédagogie et apprentissage de R,NA,Posters + Q/R des présentations courtes 1 et cocktail dinatoire,Poster,,rr2025
https://rr2025.sciencesconf.org/622003,Des Learning Analytics qui ne manquent pas d'R,"Patrice Armand, Philippe Grosjean",R et son écosystème,NA,Posters + Q/R des présentations courtes 1 et cocktail dinatoire,Poster,,rr2025
https://rr2025.sciencesconf.org/622079,iteR : Un package R pour l'analyse de matrices de confusions issues d'expériences de perception phonétique.,Olivier Crouzet,Applications de R et des statistiques en sciences humaines,NA,Posters + Q/R des présentations courtes 1 et cocktail dinatoire,Poster,,rr2025
https://rr2025.sciencesconf.org/627960,rix: Reproductibilité d'Environnements De Développement R Avec Nix,Bruno André Rodrigues Coelho,R et son écosystème,NA,Posters + Q/R des présentations courtes 1 et cocktail dinatoire,Poster,,rr2025
https://rr2025.sciencesconf.org/641233,audio.whisper – Speech Recognition in R,Jan Wijffels,Posters + Q/R des présentations courtes 1 et cocktail dinatoire,NA,NA,Poster,,rr2025
https://rr2025.sciencesconf.org/647138,Les élections européennes et législatives 2024,Patrice Kiener,Posters + Q/R des présentations courtes 1 et cocktail dinatoire,NA,NA,Poster,,rr2025
https://rr2025.sciencesconf.org/628994,R pour l'analyse de données vectorielles en analyse de la parole,Olivier Crouzet,Applications de R et des statistiques en sciences humaines,NA,NA,Communication plénière de 40min,,rr2025
https://rr2025.sciencesconf.org/619493,Traiter des verbatims et questions ouvertes à l'aide d'un modèle d'IA local,"Thomas Vroylandt, Victoire Chatain, Emmanuel Herbepin",Applications de R et des statistiques en sciences humaines,NA,NA,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/622038,Strengthening confidence in LLM-generated responses with TrustMe: a package for evaluating semantic proximities between responses generated by the NaileR package,"Remi Mahmoud, Sébastien Lê",Applications de R et des statistiques en sciences humaines,NA,R et son écosystème,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/617134,fonctionr : l'inférence statistique pour tou-te-s,"Joël Girès, François Ghesquière",Applications de R et des statistiques en sciences humaines,NA,NA,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/618118,gaussratiovegind : un package pour analyser la distribution du ratio de deux distributions normales – Application aux images de fluorescence de chlorophylle,"Pierre Santagostini, Angelina El Ghaziri, Nizar Bouhlel, David Rousseau",Applications de R et des statistiques en écologie et sciences de l’environnement,NA,Statistique,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/619563,PerRegMod : un nouveau package R pour le test et l'estimation des modèles de régression à coefficients périodiques,"Regui Slimane, Abdelhadi Akharif, Amal Mellouk",Applications de R et des statistiques en écologie et sciences de l’environnement,NA,Pédagogie et apprentissage de R,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/621801,Make a difference: fast and accurate numerical derivatives with 'pnd',Andreï V. Kostyrka,R et son écosystème,NA,Statistique,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/619520,Basculer d'une application shiny (SaaS) vers des rapports Rmarkdown en Pharmacovigilance (RaaS): résumé des avantages et inconvénients,Lionel Van Holle,"Applications de R en médecine, pharmacie et biotechnologies",NA,Reporting,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/617376,"Automatisations du contrôle qualité de formulaire de recueil de données et de rapport de résultats avec les packages docxtractr, flextable et officer","Nelly Le Guen, Agnès Solomiac, Alwenna Salaün, Caroline Prunet, Anaëlle Coquelin, Anaïs Sitruk, Sandrine Morin","Applications de R en médecine, pharmacie et biotechnologies",NA,Reporting,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/622004,Automatiser l'analyse de graphes d'hyperliens avec igraph,Robert Viseur,Applications de R et des statistiques en sciences humaines,NA,Reporting,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/628992,R et le déclin des pollinisateurs : des outils statistiques au service de l'écologie,Maryse Vanderplanck,Applications de R et des statistiques en écologie et sciences de l’environnement,NA,NA,Communication plénière de 40min,,rr2025
https://rr2025.sciencesconf.org/622007,Traiter les données collectées à l'aide de formulaires pour partager des inventaires et des résultats d'enquêtes. Développement informatique et application aux pratiques agroécologiques en Europe,Frédéric Vanwindekens,Applications de R et des statistiques en écologie et sciences de l’environnement,NA,NA,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/616973,R au service du séquençage microbien : analyse et visualisation des résultats,"Alice Delacuvellerie, Ruddy Wattiez",Applications de R et des statistiques en écologie et sciences de l’environnement,NA,NA,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/621688,Utiliser les GitHub Actions pour automatiser des tâches : exemple de l'update de la version dev d'un package,Dan Chaltiel,R et son écosystème,NA,Présentations courtes 2,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/622931,shiny2docker : dockeriser une application Shiny en toute simplicité,Vincent Guyader,R et son écosystème,NA,Présentations courtes 2,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/617265,pkgdocs: a modular R package site generator,"Daan Seynaeve, Anne-Katrin Hess",R et son écosystème,NA,Présentations courtes 2,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/608632,Nettoyer son code en un clin d'oeil avec flint,Etienne Bacher,R et son écosystème,NA,Présentations courtes 2,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/614985,Création d'un package d'échantillonnage de polytope en modélisation linéaire inverse,"Jacques Brehelin, Valerie Girardin, Théo Grente, Philippe Regnault, Nathalie Niquil",Présentations courtes 2,NA,NA,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/617086,Outils et conseils pour la maintenance partagée de package R,Hugo Gruson,Présentations courtes 2,NA,NA,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/617754,La traduction du mlverse en français,Christophe Regouby,R et son écosystème,NA,Présentations courtes 2,Communication orale courte de 5 min,,rr2025
https://rr2025.sciencesconf.org/621928,Personnalisation de documents Quarto avec `_brand.yml`,Christophe Dervieux,R et son écosystème,NA,Quarto,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/618019,Dynamisez vos documents Quarto grâce à Observable JS,Antoine Bichat,R et son écosystème,NA,Quarto,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/607903,Comment traduire vos documents efficacement dans R,"Maëlle Salmon, Yanina Bellini Saibene, Paola Corrales, Elio Campitelli, Pascal Burkhard",R et son écosystème,NA,Quarto,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/616986,ShinyProxy: easily deploy your Shiny apps,"Tobia De Koninck, Tobias Verbeke",R et son écosystème,NA,Shiny,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/621295,Tester une application Shiny : méthodologie et outils pratiques,Arthur Bréant,R et son écosystème,NA,Shiny,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/621981,Truffles : une application Shiny pour cultiver ses données... et ses truffes !,Murielle Delmotte,Applications de R et des statistiques en écologie et sciences de l’environnement,NA,Shiny,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/616413,RDepot - 100% open source enterprise management of R and Python repositories,Jonas Van Malder,R et son écosystème,NA,Outils,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/621772,"DoReMIFaSol, un package pour simplifier l'usage des données en open-data de l'Insee",Pierre Lamarche,R et son écosystème,NA,Outils,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/613421,Explorer le CRAN avec le package RWsearch,Patrice Kiener,R et son écosystème,NA,Outils,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/628985,"R, un catalyseur d'interdisciplinarité : tour d'horizon du projet eGait sur l'analyse de la marche",Aymeric Stamm,"Applications de R en médecine, pharmacie et biotechnologies",NA,NA,Communication plénière de 40min,,rr2025
https://rr2025.sciencesconf.org/617370,Calcul d'indicateurs qualité à la Haute Autorité de Santé : Mise en place d'une migration de SAS vers R sans arrêt de la production des indicateurs,"Anaëlle Coquelin, Anaïs Sitruk, Caroline Prunet, Agnès Solomiac, Nelly Le Guen, Alwenna Salaün, Sandrine Morin, Pierre-Alain Jachiet","Applications de R en médecine, pharmacie et biotechnologies",NA,Pédagogie et apprentissage de R,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/617972,"OLAF, la reine des Apps Shiny !","Antoine Bichat, Anne-Sophie Pulcrano, Sophie Courtade-GaÏani","Applications de R en médecine, pharmacie et biotechnologies",NA,NA,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/628988,Apprendre R avec méthode et efficacité,Claire Della-Vedova,Pédagogie et apprentissage de R,NA,NA,Communication plénière de 40min,,rr2025
https://rr2025.sciencesconf.org/605759,Rlinguo - R en natif sur mobile,Colin Fay,Pédagogie et apprentissage de R,NA,R et son écosystème,Communication orale de 20 min,,rr2025
https://rr2025.sciencesconf.org/622039,R vous ment!,Antoine Fabri,Pédagogie et apprentissage de R,NA,NA,Communication orale de 20 min,,rr2025
